{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Joint HPC Exchange","text":"<ul> <li> <p> About Us</p> <p>The Joint High Performance Computing Exchange (JHPCE) is a High-Performance Computing (HPC) facility in the Department of Biostatistics at the Johns Hopkins Bloomberg School of Public Health. This fee-for-service core is a long-standing collaborative effort between Biostatistics and the Computational Biology &amp; Research Computing group in the department of Molecular Microbiology and Immunology. Thefacility is open to all Johns Hopkins affiliated researchers. </p> </li> <li> <p> Community</p> <p>The facility is used primarily by labs and research groups in the Johns Hopkins Bloomberg School of Public Health (SPH), the Johns Hopkins School of Medicine (SOM) and the Lieber Institute for Brain Development (LIBD). We have over 1000 user accounts, 400 active users and         approximately 100 unique users per quarter.</p> </li> <li> <p> Cluster Details</p> <p>The computing and storage systems are optimized for genomics and biomedical research. The cluster has 65 compute nodes, providing about 2800 cores, 30TB of DRAM and over 14 PB of networked mass storage. The network fabric consists of a 10 Gbps ethernet. The facility is connected via a 40Gbps network to the University\u2019s Science DMZ. Networked mass storage uses open-source file systems (ZFS and Lustre-over-ZFS) to provide low cost file systems. We also have a 2PB disk-to-disk backup system off site for backing up more critical data. The JHPCE cluster is optimized for the embarrassingly parallel applications that are the bread-and-butter of our stakeholders, e.g., genomics and statistical applications, rather than the tightly-coupled applications that are typical in traditional HPC fields, e.g., physics, fluid-dynamics, quantum simulation etc.  Job scheduling is performed with the Simple Linux Utility for Resource Management (SLURM).</p> </li> <li> <p> Cost Recovery</p> <p>The JHPCE operates as a formal Common Pool Resource (CPR) Hierarchy with rights to specific resources based on stakeholder ownership of resources. To benefit the entire research community, excess computing capacity is made available to non-stakeholders on an as-available basis, in exchange for fees that defray the operating costs of the stakeholders.</p> </li> </ul> <p>If your lab is interested in joining the JHPCE community, either as a stakeholder or as a non-stakeholder, please contact the directors (jhpce@jhu.edu) to determine whether we can accommodate your needs.</p> <p>If your lab is already a member, and you need to add new users, then have the users fill out the JHPCE new user request form.</p> <p>Mark Miller and Brian Caffo Co-Directors, JHPCE</p>","tags":["refers-to-old-website"]},{"location":"aboutus/model/","title":"Joint HPC Exchange","text":""},{"location":"aboutus/model/#about-us","title":"About Us","text":"<p>The Joint High Performance Computing Exchange (JHPCE) is a High-Performance Computing (HPC) facility in the Department of Biostatistics at the Johns Hopkins Bloomberg School of Public Health. This fee-for-service core began in 2008 as a collaborative effort between Biostatistics and the Computational Biology &amp; Research Computing group in the department of Molecular Microbiology and Immunology. The facility has grown over the years and is open to all Johns Hopkins affiliated researchers.</p>"},{"location":"aboutus/model/#community","title":"Community","text":"<p>The facility is used primarily by labs and research groups in the Johns Hopkins Bloomberg School of Public Health (SPH), the Johns Hopkins School of Medicine (SOM) and the Lieber Institute for Brain Development (LIBD). We support the HPC needs of over 2000 user accounts, with 300 active users each quarter.</p>"},{"location":"aboutus/model/#cluster-details","title":"Cluster Details","text":"<p>The computing and storage systems are optimized for genomics and biomedical research. The cluster has 65 compute nodes, providing about 2800 cores, 30TB of DRAM and over 14 PB of networked mass storage. The network fabric consists of 10/40 Gbps ethernet connections. The facility is connected via a 40Gbps network to the University\u2019s Science DMZ.</p> <p>Networked mass storage uses open-source file systems (ZFS and Lustre-over-ZFS) to provide low cost file systems. We also have a 2PB disk-to-disk backup system off site for backing up more critical data.</p> <p>The JHPCE cluster is optimized for the embarrassingly parallel applications that are the bread-and-butter of our stakeholders, e.g., genomics and statistical applications, rather than the tightly-coupled applications that are typical in traditional HPC fields, e.g., physics, fluid-dynamics, quantum simulation etc.  Job scheduling is performed with the Simple Linux Utility for Resource Management (SLURM).</p>"},{"location":"aboutus/model/#cost-recovery","title":"Cost Recovery","text":"<p>The JHPCE operates as a formal Common Pool Resource (CPR) Hierarchy with rights to specific resources based on stakeholder ownership of resources. To benefit the entire research community, excess computing capacity is made available to non-stakeholders on an as-available basis, in exchange for fees that defray the operating costs of the stakeholders.</p> <p>If your lab is interested in joining the JHPCE community, either as a stakeholder or as a non-stakeholder, please contact the directors (jhpce@jhu.edu) to determine whether we can accommodate your needs.</p> <p>If your lab is already a member, and you need to add new users, then have the users fill out the JHPCE new user request form.</p> <p>Mark Miller and Brian Caffo Co-Directors, JHPCE</p>"},{"location":"aboutus/staff/","title":"Staff","text":"<p>The care and feeding of the JHPCE Clustering environment is done by 5 individuals, providing a total of just under 3 FTEs.</p> <p>Mark Miller - Technology Manager &amp; Co-director  Brian Caffo, PHD - Biostatistics Professor &amp; Co-Director https://www.bcaffo.com Jiong Yang - Systems Engineer Jeffrey Tunison - Systems Engineer Adi Gherman - Senior Research Associate JHU Bio</p> <p>Oversight of the JHPCE is done by the BIT Committee, composed of the following individuals.</p> <p>Brian Caffo, PHD -  Biostatistics Professor  https://www.bcaffo.com Kasper D Hansen PHD - Biostatistics Professor http://www.hansenlab.org John Muschelli PHD - Biostatistics Professor https://www.johnmuschelli.com</p>"},{"location":"access/access-overview/","title":"Accessing the Cluster: Overview","text":"","tags":["done","topic-overview"]},{"location":"access/access-overview/#cluster-structure-overview","title":"Cluster structure overview","text":"<p>The cluster consists of some public-facing hosts with the remaining computers \"behind them\" on private networks. An incomplete and very oversimplified approximation:</p> <pre><code>graph TD\n   A[Your computer] --&gt; B([Login nodes])\n   A[Your computer] -- Only via Hopkins/VPN --&gt; D((Web Portal))\n   A[Your computer] --&gt; C([Transfer node])\n   B([Login nodes]) --&gt; E[Compute node1]\n   D((Web Portal)) --&gt; E[Compute node1]\n   B([Login nodes]) --&gt; F[Compute node2]\n   D((Web Portal)) --&gt; F[Compute node2]\n   B([Login nodes]) --&gt; G[Compute node3]\n   D((Web Portal)) --&gt; G[Compute node3]\n   C([Transfer node]) &lt;--&gt; H[(storage servers)]</code></pre>","tags":["done","topic-overview"]},{"location":"access/access-overview/#public-facing-login-and-transfer","title":"Public-facing: Login and Transfer","text":"<p>The login and transfer nodes are accessible to the wider Internet.  For security reasons, the web portal is only available to computers on Hopkins networks. If you are not on a Hopkins campus, that means that you need to use the VPN to be able to see that node.</p> <ul> <li>login: Normally jhpce01.jhsph.edu and jhpce02.jhsph.edu (currently jhpce03.jhsph.edu)</li> <li>transfer: jhpce-transfer01.jhsph.edu</li> <li>web portal: jhpce-app02.jhsph.edu</li> </ul>","tags":["done","topic-overview"]},{"location":"access/access-overview/#ssh-is-the-primary-method","title":"SSH Is The Primary Method","text":"<p>Access to the JHPCE cluster requires the use of SSH.</p> <p>SSH stands for Secure SHell. SSH is actually a set of internet standard protocols. Programs implementing these protocols include both command line interface (CLI) tools and those with graphic user interfaces (GUI).  They all enable you to make secure, encrypted connections from one computer to the next.</p> <p>This document provides more information on SSH.</p>","tags":["done","topic-overview"]},{"location":"access/access-overview/#x11the-x-window-system","title":"X11/The X Window System","text":"<p>The X Window System (aka X11, aka X) is the primary GUI system for UNIX computers. X allows a program (an X \"client\") running on a UNIX computer in the cluster to be displayed on a remote computer (running an X \"server\"<sup>1</sup>) over the network. To use it, your local computer needs to have X server software installed on it.</p> <p>SSH provides support for tunnelling X11 over an encrypted connection. You may need to tell SSH that you want that service, by, for example, adding the -X flag to an ssh command in a macOS Terminal.</p> <ul> <li>macOS users need to install XQuartz from xquartz.org.</li> <li>Windows users need to use a program like MobaXterm (highly recommended) or Cygwin. We have a page describing installing and using MobaXterm.</li> <li>Linux laptop or desktop users are already using X as their windowing system.</li> </ul> <p>For more information, see our X11 document.</p>","tags":["done","topic-overview"]},{"location":"access/access-overview/#multi-factor-authentication-mfa","title":"Multi-factor authentication (MFA)","text":"<p>There are two basic \"factors\" required to log into a computer, whether your laptop or a remote UNIX cluster login node -- your username and a password. JHPCE requires the use of an additional factor, either a one-time password (OTP) six digit code, or the use of SSH key pairs. </p>","tags":["done","topic-overview"]},{"location":"access/access-overview/#one-time-passwords","title":"One Time Passwords","text":"<p>When you SSH into JHPCE, you will be prompted for a \u201cVerification Code:\u201d This is your cue to enter in a one-time password six digit code.</p> <p>Programs like <code>Google Authenticator</code> and <code>Micrsoft Authenticator</code> generate one-time password codes (OTP). These are only good for a single use, whether you successfully log in or not. Typically they are used to generate a stream of time-based OTPs, or TOTPs. These are only good for one minute, adding another layer of difficulty for someone trying to impersonate you.</p> <p>These programs are usually used on smartphones, but there are programs available to create them on laptops and desktops. The key with using ANY OTP program is to get it from a trusted source. We will default to mentioning the <code>Google Authenticator</code>.</p> <p>After you log into JHPCE for the first time, you should immediately configure your OTP program using a \"secret\" accessible to you on the cluster via the <code>auth_util</code> program. Instructions for doing that are found in the Orientation document.</p>","tags":["done","topic-overview"]},{"location":"access/access-overview/#web-portal","title":"Web Portal","text":"<p>We have a web server named jhpce-app02.jhsph.edu configured to offer a growing number of services. Click on the links to learn more.</p> <ul> <li>Reset your password or generate a OTP (learn more)</li> <li>Run applications on the cluster (RStudio, JupyterLab, VS Code) (learn more)</li> <li>Inspect a catalog of research databases (under development) (learn more)</li> </ul>","tags":["done","topic-overview"]},{"location":"access/access-overview/#safe-desktop","title":"SAFE Desktop","text":"<p>A virtual desktop named the Secure Analytic Framework Environment (SAFE) is a resource that some people find useful for their computing, as well as a means to access JHPCE (via the MobaXterm application). It is a virtual Windows computer equipped with many applications JHPCE members use for their research, including SAS and Stata. It includes 100GB of secure data storage for sensitive (PHI, PII) information. That data can be shared by research groups. Free for Johns Hopkins Medicine staff and students, it requires filling out a form and waiting for approval.</p>","tags":["done","topic-overview"]},{"location":"access/access-overview/#file-transfers","title":"File Transfers","text":"<p>We have a transfer server jhpce-transfer01.jhsph.edu for file transfers into and out of the cluster. It is connected by a 40G Ethernet link to Hopkins networks. This computer also offers a Globus Endpoint service (described here) for transfers from personal computers and other institutions.</p> <p>Transferring data into or out of the cluster is documented here.</p> <p>The login nodes SHOULD NOT be used for file transfers into and out of the cluster beyond extremely trivial cases. Their connections are four times slower and they are relied upon by all of your peers.</p> <p>Please use compute nodes for transfers WITHIN the cluster. For example, copying significant volumes of files from one file system to another, such as <code>/dcs05/a-place/</code> to <code>/dcs07/somewhere-else/</code>. Information about doing that can be found here</p> <ol> <li> <p>Note that X reverses the normal conception of client/server operation, which is that the remote computer is the \"server\". In X11, the \"server\" is the program receiving the keyboard and mouse inputs and displaying the output of remote \"client\" programs.\u00a0\u21a9</p> </li> </ol>","tags":["done","topic-overview"]},{"location":"access/file-transfer/","title":"File Transfer - Overview","text":"<p>Authoring Note</p> <p>This document was copied over from the old web site and is being slowly updated.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#file-transfer-overview","title":"File Transfer - Overview","text":"<p>A number of options exist for transfering files to-and-fro between JHPCE and your local host. Which solution you chose depends on your use case.</p> <p>Copying files around inside the cluster, between JHPCE file systems, is a different activity. We have a document about using rsync to copy files. This tool can be used for both internal copies and for moving files into or out of the cluster.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#use-the-transfer-node-and-partition","title":"Use the transfer node and partition","text":"<p>For transferring files to and from the cluster, you should use <code>jhpce-transfer01.jhsph.edu</code> rather than a login node. This is both significantly faster, as the transfer node has a 40G Ethernet connection to the outside world while the login nodes have 10G connections. In any case, EVERYONE depends on the login nodes, and you should not run ANYTHING on them that occupies them.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#interactive-use-of-the-transfer-node","title":"Interactive use of the transfer node","text":"<p>You can ssh directly to <code>jhpce-transfer01.jhsph.edu</code> and do your work.</p> <p>We have a <code>transfer</code> SLURM partition which uses the same node that you can use for interactive or batch sessions.</p> Interactive job<pre><code>jhpce01% srun --pty --x11 -p transfer bash\n</code></pre>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#batch-use-of-the-transfer-nodepartition","title":"Batch use of the transfer node/partition","text":"<p>Here is a sample SLURM batch job that you can use as a model to do an internal transfer on a compute node using good rsync arguments. You can adapt it to run on the <code>transfer</code> partition to perform transfers into or out of the cluster. You can also change it to use some other transfer programs. Usually such batch jobs require care when providing authentication information.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#common-tools","title":"Common Tools","text":"<p>Many of these transfer protocols have both command-line and graphic user interface programs available.</p> <ul> <li>scp or sftp \u2014 file transfer via command line</li> <li>rsync - a very useful uni-directional mirroring utility program</li> <li>GUI for sftp \u2014 file transfer by drag and drop from your desktop</li> <li>GlobusOnline \u2014 fast file transfers between GlobusOnline endpoints</li> <li>Aspera  \u2014  very fast file transfer to and from Aspera servers</li> <li>OneDrive access with rclone  \u2014  Use \u201crclone\u201d to access your OneDrive directory (as well as other network drives (AWS buckets, Google Drive\u2026)</li> <li>Unison \u2014 keep directories synced (can be configured to be bi-directional)</li> <li>Mount remote filesystems \u2014 directories at JHPCE mounted on your local host. IS THIS MATERIAL STILL ACCURATE IN 2024? Is this example SSHFS doc worth re-using?</li> <li>ftp (kind of\u2026)</li> </ul>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#scp-and-sftp","title":"<code>scp</code> and <code>sftp</code>","text":"<p>The <code>scp</code> and <code>sftp</code> command-line tools are the most common tools used for transferring data to and from the cluster.  The basic tradeoff is between speed (<code>scp</code> is faster) and flexibility (<code>sftp</code> is more flexible).  The <code>scp</code> and <code>sftp</code> commands are available from the Terminal on a MacOS or Linux based laptop/desktop, or from a <code>CMD</code> or <code>Powershell</code> prompt on recent Windows systems.</p> <p>Although both SCP and SFTP utilize the same SSH encryption during file transfer with the same general level of overhead, SCP is usually faster than SFTP at transferring files, especially on high latency networks.  SFTP should be used when you may need an interactive session on the cluster to navigate to a directory before transferring the files, whereas SCP should be used when you know the exact path of the file you want to transfer.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#scp","title":"<code>scp</code>","text":"<p>The <code>scp</code> command can be though of as a <code>network cp</code> command.  The command to transfer a file called <code>data.txt</code> from your local system to your home directory on the cluster would be:</p> <pre><code>scp LOCAL_PATH/data.txt USERID@jhpce-transfer01.jhsph.edu:REMOTE_PATH/REMOTE_TARGET_FILENAME\n</code></pre> <p>where the paths default to your current local directory and home directory on the remote. The target filename if omitted will be the local filename.</p> <p>If you want to copy a file from the cluster to your local laptop/desktop, you would reverse the arguments. For example to copy <code>data2.txt</code> from the cluster to a local file:</p> <pre><code>scp USERID@jhpce-transfer01.jhsph.edu:REMOTE_PATH/data2.txt LOCAL_PATH/LOCAL_TARGET_FILENAME\n</code></pre>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#sftp","title":"<code>sftp</code>","text":"<p>The <code>sftp</code> command is another means of transfering data to and from the cluster.  To use <code>sftp</code>, you would run the command:</p> <pre><code>sftp USERID@jhpce-transfer01.jhsph.edu\n</code></pre> <p>Once you\u2019ve connected, you\u2019ll be shown an <code>sftp&gt;</code> prompt.  From here you can use the shell command <code>ls</code> to get a directory listing, and and <code>cd</code> to change directories.  In addition to <code>ls</code> and <code>cd</code> you can use the <code>get</code> command to transfer a file from the cluster it to your local system, or the <code>put</code> command to transfer a file from your local system to the cluster.  Once you are done with <code>sftp</code>, you would type <code>exit</code> to end the session.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#guis","title":"GUIs","text":"<p>If you prefer drag and drop interface rather than using shell commands, then an application that presents a window for drag and drop is what you want. Depending on which OS you are using, we can recommend the following applications:</p> <p>macOS users might consider Filezilla. It   is an outstanding application that not only provides a GUI browser for FTP, SFTP, but it also allows you to browse WebDav, Amazon S3, and OpenStack Swift file systems. It is free to download and install.</p> <p>Our recommended application for Windows users accessing the JHPCE cluster is MobaXterm. You can also use https://en.wikipedia.org/wiki/WinSCP or Putty if you are already familiar with them.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#rclone","title":"Rclone","text":"<p>Rclone can be used to access network file resources, such as OneDrive, Google Drive, and AWS. See here for instructions on using it to connect to Hopkins OneDrive storage.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#aspera","title":"Aspera","text":"<p>Warning</p> <p>This might be obsolete information as of 20240220 -- that package is no longer visible at the path mentioned below.</p> <p>Aspera is a commercial product from IBM that allows file transfers that are reportedly 20 times faster than <code>ftp</code>. If you download data from the NCBI Aspera server or download/upload data from/to JHU CIDR on the Bayview campus, then you will use Aspera. The Aspera license does not allow us to install the client for our users. You must install it yourself. You may either download the linux client from the aspera site or else use the client that we already downloaded. If you prefer the latter, simply copy the installation script from here:</p> <pre><code>/jhpce/shared/jhpce/core/JHPCE_tools/1.0/packages/aspera-connect-3.6.2.117442-linux-64.sh\n</code></pre> <p>into your home directory, and then run the script:</p> <pre><code>bash aspera-connect-3.6.2.117442-linux-64.sh\n</code></pre> <p>This will install the <code>ascp</code> command under your home directory at  <code>~/.aspera/connect/bin</code>.  You can either add <code>~/.aspera/connect/bin</code> to your <code>PATH</code>, or use the full path to the <code>ascp</code> command to run it.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#unison","title":"Unison","text":"<p>Warning</p> <p>As of 20240318 we don't have unison installed in the cluster. We will work on adding it. (You can install your own copy of it.)</p> <p>Using Unison, you can keep data synchronized between directories, including ones on a single computer or between the cluster and on your local system. Both CLI and GUI versions are available. Unison needs to be installed on both computers if used across a network.</p> <p>Unison is a synchronization tool. It can be told to update files in both SOURCE and DESTINATION locations according to some rules.</p> <p>Unison home page is here with a wiki that provides access to documentation and some binaries.</p> <p>An extensive tutorial at ostechnix.</p> <p>A wiki about using it from ArchLinux.</p> <p>This document written by a previous JHPCE user (Jacob Fiksel) might still be useful.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#globus","title":"Globus","text":"<p>We have a Globus endpoint. Please see this document.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#mounting-virtual-file-systems","title":"Mounting virtual file systems","text":"<p>Obsolete</p> <p>This might be obsolete information as of 20240220 - OSXFUSE is now named macFUSE and is hosted at a different location than what is described below.</p> <p>A common use case occurs when a user has a pipeline that is periodicially emiting tab delimited files and the user wants to plot these files with a favorite plotting or analysis application that runs on their local host. In this case it is common to mount the remote file system on the local host via NFS or SMB.</p> <p>Unfortunately, given the size and hetergeneity of our user base (which spans the entire medical campus), this is not practical. Instead, we recommend that users create a virtual file system on their OSX machine with the MACFusion application. MacFusion is free and allows you to create a mount point on your local host that looks like just another directory in your local file system. So any applications and scripts on your local host can access the data in that mount point. From the user perspective, it acts just like an SMB or NSF mount point. Data is transferred back and forth via an encrypted link.</p> <p>MacFusion requires the installation of an OSX kernel extenstion and some associated tools. OSXFuse provides the needed extension. OSXFuse implements a so called \u201d FileSystem in USErspace\u201d. This technology is described here. There exist FUSE kernel modules for most flavors of unix and linux.  The procedure for installing OSXFuse and MACFusion is described below.</p> <ul> <li>Downloaded OSXFUSE from sourceforge repository</li> <li>Install OSXFUSE</li> <li>Launch the OSXFUSE installer and perform a custom install.  Be sure to select \u201cMacFuse Compatibility Layer\u201d in the Custom Install screen. </li> <li>After installing the kernel extension it may, or may not, be necessary to reboot your mac.Screen Shot</li> <li>Download and install the Macfusion app from: http://macfusionapp.org.</li> <li>Startup MacFusion, and create an entry for <code>jhpce-transfer01.jhsph.edu</code> \u2014 enter your login and password.</li> <li>Select a mount point, e.g. <code>~/jhpce/myhome/</code></li> <li>Once the drive is mounted, you can cd to the directory in the shell or view it  in a window on your desktop. To do this you need to \u201cReveal\u201d the drive by pressing Command-R.  Once the directory is revealed, you can drag and drop files into the director in the usual way you drag and drop files into any directory on your mac.</li> </ul>","tags":["topic-overview","needs-major-revision"]},{"location":"access/file-transfer/#ftp","title":"ftp","text":"<p>We don\u2019t have the ftp client installed on the cluster.  It is an older, less secure, unencrypted channel for transferring files. However if you are downloading files from an older site that does not support SFTP or one of the other more modern mechanisms, you have a couple of options for ftp.</p> <p>If you want to be able to interactively browse through the ftp site you can use the lynx text based browser command:</p> <pre><code>lynx ftp://USER@ftp.site.gov\n</code></pre> <p>Once connected, you can then use the arrow keys to move around the site, and to select a file to download or a directory to descend into.</p> <p>If you know the exact path to the file you want, you can use the \u201cwget\u201d command:</p> <pre><code>wget ftp://USER:PASSWORD@ftp.site.gov/path/to/file\n</code></pre> <p>All of these should be done from the <code>transfer</code> queue to make use of our high speed ScienceDMZ network connection.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"access/globus/","title":"Using Globus to transfer files","text":"<p>Globus is a \u201cdropbox-like\u201d service to enable data sharing between academic and research communities. By using Globus, you can easily transfer files between Globus endpoints, share data with collaborators, and easily transfer data between the JHPCE cluster and your local desktop or laptop.</p>"},{"location":"access/globus/#setting-up-an-account","title":"Setting up an account","text":"<p>The first step in using Globus is setting up and account on the Globus site.\u00a0 To start, go to https://www.globus.org/ and clicking on the \u201cLog in\u201d button in the upper right. You should now see the screen below. Select \u201cJohns Hopkins\u201d from the list of Organizations.</p> <p></p> <p>You will now be directed to the JHU Login Screen. Enter your JHED ID and Password:</p> <p>Once you enter your JHED information you will be sent to the main Globus window:</p> <p></p>"},{"location":"access/globus/#transferring-files","title":"Transferring Files","text":"<p>With Globus, you can transfer data between nodes (known as \u201cEndpoints\u201d) that are part of the Globus network. The endpoint for the JHPCE cluster is called <code>jhpce#globus01</code>. To connect to the JHPCE endpoints, enter <code>jhpce#globus01</code> in the \u201cCollections field, and select it from the list of results displayed.</p> <p></p> <p>Once you select the <code>jhpce#globus01</code> endpoint, you will be prompted to enter your JHPCE Login and Password:</p> <p></p> <p>And once you login you will be shown a flie list of your home directory on the JHCPE cluster.</p> <p></p> <p>In order to transfer data to and from your desktop, you will need to install the Globus Connect Personal package (https://www.globus.org/globus-connect-personal) on your desktop. To do this, click on the \u201cTwo-Panel\u201d icon at the top of your globus session, and then click on Install Globus Connect Personal.</p> <p></p> <p>On the next screen, follow the steps on the next page to download the appropriate software package for your system, generate a Globus Key, and create a Globu name for your desktop/laptop.\u00a0</p> <p>Once you install and start Globus Connect Personal, you will be able to easily transfer files between your desktop/laptop and the JHPCE cluster via the Globus web interface.</p>"},{"location":"access/globus/#sharing-data-with-others","title":"Sharing data with others","text":"<p>One of the benefits fo using Globus is that you can share data from the JHPCE cluster with outside collaborators. To do this navigate to the directory you wish to share, select it, and either Right-Click on it, or select \u201cShare\u201d from the menu on the right hand side of the screen. In this example, I\u2019m sharing the <code>$HOME/class-scripts/R-demo</code> directory from within\u00a0my home directory.</p> <p>Next, you will be prompted to provide a name for your share.\u00a0 In this example, I\u2019m calling it \u201cMyRDemo\u201d.\u00a0 Once you enter the name and Description, click \u201cCreate Share\u201d:</p> <p></p> <p>Next you will be shown the current access permissions, which should be just for your account to start with.\u00a0 To grant others permission to access your share, click on \u201cAdd Permissions \u2013 Share With\u201d</p> <p>You will now be able to select which users you wish to share your directory with.\u00a0 The person you are sharing with must have a Globus account, and will need to provide their Globus ID or email with you.\u00a0 Enter their Username or Email, click \u201cAdd\u201d, and then click \u201cAdd Permission\u201d.\u00a0 We strongly recommend that you only grant \u201cread\u201d permission. for your share.</p> <p>Alternatively. you can create an \u201canonymous share\u201d to share a directory with anyone on Globus. To do this select \u201call users\u201d. Again, we strongly recommend that you only grant \u201cread\u201d permission for your share.</p> <p></p> <p>Once your share is created, you can notify your collaborators that they can access your data by using the Share name you created (in this example it\u2019s \u201cMyRDemo\u201d), and can search for your share name.</p> <p></p>"},{"location":"access/mobaxterm/","title":"Mobaxterm Configuration","text":"<p>Mobaxterm is a Windows application that provides an ssh client, scp client and X11 server all in one program.\u00a0 It is a very convenient tool for accessing the JHPCE cluster and utilizing the many features of the cluster.\u00a0 There is some configuration that needs to be done though in order to effectively use Mobaxterm in the JHPCE environment.\u00a0 This FAQ will take you through the steps needed to configure Mobaxterm.\u00a0 Before your proceed you should have your Google Authenticator app available.</p> <p>The first thing you will need to do is download the MobaXterm program from their web site http://mobaxterm.mobatek.net/download-home-edition.html</p> <p>Be sure to use the \"Installer Edition\" instead of the \"Portable Edition\"</p> <p></p> <p>Once the program has been downloaded, install it as you would any other Windows program.</p> <p>Once the program is installed, start the MobaXterm program. You should see a screen like this:</p> <p></p> <p>From this screen, click on the \"Sessions\" icon </p> <p></p> <p>in the upper left corner.</p> <p>On the \"Session settings\" screen, click on \"SSH\"</p> <p></p> <p>Enter \"jhpce01.jhsph.edu\" as the \"Remote host\". Click on the \"Specify username\" checkbox, and enter your JHPCE username in the next field. Then click the \"OK\" button.</p> <p>When you click OK, you will initiate an SSH session to the JHPCE cluster. You will be prompted for your Google Authenticator \"Verification Code\", and then your password.</p> <p>Once you enter your password correctly, you will see a number of boxes pop up (usually 3) prompting for another Verification Code. Click \"Cancel on these boxes. You will then be prompted to save your password. In the lower left, check the box that says \"Do not ask this again\" and then click \"No\". (We will get rid of these annoying boxes in a couple of steps).</p> <p>mobaxterm5</p> <p>At this point you should be logged into the JHPCE cluster and sitting at a shell prompt.</p> <p>After you exit out of the JHPCE cluster, a \"jhpce01\" session will be saved as a \"Saved Sessions\".\u00a0 To login again, double-click on the jhpce01 \"Saved Session\", and you should then be prompted for \"Verification Code\" (which will come from Google Authenticator) and \"Password:\"</p>"},{"location":"access/mobaxterm/#optional-setting-up-ssh-keys-in-mobaxterm","title":"OPTIONAL -- Setting up SSH Keys in MobaXterm:","text":"<p>To make logging in more streamlined and avoid the pop-up windows when you login, you can create an SSH key pair in MobaXterm. Before starting you should login to the JHPCE cluster in MobaXterm using your Google Authenticator and Password. Once you are logged in:</p> <p>Click on \"Tools -&gt; MobaKeyGen\"</p> <p></p> <p>You should then see the \"MobaXterm SSH Key Generator\" Screen. Click on \"Generate\", and you will be prompted to move the mouse around to generate random data.</p> <p></p> <p>Move your mouse until the green bar fills up.</p> <p></p> <p>Once the green bar fills up, you should see a populated screen.</p> <p></p> <p>For security purposes, we strongly recommend you protect your key with a password.\u00a0 To do so, enter a password in the \"Key passphrase\" and \"Confirm passphrase\" boxes. Next, click \"Save private key\", and save the key to a know locationon your local laptop/desktop (such as you \"Documents directory).</p> <p>Now, at the top of the window you'll see the text version of your public key. Copy the contents of this output with your mouse, making sure to scroll all the way to the bottom of the text box.\u00a0 NOTE: to do Copy/Paste in MobaXterm, you should not use \\&lt;CTRL&gt;-C and \\&lt;CTRL&gt;-V. Instead, select the text you want to copy, then use the right mouse button to bring up the context menu, and select\u00a0 Copy or select Paste when you are pasting.</p> <p>Now, go back to the tab where your JHPCE ssh session is running. From your home directory, cd into the .ssh directory. In this directory, you will need to update the file <code>authorized_keys</code>. Edit this file with your text editor of choice (nano, vi, emacs) as shown below. If the file does not exist, you can also create the file with the command below.</p> <p></p> <p>Paste in the public key that you copied from your local session. Depending on your editor, the new key may only show up on one long line, or it may wrap to multiple lines. Save the \"authorized_keys\" file when you are done.</p> <p></p> <p>If you assigned a passphrase to your key (and you really should have) we need to make a couple of extra steps to allow the passphrase to be entered only once, instead of every time you start a new login session.</p> <ul> <li>First go to \"Settings-&gt;Configuration\" and go to the \"General\" tab and click on \"MobaXterm password management\"</li> <li>At the top of the window where it says \"Save sesison passwords\", you should click \"Ask\"</li> <li>Also be sure to check the \"Save SSH keys passphrase as well\" box</li> <li>Then click \"OK\"</li> </ul> <p></p> <ul> <li>Next on the \"Configuration Window\" go to the \"SSH\" tab, and at the    bottom of the screen check the \"Use internal SSH agent \"MobAgent\"</li> <li>Just below this checkbox, click the \"+\" sign on the right side of    the \"Load Following Keys\" screen, and navigate to your \"Private    Key\", and select it.</li> </ul> <p></p> <p>Then click OK. You will be prompted to restart Mobaxterm. Go ahead and restart it. When you MobaXterm restarts, you will be prompted to enter your passphrase for your private key.</p> <p>The final step will be to add your key to the JHPCE session in the MobaXerm application. On the left pane of MobaXterm, you should see a list of \"Saved sessions\", including a session for the \"jhpce01\" login node. Right-Click on the \"jhpce01\" session, and select \"Edit Session\". This will open a window that looks like:</p> <p></p> <ul> <li>Select the \"Use private key\" checkbox.</li> <li>The field next to the checkbox should populate with a path to your local private key. If it does not, or it is not the correct path, then click the blue icon on the right side of the field, and navigate to the location of your \"private key\" file.</li> </ul> <p></p> <ul> <li>Click OK to save your changes.</li> <li>Now, in the left pane of Saved Sessions, you should be able to double click on the \"jhpce01\" session, and a new tab should open up, and log you into the JHPCE cluster without having to enter a password or Google Authenticator PIN.</li> <li>Once you have verified that you can login, exit out of all of your SSH sessions, and close the MobaXterm app.\u00a0 Reopen the MobaXterm application, double click on the \"jhpce01\" session.\u00a0 As before, a new tab should open up, and log you into the JHPCE cluster without having to enter a password or Google Authenticator PIN. </li> </ul>"},{"location":"access/onedrive/","title":"Using rclone to access OneDrive","text":"<p>Below is an example of using rclone to access the OneDrive network resource on the JHPCE cluster.  The initial setup is a bit involved, but regular operation is fairly straightforward.</p>","tags":["needs-review"]},{"location":"access/onedrive/#one-time-configuration","title":"One-time Configuration","text":"<p>Before you start, you will need to have an X11 graphical environment set up either by using MobaXterm on a Windows system or Xquartz on a Mac.  To start, login to the cluster as normal, and then srun into a compute node with a 10G RAM request (srun \u2013pty \u2013x11 \u2013mem=10G bash ) .  Part of the rclone setup process will involve using a web browser to generate an authentication key, so once you\u2019ve logged into a compute node, run \u201cchromium-browser &amp;\u201c.  The ampersand at the end will cause Firefox to run run in the background.  You may see a steam of warning message about \u201clibGL errors\u201d, but these are because we are using X11 forwarding and not a local graphics card, and assuming the browser stars up acter a few seconds, those messages can be ignored.</p> <p></p> <p>Now, from your srun session, you will need to run \u201cmodule load go\u201d to load the \u201cgo\u201d module, and then run \u201crclone config\u201d to begin the rclone setup.</p> <p></p> <p>When prompted to \u201cmake a new remote\u201d, enter \u201cn\u201d for \u201cnew remote\u201d. When prompted for a name, enter something descriptive, like \u201cOneDrive\u201d. Next, you will be presented with a long list of storage types.</p> <p></p> <p>. . .</p> <p></p> <p>. . .</p> <p></p> <p>When prompted for the type of storage to use, enter \u201conedrive\u201d. When prompted for \u201cOauth Client ID\u201d, just hit enter. When prompted for \u201cOauth Client Secret\u201d, just hit enter. When prompted to \u201cEdit advanced config\u201d, just hit enter to use the default \u201cNo\u201d answer. When prompted to \u201cUse auto config?\u201d, enter \u201cy\u201d. At this point you\u2019ll see a URL with \u201chttp://127.0.0.1\u201d in the address, and get a message \u201cWaiting for code\u2026\u201d</p> <p></p> <p>Also at this point, the Firefox browser should open a new tab, and start going to the http://127.0.0.1 address, which should redirect you to the Microsoft login page.</p> <p></p> <p>From here, you should enter \u201cJHEDID@jh.edu\u201d. Where of course you specify your own JHEDID. You will then be sent to the familiar \u201cJohns Hopkins\u201d JHED Login screen, where you should enter your JHED password.</p> <p></p> <p>When prompted to \u201cSave your login\u201d, you should select \u201cDon\u2019t Save\u201d. You should then see in the Firefox display, a \u201cSuccess!\u201d message, and in your \u201csrun\u201d session, you should see the message \u201cGot code\u201d, and then a selection of OneDrive site options. You should select option \u201c1\u201d for \u201conedrive\u201d.</p> <p></p> <p>Next, you should see a message where you can select which drive to use. There should only be one drive, so select \u201c0\u201d. You will also get a confirmation message, and you should select \u201cy\u201d.</p> <p></p> <p>At this point a summary of the configuration will be displayed, and you should select \u201cy\u201d to accept the configuration. Finally, you can enter \u201cq\u201d to quit the config process, and you can also close the Firefox browser.</p> <p></p> <p>At this point your OneDrive connection has been configured, and you can start to access your OneDrive.</p>","tags":["needs-review"]},{"location":"access/onedrive/#regular-operation","title":"Regular Operation","text":"<p>To access your OneDrive, you\u2019ll use the \u201crclone\u201d command with various options. The most often used commands are \u201crclone lsd\u201d to list directories, \u201crclone ls\u201d to recursively list files (this can take a long time if you have a lot of files in OneDrive and you are listing the top lecel directory), and \u201crclone copy\u201d to copy data between the cluster and your OneDrive.</p> <p>An example of \u201crclone lsd\u201d is below. There are a couple of key items to note. First, the name of the argument following \u201clsd\u201d should be the same name your used for your OneDrive config. You can run \u201crclone listremotes\u201d to see the name you used. The second item to note is that the name of your remote must end in a colon.</p> <p><pre><code>[compute-113 /users/bob]$ rclone lsd OneDrive:\n          -1 2019-12-21 01:54:32         2 BoxMigration\n          -1 2014-11-05 17:23:32        25 Documents\n          -1 2014-11-05 17:22:55       173 HomeDir\n          -1 2021-01-19 13:12:36         2 JHPCE-Billing-Videos\n          -1 2015-12-03 11:37:36         1 Lustre\n          -1 2019-07-11 17:25:16        10 OLDVMs\n          -1 2014-11-05 15:15:11         1 Shared with Everyone\n          -1 2019-07-11 12:13:21         0 USB\n</code></pre> To see the files in a particular directory, you would use \u201crclone ls\u201d and supply a directory name after the colon.</p> <pre><code>[compute-113 /users/bob]$ rclone ls OneDrive:Documents\n    84842 FY2014Q3 JHPCE Charges.xlsx\n    89229 FY2014Q4 JHPCE Charges.xlsx\n    57580 Globus-compute-022.rtf\n    43103 HPSCC Expenses.xlsx\n   684491 JHPCE-Overview-2014.pdf\n  1061265 JHPCE-Overview-2014.pptx\n    71168 JHU-Intel-Test-Cluster-Access.xls\n. . .\n   410012 pg10031.txt\n  4454050 pg31100.txt\n  1418582 pg6400.txt\n      426 plot1.r\n       20 plot1.sh\n       83 test1.sh\n[compute-113 /users/bob]$ \n</code></pre> <p>Finally \u201crclone copy\u201d can be used to transfer files between your OneDrive and the JHPCE cluster.</p> <pre><code>[compute-113 /users/bob]$ ls pg6400.txt\nls: cannot access pg6400.txt: No such file or directory\n[compute-113 /users/bob]$ rclone copy OneDrive:Documents/pg6400.txt .\n[compute-113 /users/bob]$ ls -l pg6400.txt\n-rw-r--r-- 1 bob mmi 1418582 Nov  5  2014 pg6400.txt\n[compute-113 /users/bob]$ touch zzz-test.txt\n[compute-113 /users/bob]$ rclone copy zzz-test.txt OneDrive:Documents\n[compute-113 /users/bob]$ rclone ls OneDrive:Documents | tail\n  2806147 ge_presentation.pdf\n   320053 pdf.tgz\n  5589891 pg100.txt\n   410012 pg10031.txt\n  4454050 pg31100.txt\n  1418582 pg6400.txt\n      426 plot1.r\n       20 plot1.sh\n       83 test1.sh\n        0 zzz-test.txt\n</code></pre> <p>This should give you a good start on using \u201crclone\u201d to access your OneDrive. Please email \u201cbitsupport\u201d if you have any questions.</p>","tags":["needs-review"]},{"location":"access/ssh/","title":"SSH - Key Information","text":"","tags":["in-progress","refers-to-old-website","ssh","jeffrey"]},{"location":"access/ssh/#ssh-basics","title":"SSH Basics","text":"<p>Access to the JHPCE cluster requires the use of SSH.</p> <p>SSH stands for Secure SHell. SSH is actually a set of internet standard protocols. Programs implementing these protocols include both command line interface (CLI) tools and those with graphic user interfaces (GUI).  They all enable you to make secure, encrypted connections from one computer to the next.</p> <p>Depending on the kind of operating system your computer uses, you may or may not need to install SSH software.</p> <p>Apple Macs come with CLI SSH tools pre-installed. You use them by entering commands in the Terminal app.  You can install GUI apps from various vendors, but we will only discuss the CLI tools except for some file transfer GUI programs.</p> <p>On a Windows system you will need to install an ssh client.  We recommend the excellent GUI program MobaXterm. Here is a document describing how to use it. There are other programs, such as the PuTTY family of tools and WinSCP.</p>","tags":["in-progress","refers-to-old-website","ssh","jeffrey"]},{"location":"access/ssh/#ssh-keys","title":"SSH Keys","text":"<p>SSH programs make use of something called public-key cryptography. Basically secure communications can be created by splitting a secret into to parts, and placing one part on each end of a link.</p> <p>This can be extended to an optional pair of files you can generate and distribute such that one is located on the JHPCE cluster and the other is on your computer. Or smartphone!</p> <p>This key pair of files is generated once, and protected with a passphrase. You place a copy of the \"public\" key file on JHPCE in a particular place with specific permissions. You keep a copy of the \"private\" key file on your personal device(s). Once you prove to a program (ssh-agent) running on your device that you know the passphrase to your private key file, it will thereafter provide your private key when you run an SSH command.</p> <p>Once configured properly, you can use SSH keys instead of your JHPCE password.</p> <p>Example document</p>","tags":["in-progress","refers-to-old-website","ssh","jeffrey"]},{"location":"access/ssh/#just-yanked-in-here-from-our-knowledgebase-document","title":"Just yanked in here from our Knowledgebase document","text":"","tags":["in-progress","refers-to-old-website","ssh","jeffrey"]},{"location":"access/ssh/#login-howto","title":"Login howto","text":"<ul> <li>When ssh-ing into the cluster you will be prompted for 2 pieces of information. </li> <li>First you will be prompted for \u201cVerification Code:\u201d, and for this you will enter the 6 digit number from your authenticator app (we recommend Google authenticator).</li> <li>Next you will be prompted for \u201cPassword:\u201d; this you this will use a traditional password that only you know.  Note that when entering your Verification Code and Password, your cursor will not move when you type, so it will appear like nothing is happening.  + If you have never accessed the cluster before, and \u201cInitial Verification Code\u201d and \u201cInitial Password\u201d will be provided to you during your JHPCE Cluster Orientation session.</li> <li>If you only get prompted for \u201cPassword\u201d and not \u201cVerification Code\u201d, you are likely using the wrong login ID.  Your login ID is provided to you during the JHPCE orientation; it is not the same as your JHED ID.</li> <li>If you have entered your credentials correctly, you will see a login banner for the JHPCE cluster, and you will be sitting at a shell prompt on the login node.  However, if you are prompted for \u201cVerification Code:\u201d again, you likely mistyped either your password or Verification Code, and you should wait until your Google Authenticator code changes (it changes every 30 seconds) and you will need to try logging in again.</li> <li>If you have tried several times to login, and you try to ssh again and get a \u201cConnection Refused\u201d message, you will need to wait 30 minutes before trying to login again.</li> <li> <p>If you continue to have login issues, please contact bitsupport@lists.jhu.edu.</p> </li> <li> <p>2 Factor Authentication</p> </li> </ul>","tags":["in-progress","refers-to-old-website","ssh","jeffrey"]},{"location":"access/ssh/#unix-based-machines-linux-and-mac-osx","title":"Unix-based machines (linux and mac osx)","text":"<p>(((((((IN 2024 DO WE NEED TO SPECIFY A DIFFERENT (STRONGER) ENCRYPTION TYPE???))))))) + First, on your local laptop/desktop, open a terminal and <code>cd</code> into your home directory  and invoke the ssh key generator:</p> <pre><code>ssh-keygen -t rsa\n</code></pre> <ul> <li>You will be prompted for a passphrase.  For security reasons, we require that you use a passphrase to protect your key.  This prevents someone who gets access to your private key file from being able to use it!!!!! For the other questions, you can select the default values.</li> <li>The key generator will put two files in the .ssh subdirectory of your home directory, typically  <code>~/.ssh/id_rsa</code> and  <code>~/.ssh/id_rsa.pub</code>. </li> <li>You should only ever have to run the ssh key generator once on your local host.  If you have already configured passwordless login and you run the key generator a second time, it will overwrite your previous public and private key files. This will break all password-less logins that you set up with your previous keys.</li> <li>Next you want to copy your public key file to the remote host and append it to the authorized_keys file in the <code>.ssh</code> subdirectory of your home directory on the remote host. </li> <li>If there is no <code>~/.ssh</code> directory in the remote host, you will need to login to the remote host and create one. Note, attempting to connect to another host, like <code>ssh github.com</code>, will create one if it isn't there already. </li> <li>You can perform the copy and append operations in one line as follows;</li> </ul> <p><pre><code>cat ~/.ssh/id_rsa.pub | ssh &lt;your_userid&gt;@jhpce01.jhsph.edu 'cat &gt;&gt; ~/.ssh/authorized_keys'\n</code></pre> + Where you replace <code>&lt;your_userid&gt;</code> with your JHPCE userid and where you enter your JHPCE password when you are prompted for it by ssh. + To test that everything is working you should be able to log into the remote host from your local host with the following command<code>ssh &lt;your_userid&gt;@jhpce01.jhsph.edu</code>. + When you start ssh, you will be prompted for the passphrase that you used to protect your key.  To avoid having to enter your passphrase every time you use ssh, you can use the <code>ssh-agent</code> program.  To use <code>ssh-agent</code>, run</p> <p><pre><code>ssh-add\nssh-agent\n</code></pre> The ssh-agent will remain active for as long as your desktop or laptop is up and running.  If you reboot your desktop/laptop, you will need to rerun the ssh-add and ssh-agent commands.</p>","tags":["in-progress","refers-to-old-website","ssh","jeffrey"]},{"location":"access/ssh/#loging-into-nodes","title":"Loging into nodes","text":"<p>Authoring Note</p> <p>(((This isn't true if you use <code>srun</code>. Is it even true in JHPCE 3.0 anyway Also, do we want to be suggesting that people log into compute nodes?)))</p> <p>Logging into a cluster node from a login node requires keypairs.   If your private key file is in <code>.ssh/</code> then it should work, since the public key file is in your <code>authorized_keys</code> file. If you do not want the same private key file to be used to log into nodes as the one used to log into the login node, then repeat create a new public private key / public key pair on the cluster.  Append the public key to your<code>authorized_key</code> file. Note, when appending, add the public key, do not overwrite the existing file.</p> <p>Many users set up an alias for the ssh command so they don\u2019t have to type as much to log into the remote host.  You can do this by adding the following line to your <code>~/.bashrc</code>, <code>alias hpc='ssh -X &lt;your_userid&gt;@jhpce01.jhsph.edu'</code>.</p>","tags":["in-progress","refers-to-old-website","ssh","jeffrey"]},{"location":"access/ssh/#windows-machines","title":"Windows machines","text":"<p>If your desktop/laptop runs Microsoft Windows then you first need to install MobaXterm on your windows machine. If you are using MobaXterm, please use the steps at the bottom of our MobaXterm configuration page.</p>","tags":["in-progress","refers-to-old-website","ssh","jeffrey"]},{"location":"access/ssh/#permissions-on-ssh-files","title":"Permissions on SSH Files","text":"<p>SSH is very strict about the permissions found on your files on the remote end of a connection. These files are found on JHPCE in your home directory inside the directory <code>.ssh</code>  Because this directory's name begins with a period, it is not listed when you use the <code>ls</code> program.</p> <p>The primary symptom of there being a file permissions problem is that ssh is still asking for a password when you think it should not.</p> <p>These rules are normally found to be broken on the remote side of a connection, but the permissions on your computer also matter.</p> <p>ALL OF THESE FILES NEED TO BE OWNED BY YOUR ACCOUNT.</p> <p>This table shows you two forms of the chmod command arguments needed to force permissions to be acceptable by SSH. The most convenient notation used by chmod is an octal (base-8) number. The most readable notation is a comma-separated combination of letters.</p> <p>These two commands are equivalent:</p> <ul> <li><code>chmod 700 $HOME/.ssh</code></li> <li><code>chmod u+rwx,g-rwx,o-rwx $HOME/.ssh</code></li> </ul> File/Directory Octal Human Readable Note $HOME 755 or tighter g-w,o-w Not writable by group or other $HOME/.ssh 700 u+rwx,g-rwx,o-rwx No access by group or other $HOME/.ssh/authorized_keys 600 u+rw,g-rwx,o-rwx Authorized keys file $HOME/.ssh/config 600 u+rw,g-rwx,o-rwx Config file $HOME/.ssh/id_* 600 u+rw,g-rwx,o-rwx Private key files $HOME/.ssh/id_*.pub 644 u+rw,g+r,g-wx,o+r,o-wx Public key files","tags":["in-progress","refers-to-old-website","ssh","jeffrey"]},{"location":"access/ssh/#ssh-and-x11","title":"SSH and X11","text":"<p>See our document on X11 for instructions on making ssh work to support X11 displays.</p>","tags":["in-progress","refers-to-old-website","ssh","jeffrey"]},{"location":"access/ssh/#mac-specific-configuration","title":"Mac-specific Configuration","text":"<p>!!! \"Under construction\"     Needs refinement. Some mention should be made in the x11 doc.</p> <p>In your ~/.ssh/config file you may find some of these options useful.</p> Key macOS settings<pre><code>UseKeychain yes\nXAuthLocation /opt/X11/bin/xauth\nAddKeysToAgent yes\nIdentityFile ~/.ssh/id_ecdsa\nIdentityFile ~/.ssh/id_rsa\nForwardAgent yes\n</code></pre> Keeping connections alive<pre><code># These values of 15 and 30 mean that my client ssh program will send a\n# message to the server every 15 seconds, and not decide that a remote\n# server is unresponsive until (15*30)=450 seconds\n\nServerAliveInterval 15\nServerAliveCountMax 30\n# IDK whether I included this for a good reason or not. Seems like I\n# would want the connection to die by lack of response to either method\n# Was it because I could not specify how long TCPKeepAlive waited?\nTCPKeepAlive no\n</code></pre> Per-host definitions for convenience<pre><code>Host jhpce01 j1 jhpce01.jhsph.edu\n    Hostname jhpce01.jhsph.edu\n    User your-cluster-username\n    ForwardX11 yes\n    IdentityFile ~/.ssh/id_ecdsa.jhpce\n</code></pre>","tags":["in-progress","refers-to-old-website","ssh","jeffrey"]},{"location":"access/x11/","title":"X11/The X Window System","text":"","tags":["in-progress","refers-to-old-website","jeffrey"]},{"location":"access/x11/#what-is-it","title":"What is it?","text":"<p>The X Window System (aka X11, aka X) is the primary GUI system for UNIX computers. X allows a program (an X \"client\") running on a UNIX computer in the cluster to be displayed on a remote computer (running an X \"server\"<sup>1</sup>) over the network. To use it, your local computer needs to have X server software installed on it.</p> <p>SSH provides support for tunnelling X11 over an encrypted connection. You may need to tell SSH that you want that service, by, for example, adding the -X flag to an ssh command in a macOS Terminal.</p> <p>X11 has been (slowly) being replaced by Wayland. Wayland has been the future for many years, but is becoming common. However this is usually invisible to users. Mentioned here in case you see references to Wayland where you expect to see X11.</p>","tags":["in-progress","refers-to-old-website","jeffrey"]},{"location":"access/x11/#how-do-you-get-it","title":"How do you get it?","text":"<ul> <li>macOS users need to install XQuartz from xquartz.org.</li> <li>Windows users need to use a program like MobaXterm. We have a page describing installing and using MobaXterm.</li> <li>Linux laptop or desktop users are already using X as their windowing system.</li> </ul>","tags":["in-progress","refers-to-old-website","jeffrey"]},{"location":"access/x11/#example-x11-programs","title":"Example X11 Programs","text":"<p>xterm, SAS, RStudio, xclock, thunar.</p>","tags":["in-progress","refers-to-old-website","jeffrey"]},{"location":"access/x11/#configuring-ssh-to-support-x11","title":"Configuring SSH To Support X11","text":"<p>Authoringnote</p> <p>The SSH document points to this one for ALL of the information needed to use X11. So this section needs to be complete. Pointing to the MobaXterm document of course, for Windows users.</p>","tags":["in-progress","refers-to-old-website","jeffrey"]},{"location":"access/x11/#troubleshooting-x-connections","title":"Troubleshooting X Connections","text":"<p>Authoringnote</p> <p>This section should include pointers to FAQ items or vice versa. We shouldn't rewrite the same information twice!!!</p> <ul> <li>When -X ?</li> <li> <p>When -Y ?</p> </li> <li> <p>printenv DISPLAY or echo $DISPLAY</p> </li> <li> <p>[user@login31 ~]$ srun --pty --x11 bash srun: error: No DISPLAY variable set, cannot setup x11 forwarding.</p> </li> <li> <p>How do Windows users configure ForwardX11Timeout ?</p> </li> </ul> <p>Is <code>ForwardX11Timeout 0</code> better in 2024 than specifying a particular time in hours?</p> <p>https://jhpce.jhu.edu/question/my-x11-forwarding-stops-working-after-20-minutes/</p> <ol> <li> <p>Note that X reverses the normal conception of client/server operation, which is that the remote computer is the \"server\". In X11, the \"server\" is the program receiving the keyboard and mouse inputs and displaying the output of remote \"client\" programs.\u00a0\u21a9</p> </li> </ol>","tags":["in-progress","refers-to-old-website","jeffrey"]},{"location":"csub/csub-overview/","title":"C-SUB Overview","text":"<p>The CMS SUBcluster (C-SUB) makes use of some of the resources of an existing High Performance Computing cluster called JHPCE.</p>","tags":["csub","topic-overview"]},{"location":"csub/csub-overview/#motivation-to-create-the-facility","title":"Motivation to create the facility","text":"<p>The Centers for Medicare and Medicaid Services (CMS) is part of the U.S. Department of Health and Human Services. It provides important data for researchers of patients, their conditions, and the American health care system.</p> <p>Acquiring and managing sensitive information from the Federal government is time-consuming, and requires on-going administrative and information technology support by groups with specific expertise.</p> <p>To facilitate research, an effort has been made to create an infrastructure that can provide those resources, as well as a computational facility to store and analyze the data.</p> <p>Researchers can leverage this existing infrastructure to more quickly and efficiently start and conduct their work.</p> <p>The Health Analytics Research Platform (HARP) was created to implement this vision. It is a collaboration of existing personnel across multiple organizations. Its leaders provide funding and guidance to an IT group which created a computing facility named the C-SUB.</p>","tags":["csub","topic-overview"]},{"location":"csub/csub-overview/#health-policy-management-hpm-component-of-c-sub","title":"Health Policy &amp; Management (HPM) Component of C-SUB","text":"<p>The Health Analytics Research Platform (HARP) provides data services to HBHI- affiliated and HEADS Center-affiliated investigators to facilitate research collaborations advancing HBHI\u2019s strategic pillars.</p> <p>HPM Personnel</p> <ul> <li>HEADS/HARP Director: Dan Polsky </li> <li>HEADS/HARP Deputy Director: Matt Eisenberg </li> <li>CMS Data Expert: Frank Xu</li> </ul> <p>Contact</p> <p>Please send C-SUB data-specific requests such as</p> <ul> <li>joining the C-SUB</li> <li>exporting files out of the C-SUB</li> <li>data inventory \u2013 current and desired additions or updates</li> </ul> <p>to support@harp-csub.freshdesk.com</p> <p>Further Information</p> <ul> <li> <p>Health Analytics Research Platform (HARP)</p> </li> <li> <p>Hopkins Business of Health Initiative (HBHI)</p> </li> <li> <p>Hopkins Economics of Alzheimer Disease &amp; Services (HEADS)</p> </li> </ul>","tags":["csub","topic-overview"]},{"location":"csub/csub-overview/#differences-between-jhpce-c-sub-clusters","title":"Differences between JHPCE &amp; C-SUB Clusters","text":"<p>The CMS subcluster (C-SUB) makes use of some of the resources of the original JHPCE cluster. For example, the scientific software such as STATA and SAS.</p> <p>However, in many other ways it operates differently than the rest of the cluster in order to keep CMS data from escaping.</p> <p>Please keep that in mind when reading JHPCE documentation or asking for help via the bitsupport &amp; bithelp mailing lists. Mention that you are a C-SUB user.</p>","tags":["csub","topic-overview"]},{"location":"csub/csub-overview/#commonalities","title":"Commonalities","text":"<ul> <li>SLURM job scheduler</li> <li>Almost all of the software</li> <li>use of modules</li> <li>except for programs which run out of containers like RStudio Server</li> </ul>","tags":["csub","topic-overview"]},{"location":"csub/csub-overview/#differences","title":"Differences","text":"<ul> <li>Different user accounts</li> <li>Different SLURM server, partitions and nodes</li> <li>File transfer in and out is VERY different</li> <li>Home directory locations</li> <li>Common file sharing areas among DUA members (e.g. /users/55548/shared/)</li> </ul>","tags":["csub","topic-overview"]},{"location":"csub/csub-overview/#getting-help","title":"Getting Help","text":"<p>Many of the pages on this web site will be useful to C-SUB users. However they will need to interpret what they read and think about whether applying it in the C-SUB requires any modification or re-interpretation.</p> <p>Sources of assistance:</p> <ul> <li>This web site - use the search field</li> <li>This web site - see the section titled \"Getting Help\"</li> <li>the orientation slides are improved over time. They contain much information! Because of a lack of staff time, this document will be improved ahead of adding C-SUB-specific information to this web site. There is a version date on the first page. You can use that to compare to the one you used during your orientation.</li> </ul>","tags":["csub","topic-overview"]},{"location":"csub/csub-stub/","title":"stub page for the \"C-SUB\" topic","text":"<p>This is a stub page for the \"C-SUB\" topic.</p> <p>Create a new file with the right contents for the topic header in the nav bar. Then point that header to the new document instead of \"csub/csub-stub.md\"</p>"},{"location":"csub/new-csub-users/","title":"New C-SUB User or PI?","text":"<p>Please contact a member of HARP via support@harp-csub.freshdesk.com. They can provide information, discuss costs and send requests to the systems administrators as needed to implement the creation of new users and groups.</p> <p>Information about the C-SUB can be found in our overview.</p>","tags":["csub"]},{"location":"files/acl/","title":"ACL - Access Control Lists","text":"<p>Traditional Unix file and group permissions can be used to share access to files and directories.  However, there can be times when more fine-grained control of shared access is needed. To accomplish this, Access Control Lists (ACLs) can be used. They add to the normal permissions.</p> <p>Tip</p> <p>Before defining ACLs, you should first read our document about sharing files for necessary background concepts and skills.</p>","tags":["in-progress","jeffrey"]},{"location":"files/acl/#caution","title":"Caution","text":"<p>JHPCE uses two kinds of file systems on its large storage servers: ZFS and Lustre.</p> <p>You need to use a different pair of ACL commands for each type:</p> <ol> <li>ZFS: nfs4_getfacl and nfs4_setfacl</li> <li>Lustre: getfacl and setfacl</li> </ol> <p>Instructions for Lustre file systems are found later in this document.</p> <p>Tip</p> <p>As of March 2024, the only Lustre file systems are those which begin with the path <code>/dcl02/</code></p> <p>As of March 2024, all of the files originally found on the Lustre file server named DCL01 have been copied off to live on other, ZFS-using file servers. But the name /dcl01 has been preserved, for convenience.</p>","tags":["in-progress","jeffrey"]},{"location":"files/acl/#notes-and-suggestions","title":"Notes and suggestions","text":"<p>Some common notes that are applicable to both types of ACL commands:</p> <ul> <li>ACLs can be used on both files and directories.</li> <li>You can tell that a file or directory has an ACL defined by the presence of a + symbol in the output of <code>ls -l</code></li> <li>Use normal UNIX permissions where possible. ACLs can be complex to manage. Use ACLs to extend normal permissions.</li> <li>Check the values of files and directories before, during, and after changing their permissions or defining ACLs. Test what happens afterwards. Don't change many files at once until you are confident that your commands are correct. You can capture the original configuration using commands like <code>ls -lR directoryname &gt; saved-listing.txt</code> for normal UNIX permissions and <code>nfs4_getfacl --recursive directoryname &gt; saved-acls.txt</code></li> <li>ACLs should use the security notion of \u201cleast privilege\u201d, meaning that ACLs should give only the needed access and nothing more.</li> <li>For users to be able to work with a file stored several layer deep in the directory structure, they must be able to get to it. That requires that they need sufficient permissions, via either normal UNIX permissions or ACLs (or both), to \"read\" and \"execute\" (aka \"search\") all of the directories above the final file or directory. For example, if you are wanting to enable access to the directory <code>/dcs07/bob/data/project1/shared</code>, you would need to provide <code>READ-EXECUTE</code> access on <code>/dcs07/bob/data/project1</code>, <code>/dcs07/bob/data</code>, and <code>/dcs07/bob</code>. Using UNIX permissions where appropriate, and ACLs where necessary.</li> <li>Setting an ACL on a directory does not change existing files and directories inside it unless you use the <code>recursive</code> option to the ACL command.</li> <li>User's umask settings impact the permissions assigned to files and directories being created whether you are using traditional UNIX permissions or ACLs.</li> <li>\"Default\" ACLs can be set on a directory, and this ACL will be inherited into the directory structure as new files and subdirectories are created. You might need to create different \"default\" ACLs to control the creation of new files and others to control the creation of new subdirectories.</li> <li>With \"default\" or \"inherited\" ACLs, the individual user\u2019s <code>umask</code> setting is important in assuring that future new files and directories being created have the correct permissions set. The <code>umask</code> setting will take precedence over the ACL, so it must be more permissive than the ACL. For example, if you want to set a default group ACL where the group has write access, you need to make sure that your umask is set to <code>0002</code> rather than <code>0022</code>, as the \u201c2\u201d in the group umask bit will prevent the group write capability.</li> <li>Like any operation, running ACL commands on large numbers of files should be run on a compute node and not a login node. Long-running recursive ACL commands on large directory trees may be done via interactive sessions or submitted batch job scripts.</li> </ul> <p>Example usage:</p> <pre><code>[alice@compute-123 ~]$ mkdir test1\n[alice@compute-123 ~]$ umask\n0022\n[alice@compute-123 ~]$ nfs4_setfacl -a A:gfdi:hpscc@cm.cluster:RWX test1\n[alice@compute-123 ~]$ touch test1/f1\n[alice@compute-123 ~]$ nfs4_getfacl test1/f1\n\n# file: test1/f1\nA::OWNER@:rwatTcCy\nA::GROUP@:rtcy\nA:g:hpscc@cm.cluster:rtcy\nA::EVERYONE@:rtcy\n[alice@compute-123 ~]$ umask 0002\n[alice@compute-123 ~]$ touch test1/f2\n[alice@compute-123 ~]$ nfs4_getfacl test1/f2\n\n# file: test1/f2\nA::OWNER@:rwatTcCy\nA::GROUP@:rwatcy\nA:g:hpscc@cm.cluster:rwatcy\nA::EVERYONE@:rtcy\n</code></pre>","tags":["in-progress","jeffrey"]},{"location":"files/acl/#acls-in-zfs-file-systems","title":"ACLs in ZFS File Systems","text":"","tags":["in-progress","jeffrey"]},{"location":"files/acl/#basic-commands","title":"Basic commands","text":"<ul> <li>There are 2 commands for dealing with ACLs on <code>/users</code>, <code>/dcs04</code>, <code>/dcs05</code>, <code>/dcs06</code>, and <code>/dcs07</code>. </li> <li>The <code>nfs4_getfacl</code> command will display current ACL setting for a file or directory</li> <li>The <code>nfs4_setfacl</code> command is used to modify ACLs.  </li> <li>With ACLs you can grant different kinds of access on directories or files to specific users and groups, in addition to the normal group associated with the object, and in addition to \"other\".</li> <li>The simplest permissions to use in ACLs are R for read access, W for write access, and X for execute and directory access. For detailed description of fine-grained permissions that can be set, please see (https://www.osc.edu/book/export/html/4523).</li> <li>By default, one\u2019s home directory is only accessible to the owner, and the original ACL should reflect this. For example, for the user alice, the ACL on their home directory would look like:</li> </ul> <pre><code>[alice@compute-123 ~]$ pwd\n/users/alice\n[alice@compute-123 ~]$ nfs4_getfacl .\n# file: .\nA::OWNER@:rwaDxtTcCy\nA::GROUP@:tcy\nA::EVERYONE@:tcy\n</code></pre>","tags":["in-progress","jeffrey"]},{"location":"files/acl/#read-permisions","title":"Read permisions","text":"<ul> <li>Now, if alice wanted to grant read-only access to their home   directory to the user bob, they would use the <code>nfs4_setfacl</code>   command:</li> </ul> <pre><code>[alice@compute-123 ~]$ nfs4_setfacl -a A::bob@cm.cluster:RX .\n[alice@compute-123 ~]$ getfacl .\n# file: .\nA::OWNER@:rwaDxtTcCy\nA::bob@cm.cluster:xtcy\nA::GROUP@:tcy\nA::EVERYONE@:tcy\nAt this point, bob would be able to access alice\u2019s home directory. Now suppose there is a file that alice wants to let bob update. Alice could use ACLs to grant write access to a particular file:\n\n[alice@compute-123 ~]$ ls -l shared-data.txt\n-rw-r--r-- 1 alice users 79691776 Feb  2 07:06 shared-data.txt\n[alice@compute-123 ~]$ nfs4_getfacl shared-data.txt\n# file: shared-data.txt\nA::OWNER@:rwatTcCy\nA::GROUP@:rtcy\nA::EVERYONE@:rtcy\n[alice@compute-123 ~]$ nfs4_setfacl -a A::bob@cm.cluster:RWX shared-data.txt \n[alice@compute-123 ~]$ nfs4_getfacl shared-data.txt\nnfs4_getfacl shared-data.txt\n# file: shared-data.txt\nA::OWNER@:rwatTcCy\nA::bob@cm.cluster:rwaxtcy\nA::GROUP@:rtcy\nA::EVERYONE@:rtcy\n</code></pre>","tags":["in-progress","jeffrey"]},{"location":"files/acl/#write-permissions","title":"Write permissions","text":"<ul> <li>Now suppose alice wanted to create a directory that bob could write to. </li> <li>Alice could create a directory, and grant bob write access to it:</li> </ul> <pre><code>[alice@compute-123 ~]$ mkdir shared\n[alice@compute-123 ~]$ nfs4_setfacl -a A::bob@cm.cluster:RWX shared\n[alice@compute-123 ~]$ nfs4_getfacl shared\nnfs4_getfacl shared-data.txt\n# file: shared-data.txt\nA::OWNER@:rwatTcCy\nA::bob@cm.cluster:rwaxtcy\nA::GROUP@:rtcy\nA::EVERYONE@:rtcy\nNow the user bob can copy or save files in the \u201cshared\u201d directory.\n</code></pre>","tags":["in-progress","jeffrey"]},{"location":"files/acl/#inherited-defaults","title":"Inherited Defaults","text":"<p>To set an inherited \u201cdefault\u201d ACL that will allow bob access on all new files and directories that get saved into <code>/users/alice/shared</code>, you would need to</p> <ol> <li>first give bob the normal ACL permissions, then</li> <li>add a second set of ACLs that will be inherited using the <code>fdi</code> option to the <code>nfs4_setacl</code> command.</li> </ol> <p>One issue we\u2019ve seen is that a <code>@USER</code> and <code>@GROUP</code> ACL need to be explicitly set for permissions to be properly set:</p> <pre><code>[alice@compute-123 ~]$ nfs4_setfacl -a A:fdi:bob@cm.cluster:RWX shared\n[alice@compute-123 ~]$ nfs4_setfacl -a A:fdi:OWNER@:RWX shared\n[alice@compute-123 ~]$ nfs4_setfacl -a A:fdi:GROUP@:RWX shared\n[alice@compute-123 ~]$ nfs4_getfacl shared\nnfs4_getfacl shared-data.txt\n# file: shared-data.txt\nA::OWNER@:rwatTcCy\nA::bob@cm.cluster:rwaxtcy\nA::GROUP@:rtcy\nA::EVERYONE@:rtcy\nA:fdi:OWNER@:rwaDxtTcCy\nA:fdi:bob@cm.cluster:rwaDxtcy\nA:fdi:GROUP@:rwaDxtcy\nA:fdi:EVERYONE@:tcy\n</code></pre> <p>To set a Group ACL, you need to add the <code>g</code> option to the <code>nfs4_getfacl</code> command.</p> <pre><code>[alice@compute-123 ~]$ mkdir shared\n[alice@compute-123 ~]$ nfs4_setfacl -a A:g:hpscc@cm.cluster:RWX shared\n[alice@compute-123 ~]$ nfs4_getfacl shared\nnfs4_getfacl shared-data.txt\n# file: shared-data.txt\nA::OWNER@:rwatTcCy\nA::GROUP@:rtcy\nA:g:hpscc@cm.cluster:rwaDxtcy\nA::EVERYONE@:rtcy\nTo set a Group Inherited ACL, you need to add the \u201cgfdi\u201d option to the \u201cnfs4_getfacl\u201d command. With this inherited group ACL set, all new files and directories will inherit the group settings.\n\n[alice@compute-123 ~]$ nfs4_setfacl -a A:gfdi:swdev@cm.cluster:RWX shared\n[alice@compute-123 ~]$ nfs4_setfacl -a A:fdi:OWNER@:RWX shared\n[alice@compute-123 ~]$ nfs4_setfacl -a A:fdi:GROUP@:RWX shared\n[alice@compute-123 ~]$ nfs4_getfacl shared\n\n# file: shared\nA::OWNER@:rwaDxtTcCy\nA::GROUP@:rwaDxtcy\nA:g:hpscc@cm.cluster:rwaDxtcy\nA::EVERYONE@:rxtcy\nA:fdi:OWNER@:rwaDxtTcCy\nA:fdi:GROUP@:rwaDxtcy\nA:fdig:swdev@cm.cluster:rwaDxtcy\nA:fdi:EVERYONE@:tcy\n</code></pre>","tags":["in-progress","jeffrey"]},{"location":"files/acl/#removing-an-acl","title":"Removing an ACL","text":"<p>If you want to remove and ACL, you can use the <code>-x</code> option to <code>nfs4_setfacl</code>. Please note that you need to use the full ACL, and not the <code>RWX</code> shortcuts.</p> <pre><code>[alice@compute-123 ~]$ nfs4_setfacl -x A::bob@cm.cluster:rwaxtcy shared\n[alice@compute-123 ~]$ nfs4_getfacl shared\nnfs4_getfacl shared-data.txt\n# file: shared-data.txt\nA::OWNER@:rwatTcCy\nA::GROUP@:rtcy\nA::EVERYONE@:rtcy\n</code></pre>","tags":["in-progress","jeffrey"]},{"location":"files/acl/#duplicating-existing-acls","title":"Duplicating Existing ACLs","text":"<p>This section under development</p> <p>The following information needs to be revised and reviewed. It is provided in case it is helpful until then.</p> <p>You can copy working ACLs but you must be very careful and check the results. Did your umask contribute an unexpected change to the process?</p> <p>One technique is to save and restore the settings. The second example uses input/output redirection to connect the two commands.</p> <pre><code>nfs4_getfacl -R source_dir &gt; tmpfile1\nsetfacl --restore tmpfile1 destination_dir\n\nnfs4_getfacl -R source_dir |\nsetfacl --restore - destination_dir\n</code></pre> <p>You can copy the ACLs on a directory with rsync. You have to put trailing slashes on BOTH the source and destination.</p> <p><code>rsync -A public-exam1/ /dcs05/somegroup/data/otherdir/</code></p> <p>While -Ar preserves ACLs, it doesn't preserves ownerships and permissions. Use -Arogp (o=owner, g=group, p=permissions) or shorter and more common -Ara (a=archive) for a better copy of your directory.</p> <p>This page has example scripts for saving and restoring ACLs on many files at once.</p> <p>This page has different advice for the same goal.</p>","tags":["in-progress","jeffrey"]},{"location":"files/acl/#acls-in-lustre-file-systems","title":"ACLs in Lustre file systems","text":"<p>There are two commands for dealing with ACLs on the JHPCE cluster for directories in Lustre file systems, which start with <code>/dcl02</code>.</p> <p>The <code>getfacl</code> command will display current ACL setting for a file or directory, and the <code>setfacl</code> command is used to modify ACLs.  With ACLs you can grant either read-only access, or read-write access on a directory or file to specific users.</p> <p>Let\u2019s say there is a directory <code>/dcl02/project/data/alice</code> that alice owns. The <code>getfacl</code> command could be used to see the current ACL set on the directory:</p> <pre><code>[alice@compute-123 ]$ pwd\n/dcl02/project/data/alice\n[alice@compute-123 ]$ getfacl .\n# file: .\n# owner: alice\n# group: users\nuser::rwx\ngroup::---\nother::---\n</code></pre>","tags":["in-progress","jeffrey"]},{"location":"files/acl/#read","title":"Read","text":"<p>Now, if alice wanted to grant read-only access to <code>/dcl02/project/data/alice</code> to the user bob, they would use the <code>setfacl</code> command:</p> <pre><code>[alice@compute-123 ]$ setfacl -m user:bob:rx .\n[alice@compute-123 ]$ getfacl .\n# file: .\n# owner: alice\n# group: users\nuser::rwx\nuser:bob:r-x\ngroup::---\nmask::r-x\nother::---\n</code></pre>","tags":["in-progress","jeffrey"]},{"location":"files/acl/#write","title":"Write","text":"<p>Now suppose there is a file that alice wants to let bob update. Alice could use ACLs to grant write access to a particular file:</p> <pre><code>[alice@compute-123 ]$ ls -l shared-data.txt\n-rw-r--r-- 1 alice users 79691776 Feb  2 07:06 shared-data.txt\n[alice@compute-123 ]$ getfacl shared-data.txt\n# file: shared-data.txt\n# owner: alice\n# group: users\nuser::rw-\ngroup::r--\nother::r--\n[alice@compute-123 ]$ setfacl -m user:bob:rw shared-data.txt \n[alice@compute-123 ]$ getfacl shared-data.txt\n# file: shared-data.txt\n# owner: alice\n# group: users\nuser::rw-\nuser:bob:rw-\ngroup::r--\nmask::rwx\nother::r--\n</code></pre>","tags":["in-progress","jeffrey"]},{"location":"files/acl/#creating-a-common-dir","title":"Creating a common dir","text":"<p>Now suppose alice wanted to create a directory that bob could write to. Alice could create a directory, and grant bob write access to it:</p> <pre><code>[alice@compute-123 ~]$ mkdir shared\n[alice@compute-123 ]$ setfacl -m user:bob:rwx shared\n[alice@compute-123 ]$ getfacl shared\n# file: shared\n# owner: alice\n# group: users\nuser::rwx\nuser:bob:rwx\ngroup::r-x\nmask::rwx\nother::r-x\nNow the user bob can copy or save files in the \u201cshared\u201d directory.\n</code></pre>","tags":["in-progress","jeffrey"]},{"location":"files/acl/#default-acls","title":"Default ACLs","text":"<p>To set an inherited default ACL that will allow bob access on all new files and directories that get saved into <code>shared</code>, you would need to use the <code>-d</code> option to the <code>setacl</code> command:</p> <pre><code>[[alice@compute-123 ~]$ setfacl -d -m user:bob:rwx shared\n[alice@compute-123 ]$ getfacl shared\n# file: shared\n# owner: alice\n# group: users\nuser::rwx\nuser:bob:rwx\ngroup::r-x\nmask::rwx\nother::r-x\ndefault:user::rwx\ndefault:user:bob:rwx\ndefault:group::--x\ndefault:mask::rwx\ndefault:other::r-x\nIf you want to remove and ACL, you can use the \u201c-x\u201d option to setfacl.\n\n[alice@compute-123 ]$ setfacl -x user:bob shared\n[alice@compute-123 ]$ getfacl shared\n# file: shared\n# owner: alice\n# group: users\nuser::rwx\ngroup::r-x\nmask::r-x\nother::r-x\n</code></pre>","tags":["in-progress","jeffrey"]},{"location":"files/archive-files/","title":"Archive Files","text":"<p>It can be advantageous to use archive commands to gather up individual files into archive files.</p> <p>JHPCE users store petabytes of data on our storage servers in billions of files. When data is not being actively used, it can be a good idea to store files in archives.</p> <p>It is easier to deal with fewer files when transferring or storing for the long term.  There are fewer individual items to process, document, run checksums against, or ask programs to process. File systems also work better with fewer files per directory. Creating and altering entries for each file takes time. Network transfers proceed faster when data can be read and manipulated in larger blocks.</p>"},{"location":"files/archive-files/#archive-commands","title":"Archive commands","text":"<p>A variety of programs exist which will add files into and extract files from archives of different formats. The features offered can include: checks for integrity, encryption, compression, Unicode filenames.</p> <p>When choosing a format, consider its popularity. You do not want to learn years later that you can no longer access a program that can work with your old archive file.</p> <p>Also consider which operating systems you may need to use when working with the archive file.</p> <p>Also consider researching any known limitations of a format. Most formats have such limitations. For example, what is the largest file size that can be contained within an archive? The size of the resulting archive? The number of files? The maximum number of characters in a file name? Characters in the complete path to the file?</p> <p>A comparison of archive formats can be found here.</p> <p>Popular programs:</p> <ul> <li>bzip2</li> <li>cpio</li> <li>gzip</li> <li>tar</li> <li>zip</li> </ul>"},{"location":"files/archive-files/#compression","title":"Compression","text":"<p>Most archive commands have optional arguments enabling the compression or decompression of files being added to or extracted from archives.</p> <p>Some data compresses more than others. Plain text files compress very well. Binary files holding data read out of lab instruments or images compress less well or are already compressed as a result of the file format used.</p> <p>JHPCE uses ZFS file systems with compression enabled for home directories and data stores like /dcs05.</p> <p>Therefore you do not need to spend time or CPU cycles compressing files or archives already stored in the cluster. </p> <p>That may be a worthwhile activity for reducing the size of files or archives before importing them into the cluster. Usually that is the case when the path from the data source to JHPCE contains links with limited bandwidth.</p>"},{"location":"files/archive-files/#do-your-work-on-the-right-computer","title":"Do your work on the right computer","text":"<p>Login nodes are needed by everyone. They should not be bogged down by your work with files. Use a compute node for anything except the smallest file operations. If you aren't sure how much space is in a deep directory tree, don't start a check on a login node!</p>"},{"location":"files/archive-files/#preparing-to-create-an-archive","title":"Preparing to create an archive","text":""},{"location":"files/archive-files/#space","title":"Space","text":"<p>Do you have enough space to create your archive? Do you need to create several smaller archives rather than an enormous single one? (That can have its own advantages.)</p> How much space is available in a file system? <code>df -h .</code> will show you info for your current working directory (CWD) including the hostname of the file server (if you're in an NFS file system) How much space is consumed by a directory? <code>du -sh that-dir</code> will show you disk consumption of the named directory <code>du -sh that-dir/*</code> will show you disk consumption of files and directories inside the named directory"},{"location":"files/archive-files/#data-cleaning-and-preparation","title":"Data cleaning and preparation","text":"<p>You may want to (carefully) prepare a set of files before archiving them. The amount of caution is of course related to the uniqueness and value of the data.</p> <p>This data maintenance can include:</p> <ul> <li>renaming files or directories,</li> <li>deleting unwanted files,</li> <li>setting consistent file permissions,</li> <li>setting consistent user/group ownership,</li> <li>re-organizing files into directories,</li> <li>creating README files describing the contents of the archive, its creation method, and anything else you or someone else might want to know. (It is a great idea to keep a copy of such files both inside and outside of the archive!!)</li> </ul> <p>Some commands like tar can accept arguments indicating that they should exclude certain file names or patterns. You can also create a list of files to archive out of a larger set of files and tell the archive program to only archive those files.</p>"},{"location":"files/archive-files/#precautions","title":"Precautions","text":"<p>You can capture critical information before beginning (and while making changes) with simple commands like a recursive listing of a directory tree's contents such as <code>ls -lR mydir &gt; mydir.contents</code></p> <p>If you are concerned that you might make mistakes during this process, consider:</p> <ul> <li>the backup process that might be protecting the storage area you are working within,</li> <li>if there is a backup done, its frequency,</li> <li>creating a scratch archive of the original material so you can fall back to it if needed,</li> <li>making one containing only the most essential files if you do not have the storage space for one containing everything </li> </ul> <p>While doing prepatory work, consider what commands or command options you can use to check what will happen before implementing changes such as file deletions. </p> <p>A helpful technique can be moving files aside into temporary trash directories before deleting them. If things work as desired, you can then delete the trash directories. You can also rename files instead of deleting them -- e.g. add a DEL suffix.</p>"},{"location":"files/archive-files/#before-deleting-the-original-files","title":"Before deleting the original files","text":"<p>Test your work. Can you extract various sample files? Ones with the longest total path length in characters? Can you generate a list of the archive contents? Does creating a checksum with <code>md5sum archive-name.tar</code> succeed (it will cause every byte of the archive to be read)?</p> <p>Have you created documentation about what the archive contains and the commands used to create it?</p>"},{"location":"files/archive-files/#example-commands","title":"Example commands","text":"<p>There are plenty of tutorials online for working with archives. Our goal with this document is to mention things to consider and some specific example commands.</p>"},{"location":"files/archive-files/#archiving-commands","title":"Archiving commands","text":"<p>Create archive from two directories and a file. The archive file is being created in a different file system, because you knew that the directories contain several terabytes of information (and want to store the archive there).  /dcs05 and /dcs07 come from two different file servers, so reading from one while writing to the other can be faster.</p> <p><pre><code>cd /dcs05/mygroup/data/trial5/experiment8/\ntar -cf /dcs07/mygroup/my-tar-file.tar some-directory other-dir2 file9\n</code></pre> Extract everything from an archive. It is always a good idea to look at the contents of the archive to see what file structure will be created during extraction. You do not want to overwrite other files. There are options like <code>--keep-old-files</code> and <code>--keep-newer-files</code> (and others) which affect extraction behavior. Better safe than sorry!</p> <pre><code>tar -tzf compressed-archive.tgz | less\ntar -xvzf compressed-archive.tgz\n</code></pre> <p>Extract multiple files from an archive. You need to first examine the contents of the archive and look for occurences of the names you want to extract -- there may be multiple items which match. You may need to provide partial paths to indicate which copy of the file you want.</p> <pre><code>tar -tf somearchive.tar &gt; mylisting.txt\nless mylisting.txt\ntar -xvf somearchive.tar \"file1\" \"file2\"\n</code></pre> <p>Extract files matching a wildcard pattern <pre><code>tar -xvf somearchive.tar --wildcards '*.php'\n</code></pre></p>"},{"location":"files/archive-files/#find-command","title":"Find command","text":"<p>The find command is a very useful tool. If you want to modify files or directories found with find, it is recommended to use xargs.</p> <p>Note that file or directory names containing spaces or other such characters cause a world of problems in UNIX. It is extremely highly recommended to strictly avoid creating or retaining such names.</p> <p>Here is an example that finds Perl scripts <pre><code>find /usr/bin/ -exec file {} \\; | grep Perl\n</code></pre></p> <p>Find the size of cache directories inside of \"mydir\" to help you decide whether to delete or exclude them. Store the results in a text file. Inspect it with the less command (press q to quit out of it). The find option -print0 and the xargs option -0 allow searches to deal with PATH NAMES CONTAINING SPACES. <pre><code>find mydir -type d -name .cache -print0 | xargs -0 du -sh &gt; /tmp/cache-list.txt\nless /tmp/cache-list.txt\n</code></pre></p> <p>Find files ending in \".o\" (but not directories) and rename them to \".o.DELETEME\" The asterisk needs to be escaped by the backwards slash to prevent the shell from expanding the wildcard in the current directory before starting the find program. <pre><code>find mydir -type f -name \\*.o -print0 | xargs --null -I{} mv {} {}.DELETEME\n</code></pre></p> <p>Find files or directories modified after a certain date and time (09/11/2019 noon)</p> <pre><code>touch -t 201909111200 911-noon\nfind somedirofmine -newer 911-noon -print0\n</code></pre> <p>This more complex example ignores directories named Library and .dropbox, limits how deep to search <pre><code>find . \\( \\( -type d -name Library -prune \\) -o \\( -type d -name .dropbox -prune \\) \\) -o -newer 911 -depth 4 -print0 \n</code></pre></p>"},{"location":"files/copying-files/","title":"Copying Files Within The Cluster","text":""},{"location":"files/copying-files/#tldr","title":"TL;DR","text":"<p>If you need to manage a lot of files, it is well worth your time to learn how to use the <code>rsync</code> command. This program is available on UNIX and Mac computers by default. It is increasingly available on Windows as the Windows Subsystem for Linux (WSL) becomes more common.</p>"},{"location":"files/copying-files/#introduction","title":"Introduction","text":"<p>JHPCE users store petabytes of data on our storage servers. Some of it accumulates as work is done. Much is imported from outside the cluster as source material for research.  Moving around large numbers of files can be done with a variety of methods.  Many users default to <code>cp</code> or <code>mv</code></p> <p>All tools have limitations, most of which we, thankfully, don't encounter in day-to-day use. However, when manipulating large numbers of files and files in directory trees many levels deep, these issues can begin to surface. Some of them give you more confidence in the results than others. Some are misleadingly quiet despite failing or producing a result that isn't the same as the source location.</p> <p>The <code>cp</code> command is a good example of a familiar tool that can produce unexpected results. It supports recursion through the <code>-R</code> flag. Depending on the UNIX version, <code>cp</code> may or may not treat symbolic links or hard-linked files the way you expect.</p> <p>What is the state of your copy if <code>cp</code> or <code>mv</code> attempts fail mid-stream? In the middle of a file?</p> <p>For example, consider what happens if a program has a limitation where it cannot handle file paths longer than 1024 characters. You would be unlikely to experience a problem using that program to copy files around unless they are <code>/stored/in/directory/trees/with/many/entries/YYYY-MM-DD-MM-SS/long-filename-with-details-embedded-in-its-name.dat</code>  Such paths are common in the sciences and become more common as time passes and data accumulates.</p>"},{"location":"files/copying-files/#rsync","title":"Rsync","text":"<p>Rsync is a powerful command for copying large numbers of files between a SOURCE (aka SRC) and a DESTINATION (aka DEST), within a single computer or between computers. </p> <p>Note</p> <p>A key benefit of <code>rsync</code> is that it will copy only the material needed to make DEST match SRC. Most other programs, such as <code>cp</code> or <code>scp</code>, will always copy over all of SRC to DEST.</p> <p>There are MANY arguments which control how the copying will occur. So you can do things like specify files to exclude, create a log of the actions taken, and provide statistics when done. Rsync uses a variety of tests to compare files and directories. We wrote this page because using rsync properly for complex situations takes some skill and explanation.</p> <p>The most common flag used with <code>rsync</code> is <code>-a</code> for \"archive\". This provides a recursive copy, preserving symbolic links, timestamps, file permissions, user &amp; group ownership. It does NOT preserve ACLs or hard links.</p>"},{"location":"files/copying-files/#use-the-appropriate-resources","title":"Use the appropriate resources","text":"<p>When transferring files within the cluster, please use compute nodes when copying more than a few files.</p> <p>When transferring files into and out of the cluster, please use the transfer node. The various tools for that work are described in this document. The rsync information on this page can be useful for such transfers.</p>"},{"location":"files/copying-files/#example-rsync-slurm-batch-job","title":"Example rsync SLURM batch job","text":"<p>Is shown here.</p>"},{"location":"files/copying-files/#source-and-destination","title":"SOURCE and DESTINATION","text":"<p>Multiple items can be listed as SRC material. Of course there can only be one DEST.</p> <p>Rsync never updates the SRC location. Changes, if any, only occur in the DEST.</p> <p>Files in DEST but not SRC will not be deleted unless you specify one of the delete flags.</p> <p>SRC and DEST can be paths or hostnames with colons and paths or a combination. rsync will use ssh to send files between hosts, so you can even specify a different username for one of the SRC and DEST.</p> <p>Here are the different scenarios and their core syntax:</p> Local copying: <code>rsync [OPTION...] SRC... DEST</code> Access via remote shell: Pull:              <code>rsync [OPTION...] [USER@]HOST:SRC... [DEST]</code> Push:              <code>rsync [OPTION...] SRC... [USER@]HOST:DEST</code>"},{"location":"files/copying-files/#mind-the-trailing-slash","title":"Mind the trailing slash!","text":"<p>If the SOURCE represents a directory then adding a trailing forward slash to it will cause the contents of the directory to be copied into DESTINATION. If there is no trailing forward slash, then the SOURCE  directory itself will be copied into DESTINATION.</p> Example If directory /some/source/place contains files a, b, and c <code>rsync -a /some/source/place/  /a/destination/location/</code> will result in the contents of /a/destination/location/ being a, b, and c. If the command was instead  <code>rsync -a /some/source/place  /a/destination/location/</code> will result in the contents being instead /a/destination/location/place <p>This behavior is also found with the old standard <code>cp</code> program when using the <code>-R</code> recursive flag!!!</p>"},{"location":"files/copying-files/#rsync-examples","title":"Rsync Examples","text":"<p>It pays to be cautious when running commands which can cause many changes in short order.</p> <p>Rsync can be used to compare two directory trees without updating anything. If both possibly have unique data, then you want to be careful and run preliminary <code>--dryrun</code> commands with a variety of informational flags. </p> <p>Show what would be done by make no changes: <pre><code>rsync -a --verbose --dryrun --stats /local1 /other2\n</code></pre></p> <p>Only copy files ending in \".txt\" <pre><code>rsync -avz --include='*.txt' /src /dest\n</code></pre></p> <p>A good combination. <pre><code>rsync -avhAXH --progress --numeric-ids --sparse --one-file-system --stats --delete-after\n</code></pre></p>"},{"location":"files/copying-files/#rsync-flags-you-may-want-to-use","title":"Rsync Flags You May Want To Use","text":"<p>Rsync is very flexible. The manual page is long. Here are some useful arguments to know about, organized somewhat by purpose. </p> <p>Most flags have two forms you can choose between, a short one consisting of a single character, or a readable form preceeded by two hyphens, and typically followed by an equals sign and a value. <pre><code>--archive, -a            archive mode; equals -rlptgoD (no -H,-A,-X)\n\n--acls, -A               preserve ACLs (implies --perms)\n--xattrs, -X             preserve extended attributes\n--hard-links, -H                       preserve hard links\n\n--exclude-from={'list.txt'}.        there is a corresponding --include-from\n--exclude={'*.txt','dir3','dir4'}   there is a corresponding --include\n\n--dry-run, -n            perform a trial run with no changes made\n--list-only              list the files instead of copying them\n--ignore-existing        don't overwrite existing files, no matter what\n--max-delete=NUM         don't delete more than NUM files (SET TO 0 OR LOW NUMBER FOR SAFETY)\n--one-file-system, -x    ensure that you stay inside the SRC file system \n\n--atimes -U              preserve access (use) times\n--crtimes, -N            preserve create times (newness)\n--times, -t              preserve modification times\n\n--numeric-ids            don't map uid/gid values by user/group name (more efficient)\n--delete-after           wait until end to process deletes (much more efficient than deleting during)\n--partial                allows you to resume an interrupted transfer\n\n--progress               show which file is being copied (not stored in log file!!)\n--itemize-changes, -i    output a change-summary for all updates \n                         has complex output. (see below for a link)\n--log-file=FILE          useful when using --itemize\n--verbose, -v            increase verbosity\n--info=FLAGS             fine-grained informational verbosity\n--human-readable, -h     output numbers in a human-readable format\n--stats                  provide statistics at the end\n\n--size-only              skip files that match in size (know what you're doing)\n--ignore-times, -I       don't skip files that match size and time (when in doubt...)\n--checksum -c            skip based on checksums, not mod-time &amp; size\n\n--sparse                 turn sequences of nulls into sparse blocks\n--bwlimit                limit the impact of the rsync on the network (in kb/sec)\n\n--chmod=CHMOD            affect file and/or directory permissions\n--usermap=STRING         custom username mapping \n--groupmap=STRING        custom groupname mapping (STRING is not simply\n--chown=USER:GROUP       simple username/groupname mapping \n</code></pre></p> <p>The <code>--itemize-changes</code> flag is especially helpful when trying to compare two directory trees. However, it produces a cryptic string for each file or directory. We have copied a useful chart from the Internet that you can consult. See this page</p>"},{"location":"files/copying-files/#archive-tools-moving-data-through-a-pipe","title":"Archive tools moving data through a pipe","text":"<p>Rsync is usually the best method. But rsync wasn't always available in the past, or it didn't support copying one or another attribute that more basic tools did.  Different kinds of file permissions, data forks, etc.</p> <p>One method that can be quick and effective is to use an archive program like tar to create an archive file which is passed through an input/output pipe to the same program running in another directory that extracts files into that location. This technique can use available system memory as buffer space, leading to smoother flows of data as disk reads and writes occur with optimal amounts of bytes.</p> <p>This example copies the named directory some-directory from the current working directory to another location. Because tar by default works with blocks of data 512 bytes in size, a higher efficiency is achieved by telling it to create larger blocks to reduce the overhead of doing input/output requests in such small sizes.</p> <p><pre><code>tar -cbf 20480 - some-directory | (cd /destination/place; tar -xbf 20480 -)\n</code></pre> This example extends the technique to copying the data off of your current host to another host: <pre><code>tar -cbf 20480 - some-directory | ssh myaccount@another-host (cd /destination/place; tar -xbf 20480 -)\"\n</code></pre></p>"},{"location":"files/data-security/","title":"Data Security","text":"<p>This is a stub page for the \"Managing Files\" topic.</p> <p>Authoring Note</p> <p>What should users keep in mind about providing the appropriate amount of protection to their data files? (Also, should we have a document that points to outside guides to data management lifecycles? Case Western Reserve has good documentation.)</p> <p>Information about satisfying HIPAA standards can be found here.</p>","tags":["needs-to-be-written"]},{"location":"files/files-overview/","title":"MANAGING FILES","text":"<p>We spend a lot of our time manipulating files.  This document attempts to provide an overview of, and pointers to, useful knowledge.</p>","tags":["topic-overview","in-progress","jeffrey"]},{"location":"files/files-overview/#overview","title":"Overview","text":"<p>General info about where files of different types live (should live). Pointers to existing info over in the Storage topic. Reminder about what is backed up and what is not.</p>","tags":["topic-overview","in-progress","jeffrey"]},{"location":"files/files-overview/#sharing-files-with-other-users","title":"Sharing files with other users","text":"<p>Collaborating with others is a daily activity on the cluster. There are better -- and worse -- ways to do that.</p>","tags":["topic-overview","in-progress","jeffrey"]},{"location":"files/files-overview/#normal-unix-file-ownership-and-permissions","title":"Normal UNIX file ownership and permissions","text":"<p>Brief overview of how things work and how to inspect.</p> <p>UNIX groups.</p> <p>If nothing else, a pointer to other web pages (ours or on the Internet).</p>","tags":["topic-overview","in-progress","jeffrey"]},{"location":"files/files-overview/#home-directory","title":"Home Directory","text":"<p>What are the default settings and why are they important?</p>","tags":["topic-overview","in-progress","jeffrey"]},{"location":"files/files-overview/#project-storage","title":"Project storage","text":"<p>What are the default settings and why are they important?</p> <p>What are common variations?</p>","tags":["topic-overview","in-progress","jeffrey"]},{"location":"files/files-overview/#using-acls-to-allow-increased-access","title":"Using ACL's to allow increased access","text":"<p>Traditional Unix file ownership and permissions can be used to share access to files and directories. However, there can be times when more fine-grained control of access is needed. To accomplish this, Access Control Lists (ACLs) can be used. They add to or extend the normal permissions.</p> <p>We have a good document about how to use ACLs here.</p>","tags":["topic-overview","in-progress","jeffrey"]},{"location":"files/files-overview/#transferring-files-into-and-out-of-the-cluster","title":"Transferring files into and out of the cluster","text":"<p>A variety of tools exist for this task. We have documented many of them in this document.</p> <p>Before moving large amounts of data in or out, you may want to consolidate it into fewer files using archive tools. We have documented some of the relevant considerations in this document.</p> <p>For transferring files to and from the cluster, you should use <code>jhpce-transfer01.jhsph.edu</code> rather than a login node. This is both significantly faster, as the transfer node has a 40G Ethernet connection to the outside world while the login nodes have 10G connections. In any case, EVERYONE depends on the login nodes, and you should not run ANYTHING on them that occupies them.</p>","tags":["topic-overview","in-progress","jeffrey"]},{"location":"files/files-overview/#accessing-data-from-compute-nodes","title":"Accessing data from compute nodes","text":"<p>Consider your input/output needs for computations. Which storage location and type provides the best combination of speed, capacity and proximity to CPUs?</p> <p>There may well be different answers for different kinds of files used during your work.</p> <p>Should you stage your data to the fastscratch file system?</p> <p>Should you stage the data locally to the compute nodes or access it over the network? Compute nodes only have local storage in their /tmp file systems. Everyone else using a node needs to share that space. The operating system of the node itself needs there to be some free space in /tmp.</p> <p>There is a SLURM command which can copy data to assigned nodes. See the sbcast manual page.</p>","tags":["topic-overview","in-progress","jeffrey"]},{"location":"files/files-overview/#copying-data-around-within-cluster","title":"Copying Data Around Within Cluster","text":"<p>Alternatives to copying (sharing via ACL, using symbolic links).</p> <p>Do it on compute nodes.</p> <p>Example batch jobs for doing so.</p> <p>Rsync argument recommendations.</p>","tags":["topic-overview","in-progress","jeffrey"]},{"location":"files/files-overview/#best-practices","title":"Best Practices","text":"<p>Think before hitting Enter. Think again. There are few substitutes.</p> <p>Check beforehand that there will be sufficient space in destination before trying to import or create data or copy it around.</p> <p>We protect home directories and project space with redundant arrays of disks. Some of our file systems are backed up daily to other locations. But ultimately you need to ensure that you have backups elsewhere of precious files. Consider creating a GitHub repo to hold programming code -- it represents a lot of effort.</p> <p>Don't bother compressing files in most cases because we have enabled compression on our ZFS file systems. </p> <p>Archiving old or infrequently-used files can be a good idea. It speeds up directory access (less metadata in directories). It simplifies transferring bulk data and checking on the success or failure.</p>","tags":["topic-overview","in-progress","jeffrey"]},{"location":"files/files-overview/#backups-and-restores","title":"Backups and Restores","text":"<p>Home directories are backed up once a day. Users can access the last fourteen days of data themselves. Primary Investigators can request that we back up project spaces. Only a few have done so.</p> <p>Further information about this topic can be found in this document</p>","tags":["topic-overview","in-progress","jeffrey"]},{"location":"files/files-overview/#data-protection-policies","title":"Data Protection Policies","text":"<p>We will be publishing information  about cluster and university policies for the protection of certain classes of information in this document. </p>","tags":["topic-overview","in-progress","jeffrey"]},{"location":"files/files-stub/","title":"stub page for the \"Managing Files\" topic","text":"<p>This is a stub page for the \"Managing Files\" topic.</p> <p>Create a new file with the right contents for the topic header in the nav bar. Then point that header to the new document instead of \"files/files-stub.md\"</p>"},{"location":"files/rsync-itemize-manpage/","title":"Rsync itemized output manual page section","text":"<pre><code>The  \"%i\"  escape  has a cryptic output that is 11 letters long.\nThe general format is like the string YXcstpoguax,  where  Y  is\nreplaced  by the type of update being done, X is replaced by the\nfile-type, and the other letters represent attributes  that  may\nbe output if they are being modified.\n\nThe update types that replace the Y are as follows:\n\no      A  &lt; means that a file is being transferred to the remote\n       host (sent).\n\no      A &gt; means that a file is being transferred to  the  local\n       host (received).\n\no      A  c  means that a local change/creation is occurring for\n       the item (such as the creation  of  a  directory  or  the\n       changing of a symlink, etc.).\n\no      A  h  means  that the item is a hard link to another item\n       (requires --hard-links).\n\no      A . means that the item is not being updated  (though  it\n       might have attributes that are being modified).\n\no      A  * means that the rest of the itemized-output area con\u2010\n       tains a message (e.g. \"deleting\").\n\nThe file-types that replace the X are: f for a file, a d  for  a\ndirectory,  an  L for a symlink, a D for a device, and a S for a\nspecial file (e.g. named sockets and fifos).\n\nThe other letters in the string indicate if some  attributes  of\nthe file have changed, as follows:\n\no      \".\" - the attribute is unchanged.\n\no      \"+\" - the file is newly created.\n\no      \" \"  - all the attributes are unchanged (all dots turn to\n       spaces).\n\no      \"?\" - the change is unknown (when  the  remote  rsync  is\n       old).\n\no      A letter indicates an attribute is being updated.\n\nThe attribute that is associated with each letter is as follows:\n\no      A  c  means  either  that  a regular file has a different\n       checksum (requires --checksum) or that a symlink, device,\n       or  special  file  has a changed value.  Note that if you\n       are sending files to an rsync prior to 3.0.1, this change\n       flag  will be present only for checksum-differing regular\n       files.\n\no      A s means the size of a regular  file  is  different  and\n       will be updated by the file transfer.\n\no      A t means the modification time is different and is being\n       updated to the sender's value (requires --times).  An al\u2010\n       ternate  value of T means that the modification time will\n       be set  to  the  transfer  time,  which  happens  when  a\n       file/symlink/device is updated without --times and when a\n       symlink is changed and the receiver can't set  its  time.\n       (Note:  when  using  an rsync 3.0.0 client, you might see\n       the s flag combined with t instead of the proper  T  flag\n       for this time-setting failure.)\n\no      A p means the permissions are different and are being up\u2010\n       dated to the sender's value (requires --perms).\n\no      An o means the owner is different and is being updated to\n       the sender's value (requires --owner and super-user priv\u2010\n       ileges).\n\no      A g means the group is different and is being updated  to\n       the sender's value (requires --group and the authority to\n       set the group).\n\no      A u|n|b indicates the following information: u  means the\n       access  (use)  time  is different and is being updated to\n       the sender's value (requires --atimes); n means the  cre\u2010\n       ate  time  (newness) is different and is being updated to\n       the sender's value (requires  --crtimes);  b  means  that\n       both the access and create times are being updated.\n\no      The a means that the ACL information is being changed.\n\no      The  x  means  that the extended attribute information is\n       being changed.\n\nOne other output is possible: when deleting files, the \"%i\" will output  the  string  \"*deleting\" for each item that is being removed (assuming that you are talking to a  recent  enough  rsync that  it  logs deletions instead of outputting them as a verbose message).\n</code></pre>"},{"location":"files/rsync-itemize-table/","title":"Meaning of rsync itemized output","text":"<p>The <code>--itemize-changes</code> flag is especially helpful when trying to compare two directory trees. However, it produces a cryptic string 11 letters long for each file or directory. We have copied a useful chart from the Internet that you can consult.</p> <p>There is also a copy of the section of the rsync manual page here breaking this down further.</p> <p>The general format is like the string YXcstpoguax, where  Y  is replaced  by the type of update being done, X is replaced by the file-type, and the other letters represent attributes that may be output if they are being modified.</p> <pre><code>  YXcstpoguax  path/to/file\n  |||||||||||\n  `----------- the type of update being done::\n   ||||||||||   &lt;: file is being transferred to the remote host (sent).\n   ||||||||||   &gt;: file is being transferred to the local host (received).\n   ||||||||||   c: local change/creation for the item, such as:\n   ||||||||||      - the creation of a directory\n   ||||||||||      - the changing of a symlink,\n   ||||||||||      - etc.\n   ||||||||||   h: the item is a hard link to another item (requires\n  --hard-links).\n   ||||||||||   .: the item is not being updated (though it might have attributes\n  that are being modified).\n   ||||||||||   *: means that the rest of the itemized-output area contains a\n  message (e.g. \"deleting\").\n   ||||||||||\n   `---------- the file type:\n    |||||||||   f for a file,\n    |||||||||   d for a directory,\n    |||||||||   L for a symlink,\n    |||||||||   D for a device,\n    |||||||||   S for a special file (e.g. named sockets and fifos).\n    |||||||||\n    `--------- c: different checksum (for regular files)\n     ||||||||     changed value (for symlink, device, and special file)\n     `-------- s: Size is different\n      `------- t: Modification time is different\n       `------ p: Permission are different\n        `----- o: Owner is different\n         `---- g: Group is different\n          `--- u: The u slot is reserved for future use.\n           `-- a: The ACL information changed\n</code></pre>"},{"location":"files/sharing-files/","title":"Sharing Files","text":"<p>How do you safely collaborate with others in a UNIX environment in an on-going basis?</p> <p>There are different locations where you can store files for the long term. The correct location to store files depends on several factors, including their size, how private they are, whether other users should be able to read or write them, and whether they should remain for your group after you have gone to another organization.</p> <p>Traditional Unix file and group permissions can be used to share access to files and directories.  However, there can be times when more fine-grained control of shared access is needed. To accomplish this, Access Control Lists (ACLs) can be used. They add to the normal permissions.</p> <p>Tip</p> <p>Before defining ACLs, you should first read this document for necessary background concepts and skills. Our document about ACLs is here.</p>","tags":["in-progress","jeffrey"]},{"location":"files/sharing-files/#unix-ownership-permissions","title":"UNIX Ownership &amp; Permissions","text":"<p>You must understand the basics of file ownership and permissions to successfully share files. </p> <p>The Wikipedia has a fairly good description of normal UNIX file and group permissions, including the symbolic and numeric notation schemes.</p> <p>Here are some other tutorials you can read:</p> <ul> <li>https://docs.nersc.gov/filesystems/unix-file-permissions/</li> <li>https://www.tutorialspoint.com/unix/unix-file-permission.htm</li> <li>https://www.redhat.com/sysadmin/linux-file-permissions-explained</li> <li>https://kb.iu.edu/d/abdb</li> </ul>","tags":["in-progress","jeffrey"]},{"location":"files/sharing-files/#important-concepts","title":"Important Concepts","text":"<p>Out of the basic information on this topic, these are some particular details you should understand. </p> umask umask is a variable which controls the permissions assigned to files and directories that you create. You have a default umask, which can be changed for future logins if you change your <code>.bashrc</code> file. You can change the current umask at any time before you do run some commands. More guidance is included later in this document. The Wikipedia page for umask is helpful.  re-use of permission bits There are nine basic permission bits for files and directories. Three each for owner, group, and other. As UNIX developed and new capabilities were needed, the authors added one more bit (used for setuid and setgid), then started adding multiple meanings to some bits. This is shown by the letter (and its capitalization) used to represent it in the output of the <code>ls -l</code> command. read and execute bits on directories The role of the read and execute bits on directories is somewhat different than that on files.  A directory is essentially a special kind of file, containing details about its contents. So you need to be able to read the directory in order to list its contents. On a directory, the execute bit means \"search\" or \"traverse\" Users must have appropriate permissions on ALL of the parts of a path needed to reach a final file or directory. They don't need to be able to modify all of the parent directories, but they have to be able to descend through the tree of directories. /dcs07/somegroup/data/src/compile.py An example absolute path composed of four directories and a file. You cannot read the file unless the four directories and the file have appropriate permissions and group memberships. You can only modify the file if you have write permission on it. You can create other files in the same directory only if the <code>src</code> directory has the necessary writable bit enabled.","tags":["in-progress","jeffrey"]},{"location":"files/sharing-files/#unix-commands-to-know","title":"UNIX Commands To Know","text":"<p>You can learn more about these commands by reading their manual page. You can run the command <code>man command-name</code> to read it locally. Tips for reading manual pages can be found in this PDF document.</p> <p>Only some of the arguments needed are shown in this table.</p> Command Description Notes ls -l List file details Lists both files &amp; dirs ls -ld List dir details <code>-d</code> option says not to list contents of dir umask Display or change umask See footnote<sup>1</sup> id Display your user &amp; grp Specify another user to see their info chmod Change permissions use <code>-R</code> option for recursion chgrp Change grp of file or dir use <code>-R</code> option for recursion chown Change owner of file or dir Ask sysadmins to change ownership newgrp - Create new shell with different group the hyphen option is useful sg Execute cmd with different grp mkdir Make a directory You can make a tree of new dirs with <code>-p newdir1/subdir1/subdir2</code> rmdir Remove an empty directory Use <code>/bin/rm -rf</code> to delete non-empty dirs <p>(To keep table size down, we used abbrieviations: dir for directories, grp for groups, cmd for command.)</p>","tags":["in-progress","jeffrey"]},{"location":"files/sharing-files/#access-control-lists-acls","title":"Access Control Lists - ACLs","text":"<p>Sometimes you want to give access to an individual or a group in ways that the traditional UNIX permissions and ownership model do not allow. You can use an ACL to grant those permissions, including </p> <p>See this document for details on how to do this.</p>","tags":["in-progress","jeffrey"]},{"location":"files/sharing-files/#where-to-share","title":"Where to share?","text":"","tags":["in-progress","jeffrey"]},{"location":"files/sharing-files/#project-space","title":"Project Space","text":"<p>The best place for long-term sharing of files, and the only place to share any significant volume of files, is in file systems created for research groups who purchase allocations of one of our storage servers.</p> <p>If your need is temporary or you cannot purchase your own space, you might be able to secure permission from an existing owner to use their space. They will need to create a subdirectory within their allocation for you and change the permissions of the directories above that to allow you and your group to see into those directories. We are happy to create a new UNIX group so you can use it in your permissions scheme. Send the request with the desired group name and a list of member usernames to bitsupport.</p>","tags":["in-progress","jeffrey"]},{"location":"files/sharing-files/#home-directory","title":"Home Directory","text":"<p>Everyone has a home directory. By default this is a private space. Things like SSH can break if the permissions on the home directory are set incorrectly.</p> <p>You don't want to open up your home directory to everyone in the cluster by making your home directory group or world readable or writable. By default all users belong to the same group. It's not just that people you like and trust can see your files -- so can hackers if they get access to anyone's account. Your configuration files reveal details about your account, your accounts elsewhere and, if writable, allow hackers to set traps so they can become you. Then possibly access your home or other computers.</p> <p>If you must use your home directory, please use ACLs to give specific access to specific people. We have written an ACL document to guide you. We are happy to create a new UNIX group so you can use it in your permissions scheme. Send the request with the desired group name and a list of member usernames to bitsupport.</p>","tags":["in-progress","jeffrey"]},{"location":"files/sharing-files/#scratch-space","title":"Scratch Space","text":"<p>If you need to briefly share some files with someone and they are too large to send via email (say 5MB), you might consider placing them in shared scratch space. This is not recommended, but we want you to be informed about this choice before you make it.</p> <p>If you and your recipient are members of some common group other than the default, it is best to make your temporary directory group readable and searchable but remove access for \"other\".</p> /tmp An acceptable place for a quick one-time exchange of small files which don't contain protected info IF YOU ARE CAREFUL. This directory is world-readable and writable. A prime consideration is whether there is enough room in /tmp for your purpose. The operating system and other users depend on there ALWAYS being enough free space in this file system. Delete your files ASAP after the exchange. /fastscratch An acceptable place for exchanging larger files, but not for sharing over times longer than, say, a week. Everyone has a 1TB quota on this fast file system, but there is only 22TB of space. This space is meant to enable fast access to data read or written by jobs on the compute nodes. Files older than 30 days are deleted automatically. This document describes this file system in more detail.","tags":["in-progress","jeffrey"]},{"location":"files/sharing-files/#group-writable-directories","title":"Group Writable Directories","text":"<p>Authoring Note</p> <p>Most remaining work on this page lies below this point. Above here what is missing is mainly some example command output.</p> <p>Every file or directory has an owner and a group. Every user has a primary group, and can belong to one or more secondary groups.</p>","tags":["in-progress","jeffrey"]},{"location":"files/sharing-files/#group-sticky-bit","title":"Group sticky bit","text":"<p>When you want to make a directory tree group writable but also configure the SGID bit on directories, you cannot use a simple recursive chmod command. Because that will apply the same permission to both files and directories.</p> <p>These commands are examples of how you can recursively set correct permissions. They use the <code>find</code> command to print path names to directories or files, then pass those to xargs to execute the given commands upon.  </p> <pre><code>cd into-the-top-of-the-directory-tree\nfind . -type d | xargs chmod u+rwx,g+rwx,g+s,o-rwx\nfind . -type f | xargs chmod u+rwx,g+rw,o-rwx\n</code></pre>","tags":["in-progress","jeffrey"]},{"location":"files/sharing-files/#creating-a-group-writable-directory","title":"Creating A Group Writable Directory","text":"<p>Raw Material Here</p> <p>The following needs to be rewritten. It was sent as email to a user.</p> <p>The list command, ls, is crucial to figuring out what is possible, where. The long argument, -l, will show you ownership and permission information, as seen in my previous email. Sometimes you also want to use the -d argument to tell ls that you want to see the information about a directory and not what is inside it.</p> <p>So using ls -l  on /users/shared/55548/ will show you that many subdirectories are not group writable. Your failed efforts involve trying to create files or directories inside of directories that are group readable and searchable and sticky but not writable.</p> <p>Every directory in a path to the destination needs to have suitable permissions. Readability: every directory in the path /users/55548/shared/MA_switching needs to be readable by for you to be able to list its contents. Writability: only the last directory in the path needs to be writable for you to be able to modify its contents.</p> <pre><code>jhpcecms01:/users/55548/shared# ls -l\ndrwxrwsrwx  7 c-jlevy33-55548  c-55548  7 Dec  5 11:10 biosim_leverage/\ndrwxr-s---  3 c-eblasco1-55548 c-55548  3 Feb  1 14:00 c-eblasco1-55548/\ndrwxr-s---  7 c-tbrow261-10201 c-55548  9 Dec 20 12:17 Elixhauser/\ndrwxr-s---  3 c-ttotoja1-55548 c-55548  3 Feb 16 16:09 forOwen/\ndrwxrwxr-x 16 c-jxu123-10201   c-55548 22 Jul 15  2023 from-yoda/\ndrwxrwsrwx  7 c-jlevy33-55548  c-55548  7 Feb  7 10:54 hipfracture_adrd/\ndrwxr-s---  7 c-jlevy33-55548  c-55548  7 Dec 20 14:03 levy_partd/\ndrwxr-s---  2 c-aliu63-55548   c-55548  6 Feb 19 16:39 MA_partB/\ndrwxr-s---  2 c-aliu63-55548   c-55548  5 Dec 15 14:03 MA_switching/\ndrwxr-s--- 10 c-rwu32-55548    c-55548 13 Nov  8 10:31 mltss_duals/\ndrwxrws---  4 c-yyang279-55548 c-55548  4 Nov 30 10:13 shen_yang/\ndrwxr-s---  2 c-ykuang6-55548  c-55548  4 Jan 30 12:13 test/\ndrwxr-s---  2 c-jlevy33-55548  c-55548  3 Aug 29 15:19 toofull/\n</code></pre> <p>Only the owner of a directory can change its permissions. So in this case c-aliu63-55548 needs to change the permissions on MA_switching to make it group writable. This command run by them would change the directory: <code>chmod g+w /users/55548/shared/MA_Switching</code> This command run by them would change the directory and everything within it using the recursive flag: <code>chmod -R g+w /users/55548/shared/MA_Switching</code></p> <p>Why are files and directories created with the permissions that they get? A key factor here is the \u201cumask\u201d setting in the user\u2019s environment when files and directories are being created. The command \u201cumask -S\u201d will show you the permissions that will be used for new files and directories. Here you see an example of my inspecting the contents of my umask setting and then changing it to make it such that when I create a file it will be group-writable. If you want such a setting to be used in the future for all of your logins, you would add a line to the bottom of your .bashrc file in your home directory.</p> <p>jhpcecms01:/users/55548/shared# umask -S u=rwx,g=rx,o=rx jhpcecms01:/users/55548/shared# umask u=rwx,g=rwx,o=rx jhpcecms01:/users/55548/shared# umask -S u=rwx,g=rwx,o=rx</p> <p>Many of the people modifying files in the shared directory may want to adjust the permissions of existing files and directories, and change their umask values. If they want directory trees to be group writable and new files or directories to be the same. Or some other set of permissions. Not everything within the shared directory needs to be shared with every other user of the DUA.</p> <ol> <li> <p>There are 2 versions, one built into bash and a standalone one /usr/bin/umask. The latter has a <code>-S</code> option which displays permissions in a more readable fashion. The built-in only works with octal digits. To see the umask manual page which supports -S, use the command <code>man 1p umask</code> To use this version of the umask command, you need to specify the full path to it (/usr/bin/umask) instead of <code>umask</code>.\u00a0\u21a9</p> </li> </ol>","tags":["in-progress","jeffrey"]},{"location":"gpu/gpu-overview/","title":"GPU Critical Knowledge","text":"","tags":["topic-overview","needs-to-be-written","refers-to-old-website","gpu","mark"]},{"location":"gpu/gpu-overview/#overview-or-everything-in-one-document","title":"Overview or Everything in One Document??","text":"<p>Should this be an overview? JRT thinks so, because he envisions a growing number of GPU-related documents instead of one massively long document. </p> <p>Therefore should it be moved out of \"User Guides\" to be a topic inside of \"Software\"?</p>","tags":["topic-overview","needs-to-be-written","refers-to-old-website","gpu","mark"]},{"location":"gpu/gpu-overview/#migrate-previous-web-site-document","title":"MIGRATE PREVIOUS WEB SITE DOCUMENT","text":"<p>Probably put some of it here, some of it into other document(s)</p> <p>https://jhpce.jhu.edu/knowledge-base/gpus-on-the-jhpce-cluster</p>","tags":["topic-overview","needs-to-be-written","refers-to-old-website","gpu","mark"]},{"location":"gpu/gpu-overview/#our-gpu-nodes","title":"Our GPU Nodes","text":"<p>Differentiate between public and PI partitions.</p> <p>We have a table showing their resources, and partition names.</p> <p>This command will show you the current use of GPU resources: <code>slurmpic -g</code></p>","tags":["topic-overview","needs-to-be-written","refers-to-old-website","gpu","mark"]},{"location":"gpu/gpu-overview/#using-them","title":"Using them","text":"<p>Dos and don'ts.</p> <p>Is it all interactive? If not, provide some example batch job files.</p> <p>Mark has written material and sent it to various people. Combine that with perhaps info from this Tensorflow sample document</p> <p>Look for other resources out there containing advice about using GPUs in a SLURM context.</p>","tags":["topic-overview","needs-to-be-written","refers-to-old-website","gpu","mark"]},{"location":"gpu/gpu-overview/#existing-docs-at-other-sites","title":"Existing docs at other sites","text":"<p>Warning</p> <p>These other clusters have different software and policies. Look for useful information but don't expect what they say/do to work here.</p> <p>USC: USC documentation</p> <p>New Mexico State Univ: their page</p> <p>UMich section showing relevant SLURM directives for GPU use</p> <p>Yale has CUDA, tensorflow and miniconda modules while we do not. Useful? PyTorch install instructions.</p>","tags":["topic-overview","needs-to-be-written","refers-to-old-website","gpu","mark"]},{"location":"gpu/gpu-overview/#application-specific-advice","title":"Application-specific advice","text":"<p>Authoring Note</p> <p>JRT added this info here but believes it should be migrated out of the \"GPU Overview\" document to somewhere else.</p>","tags":["topic-overview","needs-to-be-written","refers-to-old-website","gpu","mark"]},{"location":"gpu/gpu-overview/#alphafold","title":"Alphafold","text":"<pre><code>$ module load alphafold/4.3.1\n$ srun --pty --x11 --mem=100G --cpus-per-task=8 --partition gpu --gpus=1 bash\n[compute-123]$ module load alphafold\n(alphafold-gpu) [compute-123]$ run_alphafold.sh -d /legacy/alphafold/data -f ./test.fasta -o . -t 2020-05-14 -n 8\n</code></pre>","tags":["topic-overview","needs-to-be-written","refers-to-old-website","gpu","mark"]},{"location":"gpu/gpu-overview/#tensorflow","title":"Tensorflow","text":"","tags":["topic-overview","needs-to-be-written","refers-to-old-website","gpu","mark"]},{"location":"help/cost-calculator/","title":"Cost Calculator","text":"<p>Should this document be renamed to something more general, like Billing or The Cost of Computing?</p> <p>PULL MATERIAL IN FROM EXISTING WEB SITE POLICIES PAGE</p>","tags":["needs-to-be-written","mark"]},{"location":"help/cost-calculator/#why","title":"Why?","text":"","tags":["needs-to-be-written","mark"]},{"location":"help/cost-calculator/#billing-process","title":"Billing Process","text":"","tags":["needs-to-be-written","mark"]},{"location":"help/cost-calculator/#how-do-we-calculate-charges","title":"How do we calculate charges?","text":"<p>Requested not used, except for duration.</p> <p>CPU requested</p> <p>RAM requested</p> <p>Job duration</p>","tags":["needs-to-be-written","mark"]},{"location":"help/cost-calculator/#if-something-changes","title":"If something changes","text":"<p>Who to contact with what information?</p> <ul> <li>People leave</li> <li>People work for different PIs</li> <li>People work for multiple PIs</li> <li>PIs leave</li> </ul>","tags":["needs-to-be-written","mark"]},{"location":"help/cost-calculator/#cost-calculator_1","title":"Cost Calculator","text":"<p>Are we going to create a form? Or just give some examples?</p>","tags":["needs-to-be-written","mark"]},{"location":"help/cost-calculator/#seeing-your-past-usage","title":"Seeing Your Past Usage","text":"<p>The sacct command is used to view information about completed jobs. Here is our sacct document with tips for using that command.</p>","tags":["needs-to-be-written","mark"]},{"location":"help/external/","title":"External Guides","text":"<p>The World Wide Web has been of incalculable benefit to humanity. We owe Sir Tim Berners-Lee an enormous debt of gratitude.</p> <p>Tip</p> <p>If you have suggestions for this page, please send the link(s) and your reasons for nominating it/them to bitsupport.</p>","tags":["in-progress","jeffrey"]},{"location":"help/external/#caveat-emptor","title":"CAVEAT EMPTOR","text":"<p>You need to consider whether what you're reading on an external web site applies to JHPCE. Policies and practices differ between clusters, as does available software and their versions.  Don't copy-and-paste blindly. Nonetheless, there is a wealth of information out there that you can apply to your work.</p>","tags":["in-progress","jeffrey"]},{"location":"help/external/#slurm-web-sites-of-note","title":"SLURM Web Sites of Note","text":"<p>We are accumulating this information on this page.</p> <p>We also have a document with links to not only the vendor's documentation for each common command, but also pages we've written with advice and examples for some important commands.</p>","tags":["in-progress","jeffrey"]},{"location":"help/external/#user-tutorials","title":"User tutorials","text":"<ul> <li>R/Bioconductor-powered Team Data Science - this site has a wealth of information for improving your data science and teamwork skills. A real gem for people new to the field!</li> <li>Lieber Institute RStats club</li> <li>Leo Collado Torres YouTube Channel including JHPCE playlist - note that the JHPCE playlist starts off with videos featuring the Sung Grid Engine job scheduler, which has been replaced by SLURM in 2023. The data science contents of the SGE-containing videos may still be of interest.</li> <li>Lieber Institute module config and Lieber Institute module source code - Lieber has generously built and maintains many software modules for JHPCE users</li> </ul>","tags":["in-progress","jeffrey"]},{"location":"help/external/#jhpce-tutorials","title":"JHPCE Tutorials","text":"<ul> <li>JHPCE 3.0 Orientation Slides -- SLURM scheduler &amp; Rocky 9</li> <li>C-SUB JHPCE Orientation Slides 2023</li> </ul>","tags":["in-progress","jeffrey"]},{"location":"help/external/#obsolete","title":"Obsolete","text":"<p>JHPCE 2.0 Orientation Slides -- 2023 -- Sun Grid Engine</p>","tags":["in-progress","jeffrey"]},{"location":"help/faq-old/","title":"FAQ","text":"<p>There is a dedicated SLURM FAQ document.</p>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#why-does-bash-report-that-it-cant-find-the-module-command","title":"Why does bash report that it can\u2019t find the module command?","text":"Click to expand answer <p>If you receive a message like</p> <pre><code>bash: module: command not found\n</code></pre> <p>The module is a shell function that is declared in <code>/etc/bashrc</code>. It is always a good idea for <code>/etc/bashrc</code> to be sourced immediately in you <code>~/.bashrc</code>.  Edit your <code>.bashrc</code> file so that the first thing it does is o execute the system bashrc file, i.e. your <code>.bashrc</code> file should start with the following lines:</p> <pre><code>if [ -f /etc/bashrc ]; then\n. /etc/bashrc\nfi\n</code></pre>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#my-script-is-giving-odd-error-messages-about-r-or-m","title":"My script is giving odd error messages about <code>\\r</code> or <code>^M</code>.","text":"Click to expand answer <p>Windows and Unix use different characters to indicate a new line.  If you have uploaded your script from a Windows machine, it may have the Windows newline characters.  These need to be replaced by the Unix newline characters.  To do this, you can run the \u201cdos2unix\u201d command on your script <code>dos2unix myscript.sh</code>. This will strip out all of the Windows newlines and replace them with the Unix newlines.</p>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#what-is-the-safe-desktop","title":"What is the SAFE desktop?","text":"Click to expand answer <p>The SAFE desktop is a virtual Windows computer that you can use to run scientific software and access JHPCE. For more information see this item.</p>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#ssh-bad-owner-or-permissions","title":"SSH \"Bad owner or permissions\"","text":"Click to expand answer <p>If you receive a message like \"Bad owner or permissions on ~/.ssh/config\" or continue to have to provide your password when ssh'ing to JHPCE when you think you have configured things to not need one, your file owner or permissions may be incorrect. See this document for answers.</p>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#im-getting-x11-errors-when-using-rstudio-with-putty-and-xming","title":"I\u2019m getting X11 errors when using rstudio with Putty and Xming","text":"<p>Obsolete</p> <p>As of 20240220 vcxsrv is not installed on the cluster. This FAQ item needs to be reviewed and probably removed. JRT</p> <p>We\u2019ve had issues reported by users of Putty with Xming. One solution we\u2019ve found is to use the (vcxsrv))[https://sourceforge.net/projects/vcxsrv/] instead Xming newlines.  (This commmand is on all nodes.)</p>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#how-can-i-add-packages-into-emacs-on-the-cluster","title":"How can I add packages into emacs on the cluster?","text":"<p>Make sure to <code>module load emacs</code> to get a later version of emacs. Then one needs to edit their <code>.emacs</code> file in their home director to include the package repos     <pre><code>(require 'use-package)\n(add-to-list 'package-archives '(\"gnu\" . \"http://elpa.gnu.org/packages/\") t)\n(add-to-list 'package-archives '(\"melpa\" . \"http://melpa.org/packages/\") t)\n</code></pre>     After restaring emacs then one can do <code>M-x package-list-packages</code> and follow the GUI.</p>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#xauth-error-messages-from-macos-sierra-when-using-x11-forwarding-in-ssh","title":"Xauth error messages from MacOS Sierra when using X11 forwarding in SSH","text":"<p>With the upgrade to MacOS Sierra, the \u201c-X\u201d option to ssh to enable X11 forwarding may not work.  If you receive the message: <code>untrusted X11 forwarding setup failed: xauth key data not generated</code> , you can resolve the issue by add the line <code>ForwardX11Trusted yes</code> to your <code>~/.ssh/config</code> file on your Mac. You may still see the warning: Warning: <code>No xauth data; using fake authentication data for X11 forwarding.</code> To eliminate this warning, add the line <code>XAuthLocation /usr/X11/bin/xauth</code> to your <code>~/.ssh/config</code> file on your Mac.</p>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#when-running-sas-an-error-dialog-pops-up-about-remote-browser","title":"When running SAS, an error dialog pops up about Remote Browser","text":"<p>When running SAS, you may need to specify options to indicate which browser to use when displaying either help or graphical output. We recommend using the Chromium browser.</p> <p>See our SAS usage document about how to resolve this issue.</p>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#im-on-a-mac-and-the-c-command-to-interrupt-an-ssh-session-isnt-working","title":"I\u2019m on a Mac, and the <code>~C</code> command to interrupt an ssh session isn\u2019t working","text":"<p>It used to, but I upgraded MacOS and now it does not work.*  Newer versions of MacOS have disabled by default the ability to send an SSH Escape with <code>~C</code> (~ Shift+C).  To reenable this, on you Mac, you need to set the <code>EnableEscapeCommandline</code> option.  You can do this by either running <code>ssh -o EnableEscapeCommandline=yes . . .</code> or by editing your <code>~/.ssh/config</code> file, and at the top of that file add the line:</p> <pre><code>EnableEscapeCommandline=yes\n</code></pre>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#how-do-i-get-the-rstudio-program-to-work-on-the-cluster","title":"How do I get the Rstudio program to work on the cluster?","text":"<p>See our core R support document about this and other R usage.</p>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#my-x11-forwarding-stops-working-after-20-minutes","title":"My X11 forwarding stops working after 20 minutes","text":"<p>This error comes from the <code>ForwardX11Timeout</code> variable, which is set by default to 20 minutes.  To avoid this issue, a larger timeout can be supplied on the command line to, say, 336 hours (2 weeks):</p> <pre><code>$ ssh -X username@jhpce01.jhsph.edu -o ForwardX11Timeout=336h\n</code></pre>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#how-do-i-copy-a-large-directory-structure-from-one-place-to-another","title":"How do I copy a large directory structure from one place to another.","text":"<p>Please do not copy or move anything except a small set of files on the login nodes.</p> <p>As an example, to copy a directory tree from <code>/home/bst/bob/src</code> to <code>/dcs07/bob/dst</code>, first, create a cluster script, let\u2019s call it <code>copy-job</code>, that contains the line <code>rsync -avzh /home/bst/bob/src/ /dcs07/bob/dst/</code>. Next, submit this script as a batch job to the cluster. An example SLURM batch job can be found here.</p>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#my-app-is-complaining-that-it-cant-find-a-shared-library-eg-libgfortranso1","title":"My app is complaining that it can\u2019t find a shared library, e.g. <code>libgfortran.so.1</code>","text":"<p>Nine times out of ten, the allegedly missing library is there. The problem is that your application is looking for the version of the library that is compatible with the old system software. It will not help to point your application to the new libraries. They are more than likely to be incompatible with the new system. The correct solution is to reinstall your software. If the problem persists after the reinstallation, then please contact us and we will install standard libraries that are actually missing.</p>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#ssh-gave-a-scary-warning-remote-host-identification-has-changed","title":"ssh gave a scary warning: <code>REMOTE HOST IDENTIFICATION HAS CHANGED</code>","text":"<p>Go into the <code>~/.ssh</code> directory of your laptop/desktop and edit the known_hosts file.  Search for the line that starts with the host that you ssh\u2019d to. Delete that line (it is probably a long line that wraps). Then try again</p>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#why-arent-slurm-commands-or-r-or-matlab-or-available-to-my-cron-job","title":"Why aren\u2019t SLURM commands, or R, or matlab, or\u2026 available to my cron job?","text":"<p>Authoring note</p> <p>This info needs to be re-written for upgraded cluster. And moved to the SLURM FAQ. Should the <code>scrontab</code> command be mentioned?</p> <p><code>cron</code> jobs are not launched from a login shell, but the module commands and the JHPCE default environment is initialized automatically only when you log in. Consequently, in a cron job, you have to do the initialization yourself. Do this by wrapping your cron job in a bash script that initializes the module command and then loads the default modules. You bash shell script should start with the following lines:</p> <pre><code>#!/bin/bash\n\n# Source the global bashrc\nif [ -f /etc/bashrc ]; then\n. /etc/bashrc\nfi\nmodule load JHPCE_DEFAULT_ENV\n</code></pre>","tags":["needs-review","in-progress"]},{"location":"help/faq-old/#ive-deleted-files-but-my-quota-hasnt-changed","title":"I've deleted files but my quota hasn't changed","text":"<p>See this document.</p>","tags":["needs-review","in-progress"]},{"location":"help/faq/","title":"FAQ","text":""},{"location":"help/faq/#compatibility","title":"Compatibility","text":"<ul> <li>My script is giving odd error messages about <code>\\r</code> or <code>^M</code>.</li> </ul> Click to expand answer <p>Windows and Unix use different characters to indicate a new line.  If you have uploaded your script from a Windows machine, it may have the Windows newline characters.  These need to be replaced by the Unix newline characters.  To do this, you can run the \u201cdos2unix\u201d command on your script <code>dos2unix myscript.sh</code>. This will strip out all of the Windows newlines and replace them with the Unix newlines.</p> <ul> <li>I\u2019m on a Mac, and the ~C command to interrupt an ssh session isn\u2019t working</li> </ul> Click to expand answer <p>New versions of MacOS have disabled the default ability to send an SSH Escape with <code>~C</code> (~ Shift+C). To reenable this, on you Mac, you need to set the <code>EnableEscapeCommandline</code> option. You can do this by either running <code>ssh -o EnableEscapeCommandline=yes . . .</code> or by editing your <code>~/.ssh/config</code> file, and at the top of that file add the line: <pre><code>EnableEscapeCommandline=yes\n</code></pre></p> <ul> <li>My app is complaining that it can\u2019t find a shared library, e.g. libgfortran.so.1</li> </ul> Click to expand answer <p>Nine times out of ten, the allegedly missing library is there. The problem is that your application is looking for the version of the library that is compatible with the old system software. It will not help to point your application to the new libraries. They are more than likely to be incompatible with the new system. The correct solution is to reinstall your software. If the problem persists after the reinstallation, then please contact us and we will install standard libraries that are actually missing.</p>"},{"location":"help/faq/#file-transfer","title":"File Transfer","text":"<ul> <li>How do I copy a large directory structure from one place to another.</li> </ul> Click to expand answer <p>As an example, to copy a directory tree from /users/bob/src to /dcs08/bob/dst, first, create a cluster script, let's call it \"copy-job\", that contains the line <pre><code>#!/bin/bash\n\nrsync -avzh //users/bob/src /dcs08/bob/dst\n</code></pre> Next, submit a batch job to the cluster <pre><code>sbatch --mail-type=FAIL,END --mail-user=bob@jhu.edu copy-job\n</code></pre> This will submit the \"copy-id\" script to the cluster, which will run the job on one of the computer nodes, and send an email when it finishes.</p> <p>Warning</p> <p>Please do not copy or move any larger files on the login nodes.</p>"},{"location":"help/faq/#login","title":"Login","text":"<ul> <li>SSH gave a warning: REMOTE HOST IDENTIFICATION HAS CHANGED</li> </ul> Click to expand answer <p>Go into the ~/.ssh directory of your laptop/desktop and edit the known_hosts file. Search for the line that starts with the host that you ssh\u2019d to. Delete that line (it is probably a long line that wraps). Then try again</p> <ul> <li>SSH \"Bad owner or permissions\"</li> </ul> Click to expand answer <p>If you receive a message like \"Bad owner or permissions on ~/.ssh/config\" or continue to have to provide your password when ssh'ing to JHPCE when you think you have configured things to not need one, your file owner or permissions may be incorrect. See this document for answers.</p> <ul> <li>How do I delete saved passwords in MobaXterm?</li> </ul> Click to expand answer <p>When using MobaXterm you should not save your password when prompted to do so. MobaXterm will save your password, and then inadvisedly try to use that as your \u201cVerification Code:\u201d, which means that when you first connect to the cluster in MobaXterm, you are prompted for \u201cPassword:\u201d, and which you will need to press to be prompted for \u201cVerification Code:\u201d If you accidentally saved your password, you can remove the saved password by the following steps.  </p> <p>1) In MobaXterm, go to \"Settings-&gt;Configuration\" </p> <p>2) On the next screen, select \"MobaXterm Password Management\" </p> <p>3) This will display a list of saved passwords, and you should delete all of the entries that reference \u201cjhpce\u201d </p> <p>Once these entries are deleted, you should be prompted for \u201cVerification Code:\u201d when you connect to the cluster via MobaXterm.</p>"},{"location":"help/faq/#modules","title":"Modules","text":"<ul> <li>Why does bash report that it can\u2019t find the module command?</li> </ul> Click to expand answer <p>If you receive a message like</p> <pre><code>bash: module: command not found\n</code></pre> <p>The module is a shell function that is declared in <code>/etc/bashrc</code>. It is always a good idea for <code>/etc/bashrc</code> to be sourced immediately in you <code>~/.bashrc</code>.  Edit your <code>.bashrc</code> file so that the first thing it does is o execute the system bashrc file, i.e. your <code>.bashrc</code> file should start with the following lines:</p> <pre><code>if [ -f /etc/bashrc ]; then\n. /etc/bashrc\nfi\n</code></pre>"},{"location":"help/faq/#resources","title":"Resources","text":"<ul> <li>What is the SAFE desktop?</li> </ul> Click to expand answer <p>The SAFE desktop is a virtual Windows computer that you can use to run scientific software and access JHPCE. For more information see this item.</p>"},{"location":"help/faq/#slurm","title":"Slurm","text":"<p>There is a dedicated SLURM FAQ document</p>"},{"location":"help/faq/#x11","title":"X11","text":"<ul> <li>My X11 forwarding stops working after 20 minutes </li> </ul> Click to expand answer <p>This error comes from the <code>ForwardX11Timeout</code> variable, which is set by default to 20 minutes.  To avoid this issue, a larger timeout can be supplied on the command line to, say, 336 hours (2 weeks):</p> <pre><code>$ ssh -X username@jhpce03.jhsph.edu -o ForwardX11Timeout=336h\n</code></pre> <ul> <li>Xauth error messages from MacOS Sierra when using X11 forwarding in SSH</li> </ul> Click to expand answer <p>With the upgrade to MacOS Sierra, the \u201c-X\u201d option to ssh to enable X11 forwarding may not work. If you receive the message: untrusted X11 forwarding setup failed: xauth key data not generated , you can resolve the issue by add the line ForwardX11Trusted yes to your ~/.ssh/config file on your Mac. You may still see the warning: Warning: No xauth data; using fake authentication data for X11 forwarding. To eliminate this warning, add the line XAuthLocation /usr/X11/bin/xauth to your ~/.ssh/config file on your Mac.</p>"},{"location":"help/general-advice/","title":"General Tips/Requests","text":"","tags":["needs-major-revision","refers-to-old-website"]},{"location":"help/general-advice/#the-cluster-is-a-shared-resource","title":"The cluster is a shared resource","text":"<p>Generally expected knowledge + Take care not to use too many resources on the login nodes. Anything CPU, RAM, or input/output intensive should be done on compute nodes rather than one of the login nodes. + Anything more than a quick <code>ls</code> including: copying large files, recursively changing permissions, creating or extracting tar or zip archives, running a <code>find</code> should be done in a session on a compute node. + Data transfers of files larger about 1GB should be done through <code>jhpce-transfer01.jhsph.edu</code> rather than a login node. + Try to avoid having directories with more than 100 files in them.  + Try to avoid storing programs and scripts in data directories like <code>DCL*</code>. + Most storage on the cluster is raided but not backed up.  + We do back up home directories and a few other select directories on the DCS and DCL systems for groups that have requested backups.  We do have additional backup storage capacity available for a small fee. + Make use of your 1 TB of fastscratch storage for IO intensive job + Please remember that DCS and DCL stand for \u201cDirt Cheap Storage\u201d and   \u201cDirt Cheap Lustre\u201d, and were designed with cost-effectiveness as a   primary driving factor over performance. + Sharing data can be done in several ways on the cluster: i.) traditional Unix file permissions and groups and ii.) Access Control Lists (ACLs). + Sharing files with external collaborators can be done via Globus.</p>","tags":["needs-major-revision","refers-to-old-website"]},{"location":"help/general-advice/#best-practices-passwords-and-authentication","title":"Best practices: passwords and authentication","text":"<ul> <li>Do not share your password with ANYONE. You are responsible for the use of your account.</li> <li>Choose a \"strong\" password.</li> <li>Use the \"kpasswd\" command to choose a new password. It requires your new password to have three of the following four sets of characters: upper-case, lower-case, numerical digits, and special characters.</li> <li>It would be best if your password was unique and not the same     password you use on other systems.</li> <li>If you believe your password or your computer have been compromised     please alert us via email to bitsupport@lists.jh.edu. Then reset your password using a different device. Visit     https://jhpce-app02.jhsph.edu/\u00a0 to reset your password.\u00a0 This web     site is only available on campus, so if you are outside of the     school network, you will need login to the JHU VPN first. You will     log into that page with your JHED ID and password.</li> <li>Hopkins staff will *NEVER* send you an email message asking for     your password or login credentials</li> <li>NEVER give out your password and login ID to anyone in an email     message or on a web page.</li> </ul> <p>If you have never used a Linux or Unix system before, we strongly     recommend going through the Unix Command     Line     tutorial. The cluster is entirely Linux based. Our Orientation is     about using the cluster, not using Linux. This tutorial should     only take 30 minutes or so to go through.</p>","tags":["needs-major-revision","refers-to-old-website"]},{"location":"help/general-advice/#new-c-sub-user-orientation","title":"New C-SUB user orientation","text":"","tags":["needs-major-revision","refers-to-old-website"]},{"location":"help/general-advice/#what-to-do-before-the-c-sub-jhpce-orientation-session","title":"What to do BEFORE the C-SUB JHPCE Orientation Session","text":"<p>There is a lot of material for us to cover and you to absorb. It is vital for your success that you complete a number of steps PRIOR to attending the\u00a0Orientation Session for the CMS Subcluster of the JHPCE (pronounced by its letters J-H-P-C-E) cluster.</p> <ul> <li>Download a copy of the slides from the Orientation     from:JHPCE-Overview-CMS.pdf.</li> <li></li> <li> <p>In order to access the JHPCE cluster and make use of the     applications on the cluster, you may need to install additional     software on your smart phone and laptop.</p> </li> <li> <p>Install the 2 Factor Authentication program. \u00a0The JHPCE cluster     makes use of \"Google Authenticator\" to provide enhanced security.     \u00a0You can choose to either install an app on your smartphone or, if     you do not have an Apple or Android based smart phone, you can     install an extension to the Google Chrome browser.\u00a0 Prior to the     Orientation Session, you will only need to download the     GoogleAuthenticator app on your smart phone, or install the Authy     Chrome extension. We will be configuring Google Authenticator     during the Orientation Session. Please     see\u00a0https://jhpce.jhu.edu/knowledge-base/authentication/2-factor-authentication/#otp     for instructions.</p> </li> <li>Install required client software.\u00a0 You may need to install a     couple of programs on your laptop or desktop in order to access the     JHPCE Cluster.\u00a0 You will need 1) an SSH client for logging in, 2) an     SFTP client for transferring files to and from the cluster, and 3)     an X11 client for displaying graphics back from the JHPCE cluster.     \u00a0The SSH client is a requirement -- the SFTP and X11 clients are     preferable but optional.<ul> <li>Microsoft Windows We have found that the easiest program to use for accessing the     JHPCE cluster is MobaXterm as it combines the functionality of     all 3 software packages (SSH, SFTP, and X11) in 1 program.\u00a0     Install MobaXterm by following the first few steps of     https://jhpce.jhu.edu/knowledge-base/mobaxterm-configuration/     .\u00a0 Alternatively, if you already use an SSH client, (such as     putty     or Cygwin) and an SCP client\u00a0 (such as     WinSCP),     you can continue using that software.</li> <li>Apple Macintosh There are built in command line tools for ssh and scp that     can be run from a Terminal window. The Terminal program can be     found in \"Applications -&gt; Utilities\". From a Terminal window,     you would type:\\     <code>ssh &lt;username&gt;@jhpcecms01.jhsph.edu</code>and then login with     the login id and the password we provided to you.- In order to     run graphical programs on the cluster and have them displayed on     your Mac, you will need to install XQuartz from     http://xquartz.macosforge.org/landing/.- Optionally, you can     also install a GUI based SFTP program such as     \"Filezilla\". One note about     Filezilla -- if you download the package from the default link     on SourceForge, you may be be blocked by your MalWare/Virus     Scanner, or prompted to install Potentially Unwanted Programs     (PUPs) during installation.\u00a0 We recommend you follow the     alternative download link     here to     download a clean copy of the program.</li> </ul> </li> </ul>","tags":["needs-major-revision","refers-to-old-website"]},{"location":"help/glossary-manual/","title":"Glossary","text":"<p>Terms you might wonder about. If you don't find what you're looking for, please use Google. Italicized terms indicate that there is a glossary entry for that item.</p> Absolute path A path which starts with a forward slash. Your shell (such as bash) interprets this location as starting with the root of the file systems on a computer. See also: relative path bash An example of a shell, which are programs which accept and process commands entered via text with a certain syntax, or set of rules. (Wikipedia page) CLI Command Line Interface - a program like bash which provides a means to enter commands via text strings and see responses. (Wikipedia page.) Cluster A collection of computers (aka \"nodes\") managed as a group to provide services. Usually uses a job scheduler. Compute node Computers within a cluster used to execute jobs Computer You're using one right now. Aren't they marvelous? Core A component of a CPU which processes threads of program instructions. Cores each have their own collections of components which are needed to execute instructions, such as registers for mathematical operations, memory stores to cache information. CPUs can contain many cores. Cores can have support for hyperthreading. (Wikipedia page. SLURM support for cores/threads.) CPU Acronym for Central Processing Unit. The main processor in a computer. Contains one or more cores. There may be more than one CPU within a computer. See information about the CPUs on your UNIX computer with the command <code>less /proc/cpuinfo</code> (press q to quit). (Wikipedia page) Current working directory Expansion of acronym CWD. Your current (aka present) location within a file system. Can be expressed as a path. The command <code>pwd</code> will return the path to your CWD. EMACS A super-complex but powerful and VERY extensible text editor written in Lisp, an abomination of a computer language. I called it \"Eight Megabytes And Constantly Swapping\" back in the day when a megabyte of RAM cost thousands and thousands of dollars. Like Doctor Who, proponents can be tiresome to others. See also: vi File system A data storage service which allows for the storage and retrieval of information. File systems are basic units of storage. File system services include holding metadata about files, such as when they were created and who owns them. The command <code>df -h .</code> will return information about the file system of your current working directory. (Wikipedia page) GUI Acronym for Graphic User Interface. Antonym of CLI. A means of interacting with a user via windows. Operating systems such as macOS and Windows rely on GUI for its ease-of-use. X11 is a protocol which provides for the display of GUI windows over networks. Some of the windows in a GUI might be terminals offering CLI programs, such as bash shells.  Hyperthreading Modern CPU cores normally have some additional circuitry which store information used by (normally two) threads. This allows the core to easily switch its attention between two threads so work can continue if one of the threads needs to wait for information to be brought into the core from RAM. (Wikipedia page) Job A unit of work given to an operating system by a scheduler on behalf of a user Job scheduler Application which controls the execution of interactive or batch jobs on a cluster. SLURM is a job scheduler. (Wikipedia page) Linux A flavor of UNIX. Don't let them convince you that they invented it. (They will try. It's sad, really.) locality The proximity of data stored in memory to the processing circuitry. You want to keep data as close as possible when creating jobs. Memory General term for anything that can store information. You have a memory. Computers use many types of memory. People often mean RAM when they say memory. Sometimes they mean hard drive space when they say memory, which is understandable but confusing to those trying to help them. Say \"disk space\" or \"disk storage\" instead. Thanks. Memory hierachy A hierarchy of types of memory used by a computer. Each type has different speed of access, capacity, and cost. Fast memory is expensive and usually provides for limited capacity. Each is therefore usually used for certain purposes. A register inside of a core inside of a CPU is the fastest memory, but small. Next is one or more caches inside of a core. Next (cheapest, fastest, most capacious) is RAM. After RAM comes hard drives on the same computer. After hard drives on the local computer comes hard drives on file servers which have to pass their information across the network. Next come USB sticks, then floppy disks, then humans typing into keyboards. The closer to a register you can keep the information needed for your program, the faster it can be processed. This distance from the processor is called locality. Pane (Associate with window) A subdivision within a window where information is displayed, perhaps alone or perhaps alongside other panes Path A string of characters used to identify a location in a directory structure inside of a file system. That location represents either a file or directory. Examples: <code>./my-script</code> or <code>/dcs07/a-groups-data/some/place/down/deep</code> See also: absolute path, current working directory, relative path. Node Any computer within a cluster Nodes can be grouped by the services they provide, such as offering computation or file services. Usually used to indicate a compute node. RAM Acronym for Read Access Memory. Part of a memory hierarchy. A form of computer memory that can be read or written in any order. Contrast with data stored on a tape. You cannot read any data from the tape without moving the tape to reach the portion where your desired information is stored. Some of us had to use data on tapes. We were lucky we didn't have to use data stored on punchcards. RAM is fast and capacious. Most RAM used in cluster nodes is volatile -- it cannot store information without continuous electrical power. (Wikipedia page) Relative path A path which does not start with a forward slash. Your shell (such as bash) interprets this location starting with your current working directory. See also: absolute path Scheduler A component of a job scheduler application which decides which jobs to start running, when, and on which cores on which CPUs on which nodes. (Operating systems also contain schedulers, which do the same things for any process or thread, whether or not they are part of a job.) (SLURM CPU allocation process described here. SLURM has multiple other documents in the Slurm Scheduling section of this page.) SSH Acronym for Secure SHell. Technically a protocol for multiple network services. Usually meant to refer to a program which implements that protocol to provide a CLI. See our SSH document. (Wikipedia page) Thread The smallest sequence of programmed instructions that can be managed independently. Part of a process (which may have one or more threads). It takes time for the information needed by a thread to run to be loaded into a CPU core. So there is an expense (delay) to switching between threads on the same core. Hyperthreading attempts to reduce that cost. (Wikipedia page. SLURM support for cores/threads.) UNIX A family of operating systems initially brought to you by Bell Telephone, a monopoly in the US. UNIX has fundamentally always used a CLI because, well, GUIs didn't exist for many years after UNIX got started. UNIX has a steep learning curve, but has only grown in use over the decades because it is powerful and extensible. If you're struggling to learn UNIX, remember that many people had to learn UNIX without the Internet or Google. Modern macOS and Windows (since Windows NT) rely on UNIX code. Linux is not UNIX. Linux is a flavor of UNIX. Anyone who tells you otherwise is a poser. (Wikipedia page) User You Vi The best text editor. Anyone who tells you otherwise is uninformed. Window (Associate with pane) One or more panes displayed to a user by a software application."},{"location":"help/good-query/","title":"Helpful Hints For Asking Questions or Reporting Problems","text":"<p>This page describes how to write a good help request email.</p>","tags":["done"]},{"location":"help/good-query/#a-good-request","title":"A Good Request","text":"<ol> <li> <p>Write a descriptive summary.</p> <ul> <li>Put in a short summary into the Subject.</li> <li>Which cluster are you on? We support two -- JHPCE and C-SUB. We assume JHPCE but specify \"C-SUB\" if that is where you are working.</li> </ul> </li> <li> <p>Expand on this in a first paragraph. Try to answer the following questions:</p> <ul> <li>Please give us your user name on the cluster.</li> <li>What are you trying to achieve?</li> <li>When did the problem start?</li> <li>Did it work before or is this the first time you are trying to do this?</li> <li>Which steps did you attempt to achieve this?</li> </ul> </li> <li>Additional advice:<ul> <li>Put enough details in the details section.</li> <li>Send us screenshot images of what you did -- often we can notice little details you might not have thought to mention.</li> <li>Please give us the exact commands you type into your console.</li> <li>What are the symptoms/is the error message</li> <li>Have you tried to google for the error message?</li> <li>Never put your password into the ticket.</li> <li>In the case that you handle person-related data of patients/study participants, never write any of this information into the ticket or subsequent email.</li> </ul> </li> </ol>","tags":["done"]},{"location":"help/good-query/#specific-questions-for-common-issues","title":"Specific questions for common issues","text":"","tags":["done"]},{"location":"help/good-query/#problems-connecting-to-the-cluster","title":"Problems Connecting to the Cluster","text":"<ul> <li>From which machine/IP do you try to connect (ifconfig on Linux/Mac, ipconfig on Windows)?</li> <li>Did it work before?</li> <li>What is your cluster user name? This is NOT your JHED ID.</li> <li>Please send us the output of <code>ssh-add -l</code> and add <code>-vvv</code> to the SSH command that fails for you.</li> <li>What is the response of the server?</li> </ul>","tags":["done"]},{"location":"help/good-query/#problems-submitting-jobs","title":"Problems Submitting Jobs","text":"<ul> <li>Please give us the directory that you ran things in.</li> <li>Please send us the submission script that you have problems with.</li> <li>If the job was submitted, Slurm will give you a job ID. We will need this ID.</li> <li>Please send us the output of scontrol show job  or sacct --long -j  of your job.","tags":["done"]},{"location":"help/help-basics/","title":"Help","text":""},{"location":"help/help-basics/#ways-to-seek-help-and-support","title":"Ways to Seek Help and Support","text":"Search this website: There is a lot of information on this site. You can search the site for helpful bits of information by entering keywords into the text box on the upper left. Search/Email for \"bithelp\" advice: <code>bithelp@lists.johnshopkins.edu</code>. This is the main list to use for \"how-to\" or \"why doesn\u2019t this work\" types of questions. It is comprised of the JHPCE community, including many power-users, and system administrators. It's used for questions about running and installing applications, and about R, Bio-conductor, Perl, SAS, C, SLURM etc. This list is also used for announcements by the maintainers of various community tools and resources. You should check to see if your question has been asked and answered before in the list archives. To be added to the bithelp list, send a request to bitsupport@lists.johnshopkins.edu. Contact system administration staff vi \"bitsupport\": <code>bitsupport@lists.johnshopkins.edu</code>. This email is for communicating with the system administration staff about operational and administrative issues like login problems, quota issues, and system downtime. It is monitored by the system administrators and some faculty. You should check to see if your question has been asked and answered before in the list archives. Please don't hesitate to reach out to us if you have any questions or concerns. <p>Tip</p> <p>When contacting us, please provide enough information so we can promptly diagnose the problem or answer your question.</p> <p>Here is a page describing the information we need.</p>"},{"location":"joinus/","title":"JHPCE Information","text":"The JHPCE Service Center manages 2 HPC computing environments."},{"location":"joinus/#jhpce","title":"JHPCE","text":"<p>The larger HPC environmnet is for general HPC computing on non-HIPAA data. We generally refer to this as the \"J H P C E\" cluster (each letter pronounced).  Informaion on the JHPCE cluster can be found at the Introduction link.</p>"},{"location":"joinus/#csub","title":"CSUB","text":"<p>We also manage a smaller sub-cluster for working on CMS Medicare and Medicaid data. We refer to this cluster as the C-SUB (See Sub) cluster. While the JHPCE service cnter manages this HPC cluster, it's operation is overseen by the HARP organization in JHU. Technical infomation about the C-SUB can be found at the CSUB Overview.</p>"},{"location":"joinus/hipaa/","title":"HIPAA","text":""},{"location":"joinus/hipaa/#basics","title":"Basics","text":"<p>HIPAA has two relevant standards that must be satisfied.  The HIPAA Security Rule Standards and the HIPAA Privacy Rule Standards. The JHPCE adheres to the HIPAA Security Rule Standards. Adhering to the HIPAA Privacy standards is the responsibility of the PI.  BSPH is not part of the Johns Hopkins covered entities (As of 1/26/06). Therefore, insofar as data on the JHPCE is concerned, the PI is responsible for ensuring that his or her research is conducted in compliance with HIPAA Privacy Rule Standards. Fortunately, this is not difficult. Formally, PIs are restricted to either deidentified datasets or to limited datasets (see links below for details). Examples of limited data sets include dbGaP datasets (assuming a data use agreement is in place) and deidentified insurance claim data. The latter can include dates such as admission, discharge, service, DOB, DOD; and location information such as city, state, five digit or more zip code; and ages in years, months or days or hours.</p>"},{"location":"joinus/hipaa/#using-phi-or-pii-on-jhpce","title":"Using PHI or PII on JHPCE","text":"<p>The JHPCE cluster may be able to meet the requirements specified by the data provider for the handling of PHI data.  There may be additional steps that the data analysts will need to go through in order to access the data, but this is typically a matter of running a few extra steps to access the data.  If you have a dataset with sensitive data, please reach out to us at bitsupport@jhu.edu and we can review the data handling requirements to assess whether the JHPCE cluster can meet them.</p>"},{"location":"joinus/hipaa/#csub","title":"CSUB","text":"<p>The JHPCE maintains a small sub-cluster for handling CMS Medicare and Medicaid claims data. This sub-cluster has a number of additional security features in place to ensure the security of this more sensitive data. If you are interested in accessing the CMS data, please email support@harp-csub.freshdesk.com for more information. We have additional information in our CSUB Section.</p>"},{"location":"joinus/hipaa/#links","title":"Links","text":"<p>The following links from the JHPSH IRB, \u00a0SOM IRB and the US Department of Health &amp; Human Services (HHS) provide details on how to de-identify your data so that you are in compliance with the HIPAA Privacy Rule Standards.</p> <ul> <li>JHSPH IRB HIPAA page</li> <li>JHMI IRB definition of de-identified data</li> <li>JHMI definition of \u201cLimited data set\u201d</li> <li>HHS Guidance Regarding Methods for De-identification of PHI </li> </ul>"},{"location":"joinus/intro/","title":"Introduction","text":""},{"location":"joinus/intro/#overview-for-new-pis-and-users","title":"Overview for new PIs and users","text":"<p>The JHPCE cluster is a Linux based HPC environment, and is designed for running loosely coupled parallelizable jobs, or programs needing large amounts of  CPUs, RAM, or disk space.  We have a number of genomics and statistical tools installed on the cluster, but most of the analysis is done using programs  written in languages like R, python, Stata, or SAS.</p> <p>The JHPCE Cluster operates as a non-profit service center run out of the  Biostats department of the Bloomberg JHU Bloomberg School of Public Health. As  such we do charge fairly nominal fees for compute and storage, and all users on the cluster need to have a sponsoring PI that will fund their usage.</p>"},{"location":"joinus/intro/#information-for-new-sponsoring-pis","title":"Information for New Sponsoring PIs","text":"<p>As mentioned above, we do operate as a non-profit JHU Service Center, and do charge for compute and storage usage on the cluster.  </p> Compute Charges Our fees for compute time are roughly 1 penny per hour for a job using 1 core  and 5GB of RAM.  Costs scale linearly with time and cpu+mem usage, so a job  running for 24 hours that used 8 cores and 40GB of RAM would cost about $2.00.  Storage Charges    Costs for storage are broken into home directory storage and project storage space.   1. Home directory Storage: All users are given a personal home directory with a 100GB quota.  For home directory space, we charge $0.45 per GB per year, so this cost would max out at $45 for a year if a user used their entire 100GB of space.  2. Project Storage: If you need several TB of space for storing large amounts of data, you can purchase an allocation on one of our large  storage arrays.  Every 12 months or so we purchase a new large storage array  for the JHPCE cluster, and sell allocations on that array. The cost for an  allocation will be based on the actual cost of the storage, but has been  decreasing over time.  Our latest storage build worked out to be about $30  per TB per year.  There is typically a 10TB minimum buy-in for new storage  purchases.  <p>We have more information about becoming a Sponsoring PI as both a Stakeholder and Non-Stakeholder at New PI Page If this sounds like a good fit for your lab, then the first step in accessing the cluster would be for you or someone on your team to complete the  New Project form.  This will help us gather the relevant contact and financial information for your lab.</p>"},{"location":"joinus/intro/#information-for-new-users","title":"Information for New Users","text":"<p>Once the New Project form is completed, the Project will be added as a Sponsoring Organization on the New Users form at which point the members of your team that will be performing the analysis can sign up for a user account.  Once the New User form is completed, an email will be sent to the requestor with some introductory information about the cluster, as well as a link to sign up for an upcoming JHPCE Orientation Session.</p>"},{"location":"joinus/intro/#orientation","title":"Orientation","text":"<p>All new users are required to attend one of our JHPCE Orientation Sessions, during which their account will be set up on the cluster.  The Orientation is typically held every other Wednesday afternoon, and lasts for about 2 hours.  Prior to attending the orientation, you should review the What to do before attending the orientation session page.  The slides for the orientation can be found Here</p>"},{"location":"joinus/leaving/","title":"Leaving JHPCE as a User or PI","text":"<p>So, you're leaving JHU.</p>"},{"location":"joinus/leaving/#departing-studentsresearchers-or-pis-of-departing-studentsresearchers","title":"Departing Students/Researchers or PIs of Departing Students/Researchers","text":"<p>If you are a student or researcher that is either leaving JHU or will no longer be using the JHPCE cluster, please be sure to have your sponsoring PI reach out to us. We will work with your PI to close out your account on the JHPCE cluster and either delete your data from the cluster, or migrate it to another location. If you have data on the cluster that you are authorized to keep, please be sure to transfer the data to a location outside of the cluster so that you can access it once you account is closed. We have some tips on transferring data to and from the cluster here</p> <p>We can keep your account open for a short time after you leave JHU if your PI agrees to continue to sponsor your usage. Please have your PI reach out to us at bitsupport@lists.jhu.edu so that we can arrange your ongoing access to the cluster.</p>"},{"location":"joinus/leaving/#departing-pisdepartments","title":"Departing PIs/Departments","text":"<p>If you are a sponsoring PI and you are leaving JHU, or will no longer be using the JHPCE cluster, please reach out to us at bitsupport@lists.jhu.edu so that we can coordinate closing out your project. There will need to be a number of decisions made about your account and data.</p> <ul> <li>Any users under your project will that will continue to use the JHPCE cluster will need to be moved under another PI's project. We will need an \"OK\" from the adopting PI in order to move anyone under their Project.</li> <li>All users that are not picked up by another sponsoring PI will have their accounts closed and home directories deleted.</li> <li>If you have data stored in a larger DCL or DCS storage allocation, the allocation will need to be either moved under another project, or deleted. As with users, you will need to identify a new PI/Project that will assume ownership of your storage allocation.</li> <li>Please be sure to transfer any data you will need to retain to a location outside of the cluster so that you can access it once you account is closed. </li> </ul>"},{"location":"joinus/new-pi-form/","title":"New PI Form","text":"<p>Please complete the form below to provide information on becoming a Sponsoring PI for a Project on the JHPCE cluster.</p> <p><sub>(Note: the form is on our old web site and will be transitioned soon)</sub></p> <p>Your browser does not support iframes.</p>","tags":["refers-to-old-website"]},{"location":"joinus/new-pi/","title":"Are you a Primary Investigator wanting to join JHPCE?","text":"<p>This page is for new PIs who are interested in joining the JHPCE as well as for PIs who have previously registered with us but need to create a new project, collaboration or organization.</p>"},{"location":"joinus/new-pi/#stakeholder-vs-non-stakeholder-pis","title":"Stakeholder vs. Non-Stakeholder PIs","text":"<p>As a PI, you can join as either a Stakeholder or Non-Stakeholder. We define Stakeholder PIs as those that have contributed computing resources to the  facility.  Non-Stakeholder PIs are those that sponsor the computing for their lab or department, but do not purchase computing resources for the cluster. Most PIs will start as Non-Stakeholders, but will move up to stakeholders when they either acquire computing resources they want to contribute to the cluster, or purchase computing resources for the cluster either through a grant or through their normal budgeting cycle. </p> <p>As a Stakeholder, you agree to share any unused capacity on your compute nodes with the broader JHPCE community by placing them on the \"shared\" partition or queue on the cluster. For non-Stakeholders, the only access to computing resources is via those shared by the Stakeholders.  This model has historically worked very well for the JHPCE community.  While there is no guarantee of computing resources to Non-Stakeholders, there is generally sufficient capacity on the \"shared\" partition to meet the needs of the users sponsored by Non-Stakeholders. </p> <p>This model is often referred to as a \u201ccommon pool resource\u201d in the sense formalized by E. Ostrom and others. Users affiliated with stakeholders have  the right of priority access to the resources that they \u201cown\u201d. All users, whether they are members of a stakeholding organization or not, are otherwise treated identically. Excess computing capacity is made available to the entire community via a low priority \u201cshared queue\u201d. The shared partition also provides surge capacity to stakeholders in addition to providing access to HPC resources to non-stakeholders.</p> <p>The JHPCE service center will charge a monthly management fee to the Stakeholder PI that has purchased computing nodes for the cluster.  This fee is roughly $500 per month for a compute node (which works out to $0.01/hr for a node with 64 cores and 512GB of RAM), and covers the charges for space, power, and cooling, as well as the salaries of those supporting the equipment.  These Stakeholder fees though are defrayed to the extent that their capacity is used by others. So if the users sponsored by a Stakeholder PI do not use their compute nodes for a month, that monthly fee is paid for entirely by its usage on the \"shared\" partition.</p> <p>In this way the system has been able to meet the needs of both the stakeholders with the greatest HPC consumption, and the needs of the smaller users in the long tail of HPC consumption (where the bulk of the science is performed). All of this is accomplished with light-weight polices and light-weight organizational infrastructure (&lt; 3FTEs) , which is a major reasons that we are able to keep our costs low.</p>"},{"location":"joinus/new-pi/#how-to-register","title":"How to register","text":"<p>If you are a Principal Investigator registering a new project or organization, please fill out this Form. If you have never registered a project and budget number with the JHPCE, we request that you contact the director of the JHPCE to arrange a 1/2 hour orientation (either in person or via telephone).</p>"},{"location":"joinus/new-pi/#becoming-a-stakeholder","title":"Becoming a stakeholder","text":"<p>There are many benefits to becoming a Stakeholder in the JHPCE cluster.</p> <p>As a Stakeholder, you will be given a dedicated partition on the node that you purchase for the cluster.  The partition will only be accessible by members of your group, thus avoiding delays when the shared partition becomes busy. We also allow you to pull your node off the the shared partition if you need dedicated access to your computing resources for a time.  Bear in mind though that while the node is off of the shared partition, you will be paying the entire management fee for the node.</p> <p>If you are interested in purchasing nodes to add to the JHPCE cluster to become a Stakeholder, please email the JHPCE Director at jhpce@jhu.edu. We can help you with sizing an appropriate solution for your needs, and coordinate with vendors to get quotes.</p>"},{"location":"joinus/new-users-form/","title":"New user form","text":"<p>Please complete the form below to request an account on the JHPCE cluster. Once we have received your form, you'll receive an email message with some introductory information and a link to sign up for one of our upcoming orientation sessions.  The sessions are generally held every 2 weeks.</p> <p><sub>(Note: the form is on our old web site and will be transitioned soon)</sub></p> <p>Your browser does not support iframes.</p>","tags":["refers-to-old-website"]},{"location":"joinus/policies/","title":"Policies","text":""},{"location":"joinus/policies/#1-introduction-to-the-commons","title":"1. Introduction to the commons","text":"<p>The JHPCE service center operates a High Performance Computing (HPC) facility as a Common Pool Resource (CPR) Hierarchy, with rights to specific resources based on stakeholder ownership of specific resources. \u00a0A formal computational model of the HPC resources provides a starting point for the self governance of the the commons, first by defining a hierarchy of resources that are governed locally by individual stakeholders, second, by distributing common and resource-specific expenses throughout the hierarchy, third by calculating fees in proportion to actual measured consumption of specific resources and fourth, by providing a data based method that incentivizes sharing of excess resource capacity. \u00a0CPR principles have provided a framework that has helped us address issues of overuse, congestion, and sustainability. The strategy has harnesses the intellectual and grant writing skills of the entire community, for the benefit of the entire community, while enabling the growth of an HPC facility that is up-to-date and very matched to the needs of its PIs. This contrasts with traditional governance models that rely on central planning, F&amp;A and a handful of rainmakers. Our experience is that the CPR model benefits not just the largest and best funded stakeholders, but also the much larger numbers of smaller stakeholders and non-stakeholders who make up the tail of the HPC consumption distribution \u2013 where the bulk of the science is produced.</p>"},{"location":"joinus/policies/#2-computing-resources","title":"2. Computing Resources","text":""},{"location":"joinus/policies/#21-background","title":"2.1 Background","text":"<p>All user are permitted to submit jobs to the shared queue. The shared queue provides low-priority access to unused capacity throughout the cluster. Capacity on the shared queue is provided on a strictly \u201cas-available\u201d basis and serves two purposes. First it provides\u00a0surge capacity to stakeholders who temporarily need more compute capacity than they own, and second, it gives provides non-stakeholders access to computing capacity. Scheduling polices attempt to harvest unused capacity as efficiently as possible while mitigating the impact on the rights of stakeholders to use their resources. The service center does not guarantee that stakeholders will provide sufficient excess capacity to meet non-stakeholders needs, however in practice the cluster is rarely operating at full capacity so there is usually ample computing capacity on the shared queue. The JHPCE service center provides the following computing services and capabilities to all PIs and their users:</p>"},{"location":"joinus/policies/#22-computing-privileges-and-services-afforded-to-all-pis","title":"2.2 Computing privileges and services afforded to all PIs","text":"<ol> <li>Low-priority access to cluster-wide excess computing capacity via the shared queue.</li> <li>Detailed quarterly reports of monthly usage and charges, stratified user.</li> <li>System-level support from the System Administrators</li> <li>Access to a download queue that is used for file transfer to and from the facility</li> <li>Access to a low-priority \u201cinteractive queue\u201d for small tasks</li> </ol> <p>2.3 Computing privileges and services afforded to compute-system stakeholders</p> <p>The JHPCE service center is organized to promote the research agendas of its stakeholders. We provide the following computing services and capabilities to stakeholders who purchase compute nodes:</p> <ol> <li>Professional system administration and support of stakeholder-owned compute nodes</li> <li>Management of service contracts, warranties and interaction with vendors (e.g. repair tickets).</li> <li>System-level support from the system administrators</li> <li>Priority access to owned compute nodes via individual stakeholder queues.</li> <li>A stable maintenance fee that is assessed on each compute node on a quarterly basis.</li> <li>Discounts on maintenance fees in exchange for providing excess compute capacity to\u00a0other users.</li> <li>Access to cluster-wide excess computing capacity via the shared queue.</li> <li>Detailed quarterly reports of monthly usage and charges, stratified by queue, host and user.</li> <li>Freedom to remove owned nodes from the cluster at any time.</li> </ol>"},{"location":"joinus/policies/#3-storage-resources","title":"3. Storage Resources","text":""},{"location":"joinus/policies/#31-background","title":"3.1 Background","text":"<p>There are numerous storage spaces available for long term storage of data on the JHPCE cluster.  There are spaces available for all users of the cluster, and also provide that opportunity to buy into a large storage purchase Every 12 - 18 months.</p>"},{"location":"joinus/policies/#32-storage-privileges-and-services-afforded-to-all-pis","title":"3.2 Storage privileges and services afforded to all PIs","text":"<p>All users have home directory space (currently a 100 GB quota). The charge for storage on home directories is proportional to actual usage. Backup of home directories is mandatory and is charged separately.</p>"},{"location":"joinus/policies/#33-storage-privileges-and-services-afforded-to-storage-system-stakeholders","title":"3.3 Storage privileges and services afforded to storage system stakeholders","text":"<p>The bulk of JHPCE storage is dedicated to specific research projects and is owned by stakeholders. Currently the service center has essentially no storage to hand out to users. To meet the continually growing storage requirements, we periodically build large, shared, low-cost, low-power storage arrays, and provide all PIs the opportunity to purchase space on these arrays. The JHPCE provides the following services/capabilities to stakeholders who have purchased a share on a storage device:</p> <ol> <li>A dedicated, fixed allocation on shared devices that stakeholders can manage as they see fit.</li> <li>Professional system administration and support of stakeholder-owned storage</li> <li>Management of service contracts, warranties and interaction with vendors (e.g. repair tickets).</li> <li>Support from the system administrator, including configuration of top-level directories,\u00a0quotas and root-level operations, e.g. on ZFS devices stakeholders can request compressed\u00a0shares, thereby doubling their usable storage.</li> <li>Stakeholders may share their space with collaborators, either for free or in exchange for sharing\u00a0the maintenance charge.</li> <li>Once a storage allocation is purchased, stakeholders maintain access to their space by paying a\u00a0stable quarterly charge that covers operating expenses and amortization of capital costs.</li> <li>Buy-in and operating charges are calculated in proportion to the total capital costs and the total\u00a0operating expenses of the storage device.</li> <li>Due to the fact that ownership of a storage device is shared, it is not possible for a stakeholder\u00a0to remove their share of a device.</li> <li>We expect storage devices to have a 5 year lifetime. Beyond that we may discontinue operation\u00a0of the device. The industry standard is to include 3 year service and support contracts in the\u00a0purchase cost of storage devices. Thus years 4 and 5 may incur higher operating charges due to\u00a0the addition of year 4-5 service contracts.</li> </ol>"},{"location":"joinus/policies/#4-cost-recovery-principles","title":"4. Cost Recovery Principles","text":""},{"location":"joinus/policies/#41-the-jhpce-facility-is-a-common-pool-resource-hierarchy","title":"4.1 The JHPCE facility is a Common Pool Resource Hierarchy","text":"<p>The facilities in the JHPCE are managed as a Common Pool Resource (CPR) hierarchy. The amount of cost that we recover from each resource in the hierarchy is determined by assigning expenses to individual resources in the CPR via a rigorous graph-theoretic time-dependent model of the entire CPR. Expenses are distributed throughout the hierarchy to determine the costs that must be assigned to specific resources, e.g. specific nodes or specific storage partitions.</p>"},{"location":"joinus/policies/#42-compliance-with-omb-regulations","title":"4.2 Compliance with OMB regulations","text":"<p>OMB regulations require that service centers do not make a profit or loss. Year-end deficits or surpluses must be carried forward to the next fiscal year. OMB regulations do not require that rates be estimated and fixed at the beginning of each fiscal year. Instead the requirement is that either rates be fixed periodically OR a well defined systematic charge-back methodology be applied uniformly to all users. We employ the latter strategy. Expense sharing and rate calculations are performed with a software tool that creates a hierarchical model of the HPC facility and incorporates institutional subsidies, expenses and depreciation schedules to calculate the operating costs assigned to individual resources. The software tool then combines the operating costs with the usage data from system logs to calculate rates and chargebacks for individual resources and users. The JHPCE bills quarterly. To guarantee that the service center exactly recovers all it\u2019s quarterly expenses, the JHPCE uses retrospectively calculated rates which are based on actual quarterly expenses and actual quarterly usage (see discussions below). This differs from the conventional approach of setting rates at the beginning of each fiscal year. To appreciate the advantages of this approach we first consider the disadvantages of the conventional approach.</p>"},{"location":"joinus/policies/#43-difficulties-associated-with-the-conventional-approach-to-setting-rates","title":"4.3 Difficulties associated with the conventional approach to setting rates","text":"<p>With the conventional approach, budgets are typically reconciled once per year to: 1) account for the deficit/surplus that has accumulated over the previous year and 2) account for changes in the services and configuration of service center and 3) guess the projected resource usage. By construction, the resulting rates lag the realities of the service center, i.e. the actual expenses, resource usage and configuration. This lag leads to the buildup of deficits (and occasionally surpluses). The resulting uncertainty causes organizational inertia that resists change and innovation. PIs demand and deserve predictable costs. They ask for the current \u201crate schedule\u201d. Unfortunately, setting fixed rates one year ahead actually leads to more variability than rates that are adjusted quarterly in response to \u201crealities on the ground\u201d. With the conventional approach, rates change (by a difficult to predict amount) at the beginning of each fiscal year. There is an annual jump in rates of unknown sign and magnitude. This is not a formula for a financially stable service center or for the predictability that PIs need.</p>"},{"location":"joinus/policies/#44-allocation-and-smoothing-of-expenses-and-subsidies","title":"4.4 Allocation and smoothing of expenses and subsidies","text":"<p>Expenses are spread over time. Capital expenses are depreciated across 3-5 year intervals as determined by their asset class. Non-capital expenses are spread across 12 months, even if the interval spans two fiscal years. Thus the impact of large expenses is spread across individual fiscal years. Expenses are allocated to the appropriate sub-hierarchy of the resource hierarchy according to the part of the resource hierarchy that incurs the expense. This is performed with the aid of a formal graphical model of the facility. For example, expenses related to storage would be assigned to the storage-related sub-hierarchy. Thus the storage expense would not directly impact compute-related rates. In general, this allows expenses to be allocated to the subset of users who actually need and use particular resources. As resources are added and removed from the JHPCE facility, in response to waxing and waning research initiative and grant funding of particular stakeholders and users, the costs associated with those changes are shared with the appropriate subset of the JHPCE community. Finally, subsidies are applied at the level of the hierarchy that is required by the donor. For example, institutional and departmental subsidies are typically for staff salaries, and are therefore applied at the staff salary level of the hierarchy.</p>"},{"location":"joinus/policies/#45-retrospective-rate-calculations","title":"4.5 Retrospective rate calculations","text":"<p>Rates in the JHPCE are calculated retrospectively at the end of every quarter and are based on that quarter\u2019s actual configuration, actual expenses, actual institutional support, and actual usage. While the precise rates are not known until the end of the quarter, 7 years of experience has shown that rates have been stable from quarter-to-quarter with smooth and gradual changes. The only exception has been when major system upgrades have occurred. To PIs that are initially uncomfortable with retrospective rates, we point out that charges are the product of two terms: rates and usage. The latter is the dominant source of uncertainty in budget estimation. Our system allows PIs to use historical rates from recent quarters to estimate their computing budgets in grant applications. By smoothing and appropriate allocation of expenses, we are able to create highly stable rates and to substantially reduce quarterly fluctuations to only a few percent. The final advantage of the retrospective system is that since the software reconciles the budget on a quarterly basis, the service center knows on a quarterly basis, exactly where it stands financially. This is the recipe for a successful service center.</p>"},{"location":"joinus/policies/#45-computing-charges-from-rates-and-usage","title":"4.5 Computing charges from rates and usage","text":"<p>Charges to individual users and stakeholders are calculated strictly in proportion to their share of usage of particular resources. Users with dedicated (i.e. unshared) resources are charged based on 100% usage (i.e. independently of actual usage). Thus stakeholders who purchase a compute node (or a fixed allocation in a shared storage device) will see a fixed charge (subject to aforementioned quarterly fluctuations). In addition, stakeholders who share their resources (e.g. by sharing excess compute cycles) see reduced cost in proportion to the amount of usage that is shared with others.</p>"},{"location":"joinus/policies/#5-current-rate-examples-spring-2024","title":"5 Current rate examples (Spring 2024)","text":"Computing queue rate shared $0.0015/GB-hour sas $0.0224/GB-hour Storage device rate rate home $0.0159/GB-month $190.99/TB-year dcl02 (Lustre allocation) $0.0021/GB-month $25.20/TB-year dcs04 (ZFS allocation) $0.0019/GB-month $23.000/TB-year dcs07 (ZFS allocation) $0.0016/GB-month $19.50/TB-year <p>Allocations may be purchased on custom devices whenever we build them. Allocations are paid off over a 5 year amortization schedule, where the cost includes the hardware costs for the storage plus the quarterly JHPCE Managed Storage charge.</p>"},{"location":"joinus/policies/#51-historical-rate-examples-summer-2021","title":"5.1 Historical rate examples (Summer 2021)ComputingStorage","text":"queue rate shared $0.0024/GB-hour sas $0.0160/GB-hour device rate rate home $0.0243/GB-month $291.99/TB-year dcs01 (ZFS allocation) $0.0031/GB-month $37.90/TB-year dcl01 (Lustre allocation) $0.0025/GB-month $29.60/TB-year"},{"location":"joinus/policies/#52-historical-rate-example-spring-2015","title":"5.2 Historical rate example (Spring 2015)ComputingStorage","text":"queue rate shared $0.0017/GB-hour sas $0.0139/GB-hour device rate rate home $0.0631/GB-month $757.65/TB-year dcs01 (ZFS allocation) $0.0055/GB-month $66.38/TB-year dcl01 (Lustre allocation) $0.0049/GB-month $59.39/TB-year"},{"location":"orient/orientation-overview/","title":"All about orientation","text":"<p>All new cluster users are required to attend a JHPCE orientation session. These sessions are generally held every other Wednesday afternoon via Zoom.</p> <p>Before signing up for a sesssion, please be sure that you have completed the New User Form and that your PI has approved your account.  Once that is done you can sign up for a slot in our next session at our Signup Site</p>"},{"location":"orient/orientation-overview/#documentation-used-in-orientation","title":"Documentation used in orientation","text":"<p>You can download the orientation slides at JHPCE-Overview</p>"},{"location":"orient/orientation-overview/#what-to-do-before-the-jhpce-orientation-session","title":"What to do before the JHPCE Orientation Session","text":"<p>Prior to attending the Orientation Session for the JHPCE cluster, you may need to install some additional applications on you laptop or smart phone. If possible, please install this software prior to attending the JHPCE Cluster  Orientation session.</p>"},{"location":"orient/orientation-overview/#install-the-2-factor-authentication-program","title":"Install the 2 Factor Authentication program.","text":"<p>The JHPCE cluster makes use of \u201cGoogle Authenticator\u201d to provide enhanced security. \u00a0You can choose to either install an app on your smartphone or, if you do not have an Apple or Android based smart phone, you can install an extension to the Google Chrome browser.\u00a0 Prior to the Orientation Session, you will only need to download the GoogleAuthenticator app on your smart phone, or install the Authy Chrome extension. We will be configuring Google Authenticator during the Orientation Session. Please see\u00a0https://jhpce.jhu.edu/knowledge-base/authentication/2-factor-authentication/#otp for instructions.</p>"},{"location":"orient/orientation-overview/#install-required-ssh-client-software","title":"Install required SSH client software.","text":"<p>You may need to install a couple of programs on your laptop or desktop in order to access the JHPCE Cluster.\u00a0 You will need 1) an SSH client for logging in, 2) an SFTP client for transferring files to and from the cluster, and 3) an X11 client for displaying graphics back from the JHPCE cluster. \u00a0The SSH client is a requirement \u2013 the SFTP and X11 clients are preferable but optional.</p> <ul> <li>Microsoft Windows - We have found that the easiest program to use for accessing the JHPCE cluster is MobaXterm as it combines the functionality of all 3 software packages (SSH, SFTP, and X11) in 1 program.\u00a0 Prior to the Orientation Session, you should install MobaXterm by following the first few steps of https://jhpce.jhu.edu/knowledge-base/mobaxterm-configuration/ .\u00a0 Alternatively, if you already use an SSH client, (such as putty or Cygwin) and an SCP client\u00a0 (such as WinSCP), you can continue using that software.</li> <li>Apple Macintosh <ul> <li>SSH Client - There are built in command line tools for ssh and scp that can be run from a Terminal window.\u00a0 The Terminal program can be found in \u201cApplications -&gt; Utilities\u201d.\u00a0 From a Terminal window, you would type: <code>ssh &lt;username&gt;@jhpce03.jhsph.edu</code> and then login with the login id and the password we provided to you.</li> <li>Graphical Programs, X11 server - In order to run graphical programs on the cluster and have them displayed on your Mac, you will need to install XQuartz from http://xquartz.macosforge.org/landing/.</li> <li>File Transfer - MacOS has a built in <code>sftp</code> text-based program for doing file transfers to and from the JHPCE cluster. Optionally, you can also install a GUI based SFTP program such as Cyberduck</li> </ul> </li> </ul>"},{"location":"orient/orientation-overview/#the-jhpce-cluster-is-linux-based","title":"The JHPCE cluster is Linux Based","text":"<p>If you have never used a Linux or Unix system before, we strongly recommend going through the Unix Command Line tutorial offered at the Digital Ocean site at\u00a0https://www.digitalocean.com/community/tutorials/a-linux-command-line-primer\u00a0. The cluster is entirely Linux based, so some exposure to the Linux command line environment is recommended before attending the Orientation Session. The tutorial should only take 30 minutes or so to go through.</p>"},{"location":"orient/orientation-overview/#best-practices-passwords-and-authentication","title":"Best practices passwords and authentication","text":"<p>Do not share your password with ANYONE. Choose a \u201cgood\u201d password using special characters and letters and digits. It would be best if your password was unique and not the same password you use on other systems. If you believe your password or your computer have been compromised please let us know immediately so we can reset your password. If you store passwords on your computer (not recommended), please let us know immediately if your computer is lost or stolen.</p>"},{"location":"orient/orientation-overview/#finally","title":"Finally","text":"<p>Hopkins staff will NEVER send you an email message asking for your password or login credentials NEVER give out your password and login ID to anyone in an email message or on a web page.</p>"},{"location":"ourtools/features/","title":"WEB SITE TOOLS/ENABLED FEATURES WORTH KNOWING HOW TO USE","text":"<p>Let's create a visually appealing web site using some of these features!! Use a WYSIWYG editor like MacDown and \"mkdocs serve\" to quickly edit.</p> <p>Please consult the Tips and Conventions page for authoring guidance and tips.</p> <p>Jeffrey likes:</p> <ul> <li>admonitions -- a lot!!</li> <li>highlighting text</li> <li>keyboard meta keys (like Ctrl)</li> <li>Details (collapsed blocks of text)</li> </ul> <p>Running the mkdocs package installed via python allows you to develop web pages on your local computer. See the recipe</p> <p>There is another document containing wishlist items that we might want to enable/configure.</p>"},{"location":"ourtools/features/#critical-reference-material","title":"Critical reference material","text":"<p>Look here for information about these and other features!!! Just keep in mind that ones marked \"insiders\" are not available for our use. Materials for MkDocs reference section.</p> <p>It isn't clear how much caution one should use in consulting MkDocs documents and people's solutions for it. JRT thinks that Material for MkDocs differs enough that one should definitely keep in mind whether your google search has turned up something about MkDocs.</p>"},{"location":"ourtools/features/#diagramming-with-mermaid","title":"Diagramming with Mermaid","text":"<p>mkdocs.yml contains code enabling the use of a JavaScript tool called Mermaid. If you want your local <code>mkdocs serve</code> program to be able to display it, you need to <code>pip install mkdocs-mermaid2-plugin</code> (see recipe at bottom of this page)</p> <p>Material for MkDocs Diagrams documentation</p> <p>Diagram syntax from the mermaid people</p> <p>A live editor at the mer-people site!!! You can copy the resulting code to your buffer or save the image as (png,svg).</p> <pre><code>graph LR\n   A[Your computer] --&gt; B[Login nodes]\n   B[Login nodes] --&gt; C[(Compute nodes)]</code></pre> <p>Supported types: flowchart (aka graph), sequenceDiagram, stateDiagram-v2,classDiagram, erDiagram</p> <p>JRT finds these types interesting: timeline, user journey</p> <p>Numerous others, including pie, bar and line charts (xychart-beta)</p> Only some types officially supported by Material for MkDocs <p>Besides the diagram types listed above, Mermaid.js provides support for pie charts, gantt charts, user journeys, git graphs and requirement diagrams, all of which are not officially supported by Material for MkDocs. Those diagrams should still work as advertised by Mermaid.js, but we don't consider them a good choice, mostly as they don't work well on mobile. While all Mermaid.js features should work out-of-the-box, Material for MkDocs will currently only adjust the fonts and colors for flowcharts, sequence diagrams, class diagrams, state diagrams and entity relationship diagrams.</p>"},{"location":"ourtools/features/#details","title":"Details","text":"<p>Like an admonition but makes pages more readable by collapsing content. Documentation here and also explained in the detail below.</p> Psst: Click To Expand <p>You can have it be open by default, too. (Add a + after the opening ?+?+?)</p> Syntax to use <p>Details must contain a blank line before they start. Use ??? to start a details block or ???+ if you want to start a details block whose default state is 'open'. Follow the start of the block with an optional class keyword (like \"tip\" or \"warning\") or classes (separated with spaces) and the summary contained in double quotes. Content is placed below the header and must be indented with FOUR SPACES.</p> <p>Another detail can be nested inside by adding another blank line and another detail header line and content block. But this header line needs to start with the word \"multiple\" So ??? multiple class \"Title\"</p>"},{"location":"ourtools/features/#frontmatter-in-document-files","title":"Frontmatter (in document files)","text":"<p>Tags are the primary use of frontmatter I think we should use at this point. This may not be a complete list of directives that one can optionally add within a document. But the basics are that you can add to the top of the document a stanza to set the title of the document, a description of it, a status indicator such as new or deprecated. See this page for how to define an icon for the page.</p> <p>Apparently multiple frontmatter elements, like both tags and a page title, need to exist together inside one pair of three dashed lines. See example:</p> <pre><code>---\ntags:\n  - a tag\ntitle: some docs need explicit titles set b/c they can't be correctly guessed\n---\n</code></pre>"},{"location":"ourtools/features/#tags","title":"Tags","text":"<p>An example of frontmatter is the code to add tags to documents. 20240211 I tested adding a tag and it works. I also specified in the nav section a page for Material for MkDocs to automatically list tags and the pages they are found on.</p> <p>A lot of optional tag-related settings/capabilities seem to be reserved for paying sponsers as of 20240201. See this page. Can users search for documents by tags in the search field?</p> <p>The tags I envision using at the outset are shown below, so we can try to use them to figure out which pages need attention and possibly who is assigned to finish it.</p> <p>The tag \"needs-improvement-later\" could be added to a page which has \"done\" to indicate that what we have is able to be published but needs more work.</p> <p>The tag \"contains-refs-to-old-site\" came to me because some pages, such as the R page, contain screenshots which contain the URL of the old web site.</p> <p>The tag \"last-revised-YYYYMMDD\" could be used on a page which also has \"done\" or \"needs-improvement-later\" so you can tell that information by looking at the tags page. As opposed to having to go look at the repository. The wishlist document mentions adding a plugin or extension which allows the last-revised date to be automatically generated and listed at the bottom of each page.</p> <p>Place lines like this at the very top of the document, before the document title, to add the tags mentioned. Tags are strings but I am hoping to avoid spaces or underscores. (Underscores suck b/c they require the shift key. And you can't always see them depenind on how text renders.)</p> <p>Code blocks are numbered by default (given settings in mkdocs.yml). See this section for instructions on adding titles to code blocks and disabling line numbering.</p> <pre><code>---\ntags:\n  - done\n  - needs-review\n  - in-progress\n  - needs-improvement-later\n  - contains-refs-to-old-site\n  - last-revised-20240210\n  - jeffrey\n  - mark\n  - jiong\n  - adi\n  - brian\n---\n</code></pre>"},{"location":"ourtools/features/#internal-links","title":"Internal links","text":"<p>From this mkdocs page JRT learned that you can specify anchor points to document sections by knowing that they are converted to lowercase and white space is replaced by dashes. So this very section, named \"Internal links\" can be specified as a link to \"features.md#internal-links\"</p>"},{"location":"ourtools/features/#keyboard-meta-keys","title":"Keyboard meta keys","text":"<p>(enabled by the pymdownx.keys extension)</p> <p>keyboard meta keys displayed e.g. Ctrl by using two plus characters, the keyword like \"ctrl\", then two more plus characters</p> <p>+ + Ctrl + +</p> <p>You can create a meta-key sequence by surrounding the sequence with plus symbols but only using single plus symbols in between the keywords.</p> <p>Ctrl+Alt+Del</p> <p>+ + ctrl + alt + delete + +</p> <p>A backtick ` is called a grave, by the way. As in the French \"accent grave\" </p> <p>Example keywords are: dblquote, cmd, ctrl, esc, tab, del, arrow-up, pipe, windows. All of the symbols you could desire are listed here!!!! https://facelessuser.github.io/pymdown-extensions/extensions/keys/ </p> <p>To create the vertical pipe or bar symbol, you can use + + bar + +</p> <p>You can create a key with any wording you want + + \" Your Wording Here \" + + to create Your Wording Here</p>"},{"location":"ourtools/features/#abbreviations","title":"Abbreviations","text":"<p>Abbreviations can be defined by using a syntax similar to URLs and footnotes, starting with an asterisk immediately followed by the term to be associated in square brackets.</p> <p>This code creates the following sentence. You can hover over \"HTML\" and see the definition appear.</p> <pre><code>The HTML specification is maintained by the W3C.\n*[HTML]: Hyper Text Markup Language\n</code></pre> <p>The HTML specification is maintained by the W3C.</p>"},{"location":"ourtools/features/#glossary","title":"Glossary","text":"<p>There's a way to create a document which is automatically updated when people define abbrieviations. See the wishlist document for details.</p>"},{"location":"ourtools/features/#definition-list","title":"Definition List","text":"<p>You can create an indented block of text using a colon followed by FOUR space characters.</p> <p>Example code and result: <pre><code>`a sample term to define`\n:    The definition you are seeking. (But not the droids.)\n</code></pre></p> <code>a sample term to define</code> The definition you are seeking. (But not the droids.)"},{"location":"ourtools/features/#admonitions","title":"Admonitions","text":"<p>These are sweet! We should use them frequently. But be aware that they are not rendered correctly in MacDown.app. This is where it is good to be running \"mkdocs serve\" on your local machine.</p> <p>About admonitions</p> <p>You add an admonition by</p> <ol> <li>starting a line with three explanation marks, a space, and a keyword (called a \"type qualifier\") such as note, danger, example, info, tip, warning. Here is a list. Certain colors are used for known keywords. If you use your own word or phrase, the color is maybe out of your control.</li> <li>on the next line(s) start with FOUR spaces</li> </ol> <p>Note</p> <p>Some text in a note.</p> <p>Example</p> <p>admonitions allow setting off info inside colored boxes, e.g. note,tip,warning,danger,example. https://squidfunk.github.io/mkdocs-material/reference/admonitions/#usage</p> <p>All lines indented four spaces are included in your admonition, including fenced code blocks.</p>"},{"location":"ourtools/features/#open-urls-in-new-tabs","title":"Open URLs in new tabs","text":"<p>(Adi has configured the server to always open URLs in new tabs.)</p> <p>JRT thinks there might be plugins which make this easier than what you have to do othwerwise, which is to use HTML instead of the Markdown notation. In normal HTML you add a space and a string to the end of the URL: <code>target=\"_blank\"</code></p> <pre><code>&lt;a href=\"https://squidfunk.github.io/mkdocs-material/reference/admonitions/\" target=\"_blank\"&gt;About admonitions&lt;/a&gt;\n</code></pre>"},{"location":"ourtools/features/#footnotes","title":"Footnotes","text":"<p>This<sup>1</sup> is a reference to the feature's description.</p> <p>You add a footnote by entering</p> <p><code>[^1]</code></p> <p>in the midst of your text. Anywhere in the document you write the footnote by placing at the start of a line the corresponding numbered entry using the same syntax but adding a colon and a space character after the closing square brace.</p> <p><code>[^1]: Wording of footnote</code></p>"},{"location":"ourtools/features/#data-tables","title":"Data tables","text":"<p>Tables are easily constructed out of vertical pipe symbols |, hyphens - and text. Optional colons can be used to align column contents.</p> <p>They don't render unless you also include the line of hyphens under the line containing the column titles.</p> <p>A simple table is created with these characters:</p> <p>| Column1 Title | Column2 Title |</p> <p>| ---------- | ---------- |</p> <p>| Contents C1R1 | Contents C2R1 |</p> <p>| Contents C2R1 | Contents C2R2 |</p> <p>Table Tips:</p> <ul> <li>Number of pipe symbols per line must match.</li> <li>Number of hyphens in the second line do not have to match any column width.</li> <li>Alignment is done by placing a colon to the left, right, or on both sides of the hyphens in your dividing line.<ul> <li>First column aligned left, second aligned right:  | :---------- | ----------: | </li> <li>First column no alignment, second aligned center:  | ---------- | :----------: | </li> </ul> </li> </ul>"},{"location":"ourtools/features/#sortable-tables","title":"Sortable tables","text":"<p>This is now implemented.</p> <p>https://squidfunk.github.io/mkdocs-material/reference/data-tables/#sortable-tables</p>"},{"location":"ourtools/features/#import-csv-or-excel-file","title":"Import CSV or Excel file","text":"<p>See https://timvink.github.io/mkdocs-table-reader-plugin/</p>"},{"location":"ourtools/features/#icons-and-emojois-examples-kinds-of-check-marks","title":"ICONS and EMOJOIS: Examples: Kinds of check marks","text":"<p>JRT found that these three kinds of check marks are examples of \"icons\" and \"emojis\".</p> Example Markdown text <code>:material-check:</code> <code>:material-close:</code> <code>:material-check-all:</code> <p>They would not render until I added these three lines to mkdocs.yml: <pre><code>  - attr_list\n  - pymdownx.emoji:\n      emoji_index: !!python/name:material.extensions.emoji.twemoji\n      emoji_generator: !!python/name:material.extensions.emoji.to_svg\n</code></pre></p> <p>See this page for more information and links to the \"icon sets\" as well as other pages that display a bazillion emojis: https://squidfunk.github.io/mkdocs-material/reference/icons-emojis/</p> <p> works if you enter <code>:smile:</code></p> <p>STILL UNKNOWN - CAN ANYONE FIGURE IT OUT AND UPDATE THIS PAGE???</p> <p>But these other things didn't work. For some of them I downloaded an .svg file for them and placed them in both a top-level .icons/ directory and a docs/.icons/ directory. So read more if you want to be able to put all kinds of cool symbols in our pages. DO YOU NEED TO HAVE .ICONS DIRECTORIES AT ALL?</p> <p>:page-facing-up:</p> <p>:mdiDatabaseSettingsOutline:</p> <p>:mdiOrderAlphabeticalAscending:</p> <p>:fa-regular fa-envelope:</p>"},{"location":"ourtools/features/#fenced-code-blocks","title":"Fenced code blocks","text":"<p>Note that you can set off a block of text using three preceding and three following backtick characters.</p> <p>There are MANY options for code blocks. All kinds of syntaxes can be used to mean different things. Here is the main document for code blocks.</p>"},{"location":"ourtools/features/#code-block-line-numbers-highlighting","title":"code block line numbers &amp; highlighting","text":"<p>For example, line numbers are enabled by default. You can disable them for a specific code block by adding after the beginning three back ticks a space, then a <code>linenums=\"0\"</code> If you have multiple code blocks and want the line numbers to continue in second and later blocks, you can replace that 0 with a specific number.</p> <p>You can highlight specific line numbers within the block by adding after the beginning three back ticks a space, then a <code>hl_lines=\"2 3\"</code></p>"},{"location":"ourtools/features/#code-block-titles-including-other-files","title":"code block titles &amp; including other files","text":"<p>Add a title by following leading 3 backticks with a space and <code>title=\".browserslistrc\"</code></p> <p>When Snippets is enabled, content from other files (including source files) can be embedded by using the <code>--8&lt;--</code> notation directly from within a code block to pull in a file via a relative path, in this case <code>includes/sample-bashrc</code></p> sample bashrc<pre><code>\n</code></pre>"},{"location":"ourtools/features/#code-block-formatting-by-programming-language","title":"code block formatting by programming language","text":"<p>!!! note:     The language keywords are not the same as in github -- there is overlap but also differences. See this list for the  language keywords for the Pygments Python syntax highlighter used by Material for MkDocs.</p> <p>Text written before learning about the above:</p> <p>Like in Github you can specify a programming language keyword immediately following the leading three backticks to cause the text to be formatted in that language's notation. </p> <p>There is a directory full of examples you can simply click on.</p> <p>Useful keywords include Awk, checksums, DNS Zone, Jupyter Notebook, Python, R, Regular Expression, Rich Text Format, SAS, Shell, sed, SSH Config/filenames, stata, YAML</p> <p>A python example</p> <pre><code>def fn():\npass\n</code></pre>"},{"location":"ourtools/features/#highlighting-text","title":"Highlighting text","text":"<p>https://squidfunk.github.io/mkdocs-material/reference/code-blocks/</p> <p>https://squidfunk.github.io/mkdocs-material/setup/extensions/python-markdown-extensions/#highlight</p> <p>Text can be deleted and replacement text added. This can also be combined into onea single operation. Highlighting is also possible and comments can be added inline.</p> <p>Formatting can also be applied to blocks by putting the opening and closing tags on separate lines and adding new lines between the tags and the content.</p> <p>I could not figure out how to quote plain text correctly so it would be displayed instead of rendered. Here I'm going to use the key symbols to defeat that challenge.</p> <p>Highlight a passage by starting with</p> <p>{ = =</p> <p>and end with </p> <p>= = }</p> <p>Delete text by starting with</p> <p>{ - - </p> <p>and ending with</p> <p>- - }</p> <p>Add Replacement text by starting with</p> <p>{ + +</p> <p>and ending with</p> <p>+ + }</p> <p>This can also be combined using tildes and greater-than characters. See the markdown source code onea single.</p> <p>and comments can be added inline by starting with</p> <p>{ &gt; &gt;</p> <p>and ending with</p> <p>&lt; &lt; }</p>"},{"location":"ourtools/features/#recipe-for-running-mkdocs-locally","title":"Recipe for Running Mkdocs Locally","text":"<p>As of 2024029 these steps are needed to build a local Material for MkDocs server that will run a browser at <code>http://127.0.0.1:8000/</code></p> <p>Warning</p> <p>Because our <code>mkdocs.yml</code> contains some certain material, JRT thinks, <code>mkdocs serve</code> spits out errors if it doesn't find Git supporting files/directories. But you're supposed to be able to create stand-alone web pages outside of Git so it would be nice to understand the interdependency.</p> <pre><code>cd ~/Documents/GitHub/\n\ngit clone https://github.com/jhpce-jhu/jhpce_mkdocs\nor you can use the ssh-key method:\ngit clone git@github.com:jhpce-jhu/jhpce_mkdocs\n\ncd jhpce_mkdocs\n\npip3 install mkdocs-material\npip3 install mkdocs-git-revision-date-localized-plugin\npip3 install mkdocs-open-in-new-tab\npip3 install mkdocs-mermaid2-plugin\nmkdocs build\nmkdocs serve\n</code></pre>"},{"location":"ourtools/features/#errors-you-might-run-into-running-mkdocs-locally","title":"Errors You Might Run Into Running Mkdocs Locally","text":"<p>It can sometimes be useful to Ctrl+C the mkdocs serve program and restart it. Usually this involves significant changes to <code>mkdocs.yml</code> and those will stop over time. However when in doubt give it a try.</p> <p>JRT added some instructions to the mkdocs.yml file causing warnings to be issued. JRT has found them very useful. <pre><code># https://www.mkdocs.org/user-guide/configuration/#validation\nvalidation:\n  omitted_files: warn\n  absolute_links: warn\n  unrecognized_links: warn\n</code></pre></p> <p>The <code>mkdocs serve</code> program will spew out a number of warnings and error messages as you change files. Most of them are important but a few of them are going to recur and are harmless. For example warnings about files in the docs/ tree which are not mentioned in the nav bar. Such files are only going to grow in number. Perhaps there is a way to exclude known cases?</p> This error means you have an error in frontmatter YML code somewhere<pre><code>TypeError: '&lt;' not supported between instances of 'NoneType' and 'str'\nERROR   -  [14:46:28] An error happened during the rebuild. The server will appear\n           stuck until build errors are resolved.\n</code></pre>"},{"location":"ourtools/features/#macdown-wysiwyg-editor","title":"MacDown WYSIWYG Editor","text":"<p>Jeffrey has found that the free MacDown editor is VERY HELPFUL in authoring. It is a MarkDown editor for the Macintosh which displays the source code in one pane and the rendered document in another pane opposite.</p> <p>It renders most of Material for MkDocs material correctly, but not all. This is another reason why it is useful to run \"mkdocs serve\" locally, so you can see in a web browser the results of your edits.</p> <p>There are preferences that are worth enabling. This page lists the MarkDown elements which are enabled and disabled by default. This page discusses extended syntax and the site has other interesting MarkDown reference information.</p> <p>One handy feature: If you copy a web URL, highlight some text in your source code, then click on the link insert symbol in the toolbar, it will automatically paste in the URl as it inserts the square brackets and parentheses to create a URL.</p> <p>Does automatic pattern matching for syntax. Includes a command line program to use to open documents (Jeffrey configured his Mac using Get Info on an .md file to use MacDown by default so he can say in Terminal \"open file.md\" and it opens up the GUI). Supports a variety of themes for those who like dark mode.</p> <p>One flaw in this program is that sometimes the source code pane is blank when you open existing documents. The solution is to quit the program and launch it again. The fast workaround is to grow and shrink the document width and the dividing line between the source and rendered document panes.</p> <p>You can install it by download via the web or with Homebrew with <code>brew install --cask macdown</code> Stats on its page indicate some popularity.</p> <ol> <li> <p>https://squidfunk.github.io/mkdocs-material/reference/footnotes/#adding-footnote-references\u00a0\u21a9</p> </li> </ol>"},{"location":"ourtools/tags/","title":"Tagged Files","text":"<p>Tags and the files they are mentioned in are listed here, automatically generated by Material for MkDocs.</p> <p>While the web site is under development, they guide site authors to documents which need help and notify users how to approach the information found on tagged pages.</p> <p>After the web site content stabilizes, the tags that remain will primarily consist of keywords.</p>"},{"location":"ourtools/tags/#adi","title":"adi","text":"<ul> <li>GUI Applications</li> </ul>"},{"location":"ourtools/tags/#csub","title":"csub","text":"<ul> <li>What Is The C-SUB?</li> <li>New User</li> </ul>"},{"location":"ourtools/tags/#done","title":"done","text":"<ul> <li>Access Overview</li> <li>Submitting Good Queries</li> <li>Self Service MFA, Password Requests</li> <li>Quality of Service (QOS)</li> <li>sacct tips</li> <li>scontrol tips</li> <li>When Will My Job Start?</li> <li>Fastscratch</li> <li>Quotas</li> </ul>"},{"location":"ourtools/tags/#gpu","title":"gpu","text":"<ul> <li>GPU</li> </ul>"},{"location":"ourtools/tags/#in-progress","title":"in-progress","text":"<ul> <li>SSH</li> <li>X11</li> <li>ACL</li> <li>Files Overview</li> <li>Sharing Files</li> <li>External Guides</li> <li>FAQ</li> <li>Tips &amp; Conventions</li> <li>GUI Applications</li> <li>Crafting SLURM Jobs</li> <li>Monitoring Your Jobs</li> <li>Example User Guides</li> <li>Backups &amp; Restores</li> <li>JHPCE-created</li> <li>R Basics</li> <li>SAS</li> </ul>"},{"location":"ourtools/tags/#jeffrey","title":"jeffrey","text":"<ul> <li>SSH</li> <li>X11</li> <li>ACL</li> <li>Files Overview</li> <li>Sharing Files</li> <li>External Guides</li> <li>Job Environment</li> <li>Getting Started</li> <li>Interactive Jobs</li> </ul>"},{"location":"ourtools/tags/#jiong","title":"jiong","text":"<ul> <li>Environment modules</li> <li>SAS</li> <li>Singularity</li> <li>stub page for the \"Software\" topic</li> </ul>"},{"location":"ourtools/tags/#mark","title":"mark","text":"<ul> <li>GPU</li> <li>Cost Calculator</li> <li>Containers</li> </ul>"},{"location":"ourtools/tags/#needs-major-revision","title":"needs-major-revision","text":"<ul> <li>File Transfer - Overview</li> <li>General Tips/Requests</li> <li>Storage Overview</li> <li>Helpful GUI Programs</li> </ul>"},{"location":"ourtools/tags/#needs-review","title":"needs-review","text":"<ul> <li>OneDrive via rclone</li> <li>FAQ</li> <li>Environment modules</li> </ul>"},{"location":"ourtools/tags/#needs-to-be-written","title":"needs-to-be-written","text":"<ul> <li>Data Security</li> <li>GPU</li> <li>Cost Calculator</li> <li>Job Environment</li> <li>Getting Started</li> <li>Adding Your Own Python and R Libraries</li> <li>Containers</li> <li>Jupyter</li> <li>Singularity</li> <li>SOFTWARE TOPIC - page to develop outline</li> <li>stub page for the \"Software\" topic</li> <li>VS Code</li> </ul>"},{"location":"ourtools/tags/#refers-to-old-website","title":"refers-to-old-website","text":"<ul> <li>Joint HPC Exchange</li> <li>SSH</li> <li>X11</li> <li>GPU</li> <li>General Tips/Requests</li> <li>New PI Form</li> <li>New user form</li> <li>R Basics</li> </ul>"},{"location":"ourtools/tags/#slurm","title":"slurm","text":"<ul> <li>Crafting SLURM Jobs</li> <li>Job Environment</li> <li>Getting Started</li> <li>Interactive Jobs</li> <li>Monitoring Your Jobs</li> <li>Node Features</li> <li>Partitions</li> <li>Quality of Service (QOS)</li> <li>Cmd tips &amp; reference</li> <li>SLURM FAQ</li> <li>sacct tips</li> <li>sacctmgr tips</li> <li>scontrol tips</li> <li>Example User Guides</li> <li>When Will My Job Start?</li> </ul>"},{"location":"ourtools/tags/#ssh","title":"ssh","text":"<ul> <li>SSH</li> </ul>"},{"location":"ourtools/tags/#topic-overview","title":"topic-overview","text":"<ul> <li>Access Overview</li> <li>File Transfer - Overview</li> <li>What Is The C-SUB?</li> <li>Files Overview</li> <li>GPU</li> <li>Storage Overview</li> <li>SOFTWARE TOPIC - page to develop outline</li> </ul>"},{"location":"ourtools/tips-conventions/","title":"Tips and Conventions","text":"<p>We aim to create a great web site for our users. Consistency contributes to that result. Here are some conventions and time-saving tips.</p> <p>PLEASE read through the Features page for ideas about ways to present information in the best manner. Materials for MkDocs has so many tools for creating attractive and useful pages!!!</p>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#conventionschecklist","title":"Conventions/Checklist","text":"<p>When editing pages on our site, please keep these things in mind.</p>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#update-tags","title":"Update tags","text":"<p>as needed to reflect current document status. Example <code>needs-to-be-written</code> becomes <code>in-progress</code> as the document is fleshed out and becomes somewhat useful to users.</p>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#remove-authoring-notes","title":"Remove authoring notes","text":"<p>as their guidance is fulfilled by your modifying the document.</p>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#write-information-once-then-refer-to-it","title":"Write information once, then refer to it","text":"<p>Instead of placing versions of the same information in multiple places, put one authoritative version in the right document and then refer to it in other documents where needed. Example: In the FAQ, the answer to a question/issue may be a simple \"See this document\"</p>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#refer-to-specific-locations-within-documents","title":"Refer to specific locations within documents","text":"<p>Jeffrey enabled \"permalink\" so each section of each document can have its own URL.</p>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#images-live-near-their-documents","title":"Images live near their documents","text":"<p>Each topic subdirectory under docs/ has an images/ directory to hold images for documents in that directory. This aids in web site maintenance, as it is more clear over time which of many dozen image files on the web site is used where.</p>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#tips","title":"Tips","text":"","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#linking-to-documents-within-web-site","title":"Linking to documents within web site:","text":"<ul> <li>Because documents are divided up between directories by topic, any references you make to them need to use correct relative paths.</li> <li>Links need to include the \".md\" file name suffixes. These are not shown in the URL on the web site, but are required for links to be make correctly.</li> </ul>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#symbolic-link-image-files-which-change","title":"Symbolic Link Image Files Which Change","text":"<p>We have some documents, such as Orientation PDF, which are updated. During the updates their file names often change in order to embed date versioning info.</p> <p>Instead of embedding links in our web pages to the actual PDF file, and having to find and update all of the links every time the file name changes, Jeffrey has found that creating symbolic links with well-chosen static file names to the variable file names allows the links to remain constant.</p> Make a target named latest-orient.pdf<pre><code>cd docs/orient/images\nln -s JHPCE-Overview-CMS-2023-12-2.pdf latest-orient.pdf\n</code></pre>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#blank-lines-are-required-for-some-features-to-work","title":"Blank lines are required for some features to work:","text":"<p>Some elements, such as lists like this one, rely on there being a blank line above the first item. Same is true for admonitions and details.</p>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#frontmatter-indentation","title":"Frontmatter Indentation:","text":"<p>Items in YAML at the top of many pages has to be indented according to YAML rules, or things break.</p>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#indentation-for-block-content","title":"Indentation for block content:","text":"<p>FOUR spaces is what you need to put in front of each paragraph you want to be included in something like an admonition or detail. FOUR, no more, no less. Four spaces is also needed to nest list items.</p>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#inspect-example-documents","title":"Inspect example documents","text":"<p>if you want to see how something was done in practice. The features page contains many such examples.</p>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#line-numbers-in-code-blocks","title":"Line numbers in code blocks","text":"<p>They had been enabled by default until 20240310, when Jeffrey disabled them. When enabled, you got rid of them for a cod block by adding <code>linenums=\"0\"</code> after the opening three backticks and a space, i.e. ` ` ` Space linenums=\"0\"</p> <p>Now that they have been disabled, if you want line numbering, you should add <code>linenums=\"1\"</code></p>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#add-a-title-too","title":"Add a title, too","text":"<p>to code blocks by adding <code>\"title words\"</code> after the opening three backticks and a space, i.e. ` ` ` Space \" My title \" Space linenums=\"0\"</p>","tags":["in-progress"]},{"location":"ourtools/tips-conventions/#2-ways-of-embedding-code-blocks","title":"2 ways of embedding code blocks:","text":"<ul> <li>With HTML:</li> </ul> <pre><code>[test@compute-107 ~]$ module list\n\nCurrently Loaded Modules:\n  1) JHPCE_ROCKY9_DEFAULT_ENV   2) JHPCE_tools/3.0\n</code></pre> <ul> <li>With Markdown: <pre><code>[test@compute-107 ~]$ module list \n\nCurrently Loaded Modules:\n  1) JHPCE_ROCKY9_DEFAULT_ENV   2) JHPCE_tools/3.0\n</code></pre></li> </ul>","tags":["in-progress"]},{"location":"ourtools/wishlist/","title":"Features we might/should implement","text":""},{"location":"ourtools/wishlist/#places-with-resources-to-investigate","title":"Places with resources to investigate","text":"<p>This best-of-mkdocs is updated regularly and has categorized MkDocs plugins and other solutions generated from github star rankings.</p> <p>This page has a number of recommendations that I find interesting. As always, one has to consider whether something is the best-in-class. The PDF export link below for example hasn't been updated in years. Is it still the right choice? Maybe. Mermaid graph generation plugin, PDF export, page redirects, exclude and exclude-from-search, Jupyter notebook</p>"},{"location":"ourtools/wishlist/#multi-line-column-headers","title":"Multi-line column headers","text":"<p>Maybe this is possible. Would be nice to be able to use more words-per-column without forcing the table to be pushed out and require the use of a scrollbar.</p>"},{"location":"ourtools/wishlist/#absolute-paths","title":"Absolute paths","text":"<p>So references to other documents could be made to a single absolute path. Right now you have to use relative paths, which is just prone to more errors. </p> <p>20240317 - JRT noticed that Adi's use of absolute paths for web portal images were rendered on the web site but not when viewed through a \"mkdocs serve\" session. He changed those links to be relative.</p>"},{"location":"ourtools/wishlist/#sortable-tables","title":"Sortable tables","text":"<p>(Adi has enabled) (but there are other options we might want to enable)</p> <p>They are possible. Might require an extension or plugin.</p> <p>This might have been enabled by adding this to mkdocs.yml</p> <p>Note that tablesort provides alternative comparison implementations like numbers, filesizes, dates and month names. See the tablesort documentation for more information.</p>"},{"location":"ourtools/wishlist/#announcement-bar-in-header","title":"Announcement bar in header","text":"<p>For things like planned outages. Update <code>/overrides/main.html</code> file and replace the message with any custom one. Site needs to be rebuild afterwards for the announcement to propagate to live.</p> <p>To hide the announcement (or any overriden block) use <code>-%</code> at the top block definition and <code>%-</code> at definitioan closing. <pre><code>{% block announce -%}\n{%- endblock %}\n</code></pre> To adjust colors modify <code>docs/stylesheets/extra.css</code> and adjust the <code>.md-banner</code> style definition to match your color preference. <pre><code>.md-banner {\n  background-color: #ffcc00;\n  color: #cc3300;\n}\n</code></pre></p>"},{"location":"ourtools/wishlist/#open-urls-in-new-tabs","title":"Open URLs in new tabs","text":"<p>(Adi has enabled) I think there might be plugins which make this easier than what you have to do othwerwise, which is to use HTML instead of the Markdown notation. In normal HTML you add a space and a string to the end of the URL: <code>target=\"_blank\"</code></p> <pre><code>&lt;a href=\"https://squidfunk.github.io/mkdocs-material/reference/admonitions/\" target=\"_blank\"&gt;About admonitions&lt;/a&gt;\n</code></pre>"},{"location":"ourtools/wishlist/#maybe-a-user-contribution-capability","title":"Maybe a user-contribution capability","text":"<p>For topic headings like SOFTWARE where users have recipes and tuning advice. Implemented how? git pull requests against any page on the site? Is there a way to limit to a subsection?</p>"},{"location":"ourtools/wishlist/#search-enhancements","title":"Search enhancements","text":"<pre><code>plugins:\n  - search\n</code></pre> <p>Search is a plugin. There are many plugins out there for MkDocs. A different set, I suppose, for Material for MkDocs. Some overlap, some exclusive.</p> <p>Note that search is enabled by default but if you add options it HAS TO BE LISTED in the plugins stanza.</p> <p>There are A LOT of extras you can do. Someone explore later if desired.</p> <p>https://squidfunk.github.io/mkdocs-material/setup/setting-up-site-search/</p>"},{"location":"ourtools/wishlist/#blog","title":"BLOG","text":"<p>A blog writable only by site administrators. As a tool for making announcements. <pre><code>plugins:\n  - blog\n</code></pre> Blog is a plugin. https://squidfunk.github.io/mkdocs-material/setup/setting-up-a-blog/ Be aware that you cannot use features preceeded by \"Insiders\" This is enabled by adding a line to the plugins stanza</p> <p><code>- blog</code></p>"},{"location":"ourtools/wishlist/#last-modified-dates-on-documents","title":"last-modified dates on documents","text":"<p>This might be provided by multiple plugins out in the world. The one that might be the most common is \"git-revision-date-localized\"</p>"},{"location":"ourtools/wishlist/#glossary","title":"Glossary","text":"<p>There's a way to create a document which is automatically updated when people define abbrieviations.</p>"},{"location":"ourtools/wishlist/#tabs","title":"Tabs","text":"<p>Jeffrey doesn't quite understand where we would use these yet. But they're very neat. tabs documentation Here is an example of a pair of tabs inside an admonition.</p>"},{"location":"portal/datacatalog/","title":"Database Catalog","text":"<p>The JHPCE Data Catalog provides a way to browse and search an online collection of data sets generated at JHU as well as publicly available ones.</p> <p>The goals of the JHPCE Data Catalog are:</p> <ul> <li>Provide a central place for JHU generated data</li> <li>Facilitate the collaboration between different JHU Departments</li> <li>Help JHU researchers idenfity data sets that relevant to their work</li> </ul> <p>The catalog does not store the data sets but rather provides an index of available ones to help researchers identify data sets pertinent to their work.</p> <p>Warning</p> <p>This is being developed. Please send suggestions about functional matters to bitsupport. After further refinement we will welcome contributions to the database itself.</p> <p>Access requires a JHED credential and a computer that is on campus or using the VPN.</p> <p>https://jhpce-app02.jhsph.edu/</p>"},{"location":"portal/web-apps/","title":"JHPCE Web Enabled User Apps","text":"<p>Our web portal has several sections. You will need to log with your JHED ID and password. This web site is only available on campus, so if you are outside of the school network, you will need login to the JHU VPN first.</p> <p></p> <ul> <li> <p> JupyterLab</p> <p></p> <p>JupyterLab is the latest web-based interactive development environment for notebooks, code, and data. Its flexible interface allows users to configure and arrange workflows in data science, scientific computing, computational journalism, and machine learning. A modular design invites extensions to expand and enrich functionality. The JHPCE JupyterLab session will timeout after 60 minutes of innactivity, a new session will need to be requested if that happens.</p> </li> <li> <p> RStudio</p> <p></p> <p>RStudio is an integrated development environment (IDE) for R. It includes a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging and workspace management. The JHPCE RStudio session will timeout after xxx(Mark?) minutes of innactivity, a new session will need to be requested if that happens.</p> </li> <li> <p> Visual Studio Code</p> <p></p> <p>Visual Studio Code is a lightweight but powerful source code editor. It comes with built-in support for JavaScript, TypeScript and Node.js and has a rich ecosystem of extensions for other languages and runtimes (such as C++, C#, Java, Python, PHP, Go, .NET). You can visit the link below for additional setup and usage details (this link site is only available on campus, so if you are outside of the school network, you will need login to the JHU VPN first.) The Visual Studio Code session will timeout after 12 hours of innactivity, a new session will need to be requested if that happens.</p> <p> Access Instructions</p> </li> </ul> <p>Authoring Note</p> <p>What do users need to know about using this service in practice?</p> <p>How long do sessions run if you don't connect to them? Do they automatically time out?</p> <p>Do users need to do anything to clean up if they change their mind or cannot connect to it or things freeze up? (<code>squeue --me</code> and <code>scancel jobid</code>?)</p> <p>Can you disconnect from and then reconnect to any of these apps?</p>","tags":["in-progress","adi"]},{"location":"portal/web-reset/","title":"JHPCE User Account Tools","text":"<p>Our web portal has several sections.</p> <p>The JHPCE User Account Tools section provide the means to:</p> <ul> <li>Reset your password</li> <li>Request Authenticator Code (\"One Time Password\")</li> <li>Update Contact Information</li> </ul> <p>Warning</p> <p>As of 20240306, C-SUB users cannot use these services, as they are not yet included in an underlying database.</p> <p>Note</p> <p>Your JHPCE cluster username and password are NOT the same as your JHED ID and password. These are maintained by different groups and do not change in one place when changed in the other.</p> <p>Password complexity requirements</p> <p>After you get logged in, use the \"kpasswd\" command to choose a new password. You will need to use a password with three of the following four sets of characters: upper-case, lower-case, numerical digits, and special characters.</p>","tags":["done"]},{"location":"slurm/crafting-jobs/","title":"Crafting SLURM Jobs","text":"<p>Authoring Note</p> <p>This document is accumulating information which might best be split into several more-focused documents. There are many aspects of creating jobs.</p> <p>There are a variety of techniques one can use to initiate SLURM jobs to accomplish various tasks. Here we will initially accumulate pointers to documentation written by others for their clusters. Later we will write concrete examples of our own.</p> <p>In the directories under <code>/jhpce/shared/jhpce/slurm/</code> you will find files used during orientation, some accumulated documents and batch examples.</p>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#sbatch-srun-and-salloc","title":"Sbatch, srun and salloc","text":"<p>There are three commands used to request resources from SLURM. You will find all three discussed in the linked documentation.</p> <p>Here at JHPCE we have been using <code>srun</code> primarily as way to start interactive sessions. However it can also be used inside of <code>sbatch</code> scripts. See web site below for examples.</p> <p>Be careful using <code>salloc</code> that you don't leave allocated resources unused.</p>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#sbatch-rules","title":"Sbatch Rules","text":"<ol> <li>First characters in batch file need to be: <code>#!/bin/bash</code> (although you can use an interpreter other than bash)</li> <li><code>#SBATCH</code> directives need to appear as the first characters on their lines.</li> <li><code>#SBATCH</code> directives need to appear before any shell commands.</li> <li>You can put comments after # symbols.</li> <li>You may need to add a <code>wait</code> command at the bottom to ensure that processes spawned earlier complete before the script does.</li> </ol>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#slurm-directive-order-of-precendence","title":"SLURM Directive Order of Precendence","text":"<p>For now see these two PDF pages from an orientation document.</p>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#job-environment","title":"Job Environment","text":"<p>Authoringnote</p> <p>This probably deserves its own document. There are a variety of things to describe here, some subtle. Options to pass or not pass parts of environment used to dispatch job into the job. Should people use the <code>-l</code> arg to bash? <code>#SBATCH --chdir=</code></p>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#inputoutput-considerations","title":"Input/output Considerations","text":"<p>Authoringnote</p> <p>Use the same terms as used in the storage overview. We want to be consistent. It helps users, and helps us make links between related articles.</p> <ul> <li>home directory</li> <li>local compute node /tmp</li> <li>fastscratch</li> <li>project storage</li> </ul> <p>Some programs have specific variables you can set to indicate where files should be created.</p> <p>SAS has \"WORK\" -- is this set to something in the module load process?</p> <p>R has \"TEMPDIR\" which defaults to /tmp.</p> <pre><code>You could use your 1TB of fastscratch space for this. So your SLURM script could use commands like:\n\nmodule load conda_R\nexport TEMPDIR=$MYSCRATCH\nR CMD BATCH myprog.R\n</code></pre>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#dependent-jobs","title":"Dependent jobs","text":"<p>You can configure jobs to run in order with some conditional control. See this part of the sbatch manual page.</p>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#heterogeneous-job-support","title":"Heterogeneous Job Support","text":"<p>Each component of such jobs has virtually all job options available including partition, account and QOS (Quality Of Service). See this vendor document.</p>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#examples-from-elsewhere","title":"Examples from Elsewhere","text":"","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#workflow","title":"Workflow","text":"<p>This cluster has some good material about workflows.</p>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#nersc-examples","title":"NERSC Examples","text":"<p>Good examples.</p>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#usc-examples","title":"USC Examples","text":"<p>Good examples of basic different types of batch jobs</p>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#running-multiple-jobs-from-one-script","title":"Running Multiple Jobs From One Script","text":"<p>Using srun inside of sbatch scripts, in serial and parallel. Remember to include the <code>wait</code> bash command at the end of your batch file so the job doesn't end before all of the tasks inside of it.</p>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#using-signals-to-clean-upcheckpointing","title":"Using signals to clean up/checkpointing","text":"<p>It's a Good Thing to save the state of your computation so that you can pick up where you left off if your job ends earlier than expected.  We should provide some links to existing documentation people have written about how to implement checkpointing.</p> <p>It's also a Good Thing to clean up after yourself, by, for example, deleting files created in /tmp by your job.</p> <p>If a job is cancelled or killed because it exceeds its time limit (maybe memory too?), SLURM sends two signals some time apart. Normally the first is a TERM signal, later a KILL signal. You can dispatch jobs with instructions to send them specific signals a specified number of seconds before the KILL signal is sent.</p> <p>You can modify your batch jobs so they do Good Things when they receive the first signal.</p> <p>See the sbatch manual page's explanation for the <code>--signal</code> argument.</p> <p>Pay attention to which process(es) are sent signals. The batch job, all of the job steps, ...</p> <p>Here is a blog post which discusses this in some detail.</p> <p>That post refers to this one which was updated after the post was written, so there might be newer info than was incorporated in the post.</p> <p>This stackoverflow answer seems to take a different approach. This is an advanced topic and will require some care and perhaps experimentation to verify your solution.</p>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#example-batch-jobs","title":"Example Batch Jobs","text":"","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#copying-data-within-cluster","title":"Copying data within cluster","text":"<p>Here is a sample batch job. More information about this topic is accumulating here.</p> Click to expand <p>Content. How hard will it be to do code blocks? <pre><code>#!/bin/bash\n\n#SBATCH -p shared\n#SBATCH --mem=10G\n#SBATCH --job-name=cp-files\n#SBATCH --time=15-0\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=1\n#SBATCH --output=cp-files-%j.out    # file to collect standard output\n#SBATCH --error=cp-files-%j.err # file to collect standard output\n#SBATCH --mail-user=my-email-address@jhu.edu\n#SBATCH --mail-type=BEGIN,FAIL,END\n\ndate\ncd /dcs04/sample/path/\n\necho \"I am running on compute node:\"\nhostname\n\necho \"In directory:\"\npwd\n\necho \"The files found in this directory are:\"\n/bin/ls\n\n# args are meant to try to prevent files from being deleted in destination\nrsyncargs=\"-h --progress --sparse --numeric-ids --one-file-system --stats --ignore-existing --max-delete=0\"\n\necho \"about to try to rsync\"\n\nrsync -a $rsyncargs directory-to-be-copied /dcs05/destination/path/\n\ndate\necho \"done\"\n</code></pre></p>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#copying-data-intoout-of-cluster","title":"Copying data into/out of cluster","text":"<p>We have a transfer node which is a SLURM client.</p>","tags":["in-progress","slurm"]},{"location":"slurm/crafting-jobs/#running-a-job-on-every-node","title":"Running A Job On Every Node","text":"<p>This is put here as a tool for system administrators needing to do maintenance where a SLURM job is appropriate. Maybe the technique will be useful for someone for a more limited case.</p> Click to expand <pre><code>#!/bin/bash\n#\n# JPHCE - dispatch-to-everynode - Dispatch a job to each node which is responding\n#\n#       FAILS TO WORK IF YOU DON'T SPECIFY A BUNCH OF PARTITIONS\n#       BECAUSE SHARED IS USED. Following worked at this time\n#       #SBATCH --partition=shared,cee,transfer,sysadmin,sas,gpu,bstgpu,neuron\n#\n# You need to specify a batch file at the minimum\n# You can specify additional arguments\n# TODO: Nice to be able to specify a partition to sinfo if desired\n#--------------------------------------------------------------------------\n#--------------------------------------------------------------------------\n# Date          Modification                                       Initials\n#--------------------------------------------------------------------------\n# 20231222      Created, added standard comment section.                JRT\n#--------------------------------------------------------------------------\n\nusage()\n{\necho \"Usage: $0 [directives..] batchfile \"\necho \"Usage:   Specify at least a job file\"\necho \"Usage:   Good idea to include in your batch file --output=/dev/null\"\nexit 1\n}\n\nif [ $# -lt 1 ]; then\n        usage\nelse\n        for i in `sinfo -N -r | awk '{print $1}' | sort -u | grep -v NODELIST`\n        do\n                echo $i\n                sbatch --nodelist=${i} \"$@\"\n        done\nfi\n</code></pre>","tags":["in-progress","slurm"]},{"location":"slurm/environment/","title":"SLURM Job Environments","text":"<p>Warning</p> <p>There are useful things we can document about controlling the job execution environment. This is fairly low priority though, as most things Just Work. </p>","tags":["needs-to-be-written","jeffrey","slurm"]},{"location":"slurm/environment/#overview-of-what-might-be-covered-here","title":"Overview of what might be covered here","text":"<p>Some parts of the environment in the shell you submit a job are copied into the job's environment. This can be controlled with certain SLURM arguments.</p> <p>Some clusters strongly advise their users to create batch scripts in which the <code>#!/bin/bash</code> first line has a <code>-l</code> flag. Because shells like bash process \"dot files\" (e.g. <code>.profile</code> and .<code>bashrc</code>) differently for login versus interactive shells. Perhaps this can explain subtle behaviors you notice. Perhaps this is more important in some clusters than others because of the way accounts are provisioned when created.</p> <p>SLURM sets a large number of shell environment variables for jobs to consult if desired.  A good list can be found in the sbatch manual page's INPUT ENVIRONMENT VARIABLES and OUTPUT ENVIRONMENT VARIABLES sections.</p> <p>You can see some of them by starting an interactive session and running <code>printenv | grep -i slurm</code> (there may be others that are set for jobs depending on their type and arguments -- array jobs, dependent jobs, ???).</p> <p>The way SLURM commands operate can be influenced by setting some certain environment variables, such as SLURM_TIME_FORMAT, SACCT_FORMAT, SQUEUE_FORMAT, SQUEUE_FORMAT2, SQUEUE_SORT. It can be useful to define these in aliases or shell scripts to format output in ways you need. Simply changing the value of these variables can produce vastly different output for commands like sacct and squeue.</p> <p>Are there any tricks to propagating information between components of a job? I mean setting your own variables in batch job scripts and having them be visible by all of the processes you mean to use them?</p> <p>When modifying environment variables in shell scripts or your current shell, remember that you may be dealing with existing information that you don't want to discard (by redefining the variable without referring to the existing value). When dealing with variables that you don't make up out of whole cloth and which have simple names which might match existing ones, check for their existence first. If they exist, you may want to prepend your changes, say to a PATH-type variable which usually has multiple entries. Or append, if you want system defaults to come before your values.</p> <p>Remember that modules change environment variables when loaded and unloaded. User's default environments are controlled by some JHPCE-created modules. </p>","tags":["needs-to-be-written","jeffrey","slurm"]},{"location":"slurm/environment/#until-this-is-fleshed-out","title":"Until this is fleshed-out...","text":"<p>Consult our list of good documentation at other clusters.</p> <p>Send suggestions of items to include here to bitsupport.</p>","tags":["needs-to-be-written","jeffrey","slurm"]},{"location":"slurm/getting-started/","title":"Introduction to SLURM","text":"<p>Until we write this, please</p> <ol> <li>see the orientation document (pdf)</li> <li>check out other SLURM-related pages on this web site. There is already some great information here. The commands tip and reference document contains links to manual pages and pages we've written with guidance and examples.</li> <li>If you can't find what you are looking for here, we have a collection of good documentation from other clusters here.</li> </ol>","tags":["needs-to-be-written","slurm","jeffrey"]},{"location":"slurm/interactive-jobs/","title":"Interactive Jobs","text":"","tags":["slurm","jeffrey"]},{"location":"slurm/interactive-jobs/#the-essentials","title":"The essentials","text":"<p>The core command to create an interactive session is:</p> <p><code>srun --pty --x11 bash</code></p> <p>The last element of an srun command has to be a program.</p> <p>The <code>--x11</code> is optional, and only needed if you are going to be running X11 programs during your session. Omitting it can avoid a number of issues.</p>","tags":["slurm","jeffrey"]},{"location":"slurm/interactive-jobs/#shortcuts","title":"Shortcuts","text":"<p>Warning</p> <p>If you want to type 5 characters instead of 22 every time you want to create an interactive job, read on and indicate that this page was helpful.  If you like to type every last character of every command, skip this section.</p> Here are two equivalent commands. Which would you rather use? <code>srun --pty --x11 --mem=20G -p interactive bash</code> <code>jsrun --mem=20G -p interactive</code> <p>You can define aliases and bash routines in your <code>.bashrc</code> file for commands you use frequently.  Bash functions can be useful for commands that are difficult to specify in simple shell aliases. You can view the definition of aliases with <code>alias</code> and bash routines with the command <code>declare -f function_name</code>.   Changes to your <code>.bashrc</code> file aren't available to your currently running shell unless you log out and back in again, launch a new shell on top of the old one, or simply have your current shell re-read the file (\"source it\") with <code>. .bashrc</code> The following routines can be copied to your buffer by hovering your mouse over the right-hand side and clicking on the copy icon which appears (faintly).</p> <p>jsrun - JHPCE srun with X11 support: <pre><code>jsrun() { if [ -z ${DISPLAY} ]; then /usr/bin/srun --pty \"$@\" bash; else /usr/bin/srun --pty --x11 \"$@\" bash; fi }\n</code></pre></p> <p>jxrun - JHPCE srun when you want to skip X11 entirely:</p> <p><code>jxrun() { /usr/bin/srun --pty \"$@\" bash; }</code></p> <p>These examples inclue <code>$@</code> symbols, which are replaced by any additional arguments you provide. The srun command requires bash or another program to come last, which is one of the reasons why a simple shell alias can't be used. You have to create either a shell script or a routine.</p> <p>So you can use these functions like a normal srun command, e.g.</p> <p><code>jsrun --mem=3G -p transfer</code></p>","tags":["slurm","jeffrey"]},{"location":"slurm/monitoring/","title":"Monitoring SLURM Jobs","text":"","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#overview","title":"Overview","text":"<p>Has my job ended? Why did my job fail? How much memory did my sample job use so I can use memory efficiently in future similar jobs?<sup>1</sup> There are a number of ways in which you can learn the answers to these questions. The state of the job will determine which tools and techniques you use.</p>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#job-states","title":"JOB STATES","text":"<p>Until we draw a nice diagram, a written description will have to suffice. Here we focus on batch jobs and common states. Job states have short names consisting of one or two capitalized letters, and a full name. Short names are introduced in parentheses below. We have placed a copy of the list in <code>/jhpce/shared/jhpce/docs/job-states.txt</code>.</p> <p>Batch jobs consist of several job steps, two at minimum (\"batch\"<sup>2</sup> and \"extern\"<sup>3</sup>). The overall job and each step has its own job state code. They often differ. The <code>-X</code> flag to sacct will show you only the overall job state, such as FAILED, but some times you need to check the state of all of a jobs steps in order to see that a \"batch\" step ran OUT_OF_MEMORY.</p> <ol> <li>User submits job</li> <li>SLURM evaluates syntax and resource requests.</li> <li>If problems found, then job is rejected immediately.</li> <li>Otherwise it is accepted and becomes PENDING (PD).</li> <li>PENDING jobs can be held, CANCELLED (CA) or be dispatched to compute node(s) to start RUNNING (R).</li> <li>RUNNING jobs can immediately run into a problem due to coding errors and become FAILED (F).</li> <li>RUNNING jobs can run correctly but then exceed their memory allocation and become OUT_OF_MEMORY (OOM).</li> <li>RUNNING jobs can run correctly but run into their wall-clock time limit and become DEADLINE (DL) or FAILED.</li> <li>RUNNING jobs can run correctly, switch to COMPLETING (CG) as processes are quitting, and then COMPLETED (CD).</li> </ol>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#pending-jobs","title":"PENDING JOBS","text":"<p>Jobs waiting to run will sit \"in the queue.\" They will be shown to have a \"Reason\"</p>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#tools-for-pending-jobs","title":"Tools for pending jobs","text":"<p><code>squeue --me</code></p> <p><code>scontrol show job</code> - this only works for pending and running jobs.</p>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#running-jobs","title":"RUNNING JOBS","text":"","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#how-to-get-information-about-running-jobs","title":"How to get information about running jobs?","text":"<p>If you want or need to get more information about your jobs, you should add \"instrumentation\" to them. Instrumentation is any of a number of techniques which gather and save or print information for you to inspect. A trivial example is adding a command in your batch file script that echoes \"I'm running on node\" and then runs the hostname command.</p> <ol> <li><code>scontrol show job</code></li> <li>Look at their output and error files</li> <li>Look at files they are writing to</li> <li>Use sstat to inspect parameters SLURM has collected for the job</li> <li>Use sattach to connect to the input/output of your script on the leading node of a job.</li> <li>Log into a node and inspect system state with commands like <code>ps</code> or <code>htop</code></li> </ol>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#completed-jobs","title":"COMPLETED JOBS","text":"<p>Here we mean jobs that are no longer running, whether they succeeded or failed for some reason.</p>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#how-to-get-information-about-completed-jobs","title":"How to get information about completed jobs?","text":"<p>If you want or need to get more information about your jobs, you should add \"instrumentation\" to them. Instrumentation is any of a number of techniques which gather and save or print information for you to inspect. A trivial example is adding a command in your batch file script that echoes \"I'm running on node\" and then runs the hostname command.</p> <ol> <li>Look at their output and error files</li> <li>Look at files they wrote to</li> <li>Use sacct to inspect parameters about the job, including their exitcode</li> </ol> <p>Exit codes are poorly documented, unfortunately.</p> <p><code>scontrol show job</code> doesn't work for completed jobs.</p>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#investigating-failures","title":"INVESTIGATING FAILURES","text":"<p>Authoring Note</p> <p>This might warrant a dedicated page.</p>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#tool-set","title":"TOOL SET","text":"<p>Here is a list of tools and techniques. You may use the same command to look at jobs in different states so we've gathered details here rather than repeating them in every section above.</p>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#email-notification","title":"Email Notification","text":"<p>You can direct SLURM to send you email when various things happen with your job. These directives can be given on the command line, in batch job scripts, and set in your SLURM defaults file. You can even modify running jobs to set or change their notification settings (see the scontrol tips page).</p> <p>Warning</p> <p>Take care not to cause a storm of outgoing email from our cluster!!! This will lead to our server being blacklisted by Hopkins and/or other mail administrators. Then NO ONE will get email until we can convince them that it won't happen again.</p> <p>By default email notifications are sent for entire job arrays, not individual tasks. Be VERY careful if you change that behavior.</p> <p>The mail arguments are shown in the sbatch manual page.</p> Specify your email address<pre><code>--mail-user=&lt;email-address&gt;\n</code></pre> Specify notification events<pre><code>--mail-type=&lt;list-of-types&gt;  # comma-separated\n</code></pre> Here are the main types: <ul> <li>NONE, BEGIN, END, FAIL, INVALID_DEPEND</li> <li>ALL (equivalent to BEGIN, END, FAIL, INVALID_DEPEND, REQUEUE, and STAGE_OUT)</li> <li>TIME_LIMIT, TIME_LIMIT_90 (reached 90 percent of time limit), TIME_LIMIT_80 (reached 80 percent of time limit), TIME_LIMIT_50 (reached 50 percent of time limit)</li> </ul>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#output-and-error-files","title":"Output and error files","text":"<p>By default your job will store an output file named \"slurm-%j.out\" where the \"%j\" is replaced by the job ID containing job output and errors in the same directory in which your job ran. You can direct SLURM to put the file(s) elsewhere and change their names.</p> <p>For job arrays, the default file name is \"slurm-%A_%a.out\", \"%A\" is replaced by the job ID and \"%a\" with the array index. </p> <p>If you add echo statements in your job batch file then you can inspect the job output/error files for clues as to its status.</p>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#squeue","title":"squeue","text":"<p>squeue - Display information about pending and running jobs.</p>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#sstat","title":"sstat","text":"<p>Display process statistics of a running job/step. Some of the advice given for <code>sacct</code> (below) applies to <code>sstat</code>.</p> <p>https://slurm.schedmd.com/archive/slurm-22.05.9/sstat.html</p>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#scontrol-show-job","title":"scontrol show job","text":"<p>The <code>scontrol</code> command has many uses. Before a job ends you can get detailed information with <code>scontrol</code>.</p> <p>Yay</p> <p>We have written a document describing frequent uses of scontrol. See this page.</p>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#sacct","title":"sacct","text":"<p>sacct - Display accounting data for running and completed jobs in the Slurm database.</p> <p>Yay</p> <p>We have written a document describing key elements of using sacct. See this page.</p>","tags":["in-progress","slurm"]},{"location":"slurm/monitoring/#suggestions-to-a-user","title":"Suggestions to a user","text":"<p>Note</p> <p>The following was sent to a user who was having SAS jobs fail with errors indicating a problem with space or quota.</p> <p>Instrumenting your job means adding commands to it to gather information. Running df commands to check the size and capacity of all or specific file systems. (df -h -x tmpfs might be a helpful variant). As mentioned in the orientation material, the sstat command can gather information for running jobs (as opposed to sacct which is oriented towards completed jobs). Some of the output fields available via sstat and sacct relate to memory usage while others can reveal disk input/output volumes.</p> <p>Because your batch job script might not be able to run sstat\u2019s during SAS\u2019s execution, you may need to run the information-gathering commands interactively or via a second batch job. (I mean your batch job could run commands before or after invoking SAS, unless they put the SAS program into the background they won\u2019t be able to run the commands while SAS is running. I don\u2019t know what happens if one tries to run a program in the background (by putting an &amp; after it, like one can run thunar for example) inside of a SLURM batch job.</p> <p>Your gathering might involve the sleep command in between invocations. I would suggest also running the date command so you have timestamps.</p> <p>You could put the sleep, date, sstat commands inside of a while (true) loop. Then cancel the loop with a control c or scancel depending on whether they are running interactive or batch. Redirecting the output to text files would be useful.</p> <p>So your information-gathering efforts should probably start by running some sacct commands to inspect the parameters of previous failed jobs, and perhaps even the ones that succeeded to see if any differences appear.</p> <p>The -e flag is available to both sstat and sacct to show the fields available. The sets overlap but also differ.</p> <ol> <li> <p>Making sure your jobs request the right amount of RAM and the right number of CPUs helps you and others using the clusters use these resources more efficiently, and in turn get more work done more quickly.\u00a0\u21a9</p> </li> <li> <p>The batch script that you have created to run your commands.\u00a0\u21a9</p> </li> <li> <p>The external step is the connection SLURM makes to the compute node to begin executing your job.\u00a0\u21a9</p> </li> </ol>","tags":["in-progress","slurm"]},{"location":"slurm/node-features/","title":"Node Features","text":"<p>Warning</p> <p>For advanced users who want the highest performance at the expense of possibly waiting longer for jobs to start and maintaining multiple versions of code. We cannot advise you on building optimized code.</p> <p>JHPCE has a wide variety of compute nodes. Some have GPU processors, some have large amounts of memory, and there are many models of CPUs present. We tend to keep equipment running as long as possible.</p> <p>SLURM allows for the assignment of keywords to nodes so that users can guide their jobs to appropriate machines. This is, of course, in addition to the other methods of indicating resource needs, such as desired partition(s), amount of memory, and the need for a GPU.</p> <p>If you believe that your code will gain a lot from being run on specific kinds of CPUs, you can compile it with optimization flags to perform well on them. Of course, you have then created binaries which might fail to run altogether on older nodes. Please name your binaries in a way which makes their special status apparent to you down the road, in case you forget. That might be a challenging puzzle to figure out.</p> <p>One could, at run-time, write batch job scripts which check the features of the node they were assigned, and choose to execute code highly-optimized for that node's CPU.</p>","tags":["slurm"]},{"location":"slurm/node-features/#current-tag-categories","title":"Current tag categories","text":"<p>Currently we have defined features for:</p> <ul> <li>CPU manufacturer (intel,amd)</li> <li>CPU line (e.g. Opteron)<sup>1</sup></li> <li>CPU cpu-type architecture as used by the gcc compiler (see below)</li> <li>presence of a GPU</li> <li>GPU model</li> <li>GPU with memory amount</li> <li>RAM amount in 250Gb increments at 500 and above<sup>1</sup></li> </ul>","tags":["slurm"]},{"location":"slurm/node-features/#using-features-with-slurm-jobs","title":"Using Features with SLURM Jobs","text":"<p>You can tell the scheduler that you prefer or require features using the <code>--prefer=string</code> or <code>--constraint=string</code> when using <code>srun</code> or <code>sbatch</code> or <code>salloc</code></p> <p>Of course, saying that you prefer a feature means that your job might be sent to nodes which lack that feature. If your code requires a feature, then this will mean that your job has fewer nodes on which it might run and might stay pending for longer.</p> <p>See the <code>--prefer</code> and <code>--constraint</code> sections of the sbatch manual page for descriptions of using AND and OR operators to combine features. Sadly it does not seem possible to simply exclude features (so you could say I want any node except ones with these features (because they are too old for my code)).</p> <p>Tip</p> <p>When specifying multiple features, you may need to enclose them in double quotes. The symbols used for AND, OR and number of matches are all ones which the bash shell will mis-interpret.</p>","tags":["slurm"]},{"location":"slurm/node-features/#viewing-features","title":"Viewing Features","text":"<p>These features keywords are up to systems administrators to choose and define by adding \"Features=string1,string2\" to \"NodeName=\" entries in <code>/etc/slurm/nodes.conf</code></p> <p>For any particular node, you can see features information with the command <code>scontrol show node nodename</code></p> <p>If you specified a feature for a job, it will appear in the output of <code>scontrol show job jobid</code></p>","tags":["slurm"]},{"location":"slurm/node-features/#cpu-related-feature-info","title":"CPU-Related Feature Info","text":"","tags":["slurm"]},{"location":"slurm/node-features/#manufacturer","title":"Manufacturer","text":"<p>JHPCE has CPUs made by both Intel and AMD.</p> <p>So one feature that has been defined for our nodes is the CPU manufacturer: <code>amd</code> or <code>intel</code></p>","tags":["slurm"]},{"location":"slurm/node-features/#instruction-set-extensions","title":"Instruction Set Extensions","text":"<p>As time has passed, computer science has progressed and users have needed new kinds of computation to be as fast as possible, CPU manufacturers have decided that it is worth extending the assembly language used in central processing units because there were significant gains for notable use cases. Nothing is faster than silicon inside of a CPU core, so moving frequent calculations into CPU designs provides notable performance gains for some code sets.</p> <p>The x86 instruction set is used on all JHPCE nodes. It has a number of extensions. The x86 Wikipedia page includes pointers to them.</p> <p>Extensions are listed as \"flags\" when you look at the output of <code>less /proc/cpuinfo</code> on a particular node.</p>","tags":["slurm"]},{"location":"slurm/node-features/#cpu-types","title":"CPU \"Types\"","text":"<p>Instead of listing all of the extensions as features, we instead use cpu-type as defined by the authors of gcc.</p> <p>The GNU C/C++ compiler suite is the most commonly used one for those languages. See this page for cpu-type details, including which extensions each type represents.</p> <p>This command was run on each node to determine its cpu-type:</p> <p><code>/usr/bin/gcc -march=native -Q --help=target | grep -- '^[ ]*-march' | cut -f3</code></p>","tags":["slurm"]},{"location":"slurm/node-features/#building-optimized-code","title":"Building Optimized Code","text":"<p>That is beyond the scope of this document.</p> <p>\u201cmtune\u201d and \u201cmarch\u201d are important gcc flags to investigate.</p> <p>The various levels of optimization requested via <code>-O#</code> might also impact the flexibility of the binaries you build.</p> <p>Note</p> <p>If you find good documents that would help other users optimize their binaries, please let us know at the bitsupport address.</p>","tags":["slurm"]},{"location":"slurm/node-features/#frequency-by-cpu-type","title":"Frequency By CPU-type","text":"<p>In January 2024, the cluster compute nodes consisted of approximately</p> <pre><code>      3 bdver1\n      7 bdver2\n     10 broadwell\n      2 cascadelake\n     11 haswell\n     17 icelake-server\n      5 skylake-avx512\n      4 znver2\n      2 znver3\n</code></pre> <p>The bdver and znver types represent AMD CPUs.</p> <p>Perhaps the largest delta in compiler flags is between bdver1 and the rest. bdver1 does not support these gcc flags:   -mbmi   -mf16c   -mfma   -mdirect-extern-access</p> <ol> <li> <p>It's not clear that these tags add much value. The RAM tags were thought to perhaps aid someone trying to increase memory locality. SLURM's scheduler, will, of course, allocate nodes with enough free memory to meet the jobs requirements.\u00a0\u21a9\u21a9</p> </li> </ol>","tags":["slurm"]},{"location":"slurm/partitions/","title":"Partitions","text":"<p>A partition is a logical collections of nodes that comprise different hardware resources and limits to help meet the wide variety of jobs that get scheduled on the cluster. Nodes can belong to more than one partition.</p> <p>There are several types of partitions:</p> <ul> <li>General access (e.g. shared, interactive, gpu, transfer)</li> <li>Application only (e.g. sas)</li> <li>GPU (equipped with GPU cards)</li> <li>PI-owned (for use only by members of the PI's group)</li> </ul>","tags":["slurm"]},{"location":"slurm/partitions/#pi-partitions","title":"PI Partitions","text":"<p>JHPCE exists because Primary Investigators worked together to create a cluster. They share their resources via public partitions (see below).</p> <p>Only submit jobs to these partitions if you are a member of the Primary Investigator's research groups or have been given explicit permission to do so. If you are in doubt, ask before submitting. Jobs from non-group members will be killed and repeated abuse will lead to repercussions.  </p>","tags":["slurm"]},{"location":"slurm/partitions/#public-partitions","title":"Public Partitions","text":"<p>Partitions shared, interactive, gpu, sas and transfer are considered public and available to all.</p> <p>Specific use</p> <p>Only jobs which require the use of GPU cards should be submitted to the gpu partition.</p> <p>Only jobs which require the use of the SAS application should be submitted to the sas partition.</p> <p>Only jobs related to transferring data into or out of the cluster should be submitted to the transfer partition.</p> <p>The public partitions provide low-priority access to unused capacity throughout the cluster. Capacity on the shared queue is provided on a strictly \u201cas-available\u201d basis and serves two purposes.</p> <p>First it provides surge capacity to stakeholders who temporarily need more compute capacity than they own, and second, it gives provides non-stakeholders access to computing capacity.</p> <p>Scheduling polices attempt to harvest unused capacity as efficiently as possible while mitigating the impact on the rights of stakeholders to use their resources. The JHPCE service center does not guarantee that stakeholders will provide sufficient excess capacity to meet non-stakeholders needs, however in practice the cluster is rarely operating at full capacity so there is usually ample computing capacity on the shared queue.</p>","tags":["slurm"]},{"location":"slurm/partitions/#getting-info-about-partitions","title":"Getting Info About Partitions","text":"<p>Our command <code>slurmpic</code> shows information about partitions, including the member nodes, their current utilization, and some summary statistics.<sup>1</sup> By default it displays the shared partition. Specific partitions can be displayed using <code>slurmpic -p partitionname</code>. All of the nodes in all of the GPU partitions can be displayed with <code>slurmpic -g</code>. Run <code>slurmpic -h</code> to see usage notes.</p> <p>The best way to see the configuration of a partition is with the scontrol command. (Vendor's scontrol manual page. Our local scontrol tips page.) <pre><code>scontrol show partition partitionname\n</code></pre></p> <p>The command <code>sinfo</code> shows information about all of the partitions. It has many options, so you can also use it to see information about nodes. (Note: Partitions which require group membership to submit to are only visible via <code>sinfo</code> to members of those groups. Because the local command <code>slurmpic</code> uses <code>sinfo</code> to retrieve information, the output of <code>slurmpic -a</code> (show all nodes) will omit those private PI partitions' nodes.)</p>","tags":["slurm"]},{"location":"slurm/partitions/#cpu-partitions","title":"CPU Partitions","text":"","tags":["slurm"]},{"location":"slurm/partitions/#public-cpu-partitions","title":"Public CPU Partitions","text":"<p>Limits for CPU cores, RAM and Time (default/maximum)</p> Name Type Core RAM Time Notes/Use shared public 100 1TB (1d/90d) DEFAULT interactive public 2 20gb (1d/90d) Small but accessible gpu public (none) (none) (1d/90d) Only for GPU jobs sas application (none) (none) (none/90d) Licensed for SAS transfer public no (none) (none) (none/90d) <p>To reduce table width, column names are terse.</p>","tags":["slurm"]},{"location":"slurm/partitions/#pi-cpu-partitions","title":"PI CPU Partitions","text":"<p>Limits for CPU cores, RAM and Time (default/maximum)</p> Name Type Core RAM Time Notes/Use bader PI (none) (none) (none/90d) bluejay PI (none) (none) (none/90d) UNIX group cancergen PI (none) (none) (none/90d) caracol PI (none) (none) (none/90d) UNIX group cee PI (none) (none) (none/90d) cegs2 PI (none) (none) (none/90d) chatterjee PI (none) (none) (none/90d) echodac PI (none) (none) (none/90d) gwas PI (none) (none) (none/90d) not yet defined hl PI (none) (none) (none/90d) hpm PI (none) (none) (none/90d) not yet defined hongkai PI (none) (none) (none/90d) mommee PI (none) (none) (none/90d) stanley PI (none) (none) (none/90d) UNIX group sysadmin admin (none) (none) (none/90d) For system testing","tags":["slurm"]},{"location":"slurm/partitions/#gpu-partitions","title":"GPU Partitions","text":"<p>Limits for CPU cores, RAM and Time (default/maximum)</p> Name Type Requires Approval Core RAM GPU Time Notes/Use gpu public no (none) (none) (none) (1d/90d) bestgpu PI yes (none) (none) (none) (none/90d) caracol PI yes (none) (none) (none) (none/90d) neuron PI yes (none) (none) (none) (none/90d) <ol> <li> <p>Note that the statistics displayed are for that partition, not the whole cluster. Also, memory and CPU use of nodes that are DOWN or in DRAIN are not included in the stats.\u00a0\u21a9</p> </li> </ol>","tags":["slurm"]},{"location":"slurm/qos/","title":"Quality of Service","text":"<p>Systems administrators can define resource limits called QOS and assign them to a variety of objects, mainly users and job partitions. We use them to share resources equitably and to allow exceptions.</p> <p>For example, we have a QOS named <code>shared-default</code> which is normally set to allow a user to use 100 CPU cores and 1TB of RAM at any one time in the <code>shared</code> partition.  These values were chose to represent roughly 20% of those available in that partition. When Primary Investigators who own nodes need to remove them from the shared partition for their own use, that QOS' definition can be changed to a lower value to maintain the 20% goal.</p> <p>Vendor QOS documentation about them can be found here. There are also entries in the manual pages for various SLURM commands about QOS<sup>1</sup>.</p> <p>QOS definitions for users and partitions are stored in a database.</p> <p>We have a document containing useful QOS-related commands. Those commands include ones which allow you to see the value of a QOS like <code>interactive-default</code></p> <p>See our currently defined QOS in a readable format:</p> <p><code>sacctmgr show qos format=Name%20,Priority,Flags%30,MaxWall,MaxTRESPU%20,MaxJobsPU,MaxSubmitPU,MaxTRESPA%25</code></p>","tags":["done","slurm"]},{"location":"slurm/qos/#partition-qos","title":"Partition QOS","text":"<p>Job partitions like <code>shared</code> have two QOS-related attributes:</p> <ol> <li> <p>Qos - If present, this specifies the QOS which by default applies to all jobs submitted. The <code>interactive</code> partition has <code>QoS=interactive-default</code></p> </li> <li> <p>AllowQoS - By default, this value is set to ALL. If set to a comma-separated list, then only those can be used or requested by users. The <code>interactive</code> partition has <code>AllowQos=normal,interactive-default</code></p> </li> </ol> <p>You can see the configuration of a partition with the scontrol command. (Vendor's scontrol manual page. Our local scontrol tips page.) Here is a command which will show you the QOS attributes on an exmple partition named partitionname</p> <pre><code>scontrol show partition partitionname | grep -i qos\n</code></pre>","tags":["done","slurm"]},{"location":"slurm/qos/#user-qos","title":"User QOS","text":"<p>User accounts have two QOS-related attributes:</p> <ol> <li> <p>Qos - Our users (currently) all have a QOS value of \"normal\", (which is inherited from their parent account, named \"jhpce\").  The \"normal\" QOS  (currently) has no limits defined for it.</p> </li> <li> <p>Allowed Qos - By default, this value is empty. If set to a comma-separated list, then the user can choose to submit jobs using one of them.  Jobs request a QOS using the \"--qos=\" option to the sbatch, salloc, and srun commands. (If the partition does not allow a QOS to be used, then your job will be rejected.)</p> </li> </ol> <p>See your own user database values: <code>sacctmgr show user withassoc where name=your-cluster-username</code></p> <p>The SLURM FAQ includes an entry about the error you receive if you ask for more RAM in a single job than is allowed. </p> <p>If you submit jobs which together ask for more memory than you are allowed to use at one time, then ones that \"fit\" inside the limit will run and the remaining jobs will be waiting in PENDING state. </p> <p>The \"Reason\" code shown in the output of <code>squeue --me -t pd</code> (\"show me my pending jobs\") will be <code>QOSMaxMemoryPerUser</code>for jobs waiting for your running jobs to be using less than the RAM limit defined in the QOS that is impacting you.  The Reason will be <code>QOSMaxCpuPerUserLimit</code> for jobs waiting for your core usage to drop below that which is allowed.</p>","tags":["done","slurm"]},{"location":"slurm/qos/#how-we-are-using-qos-to-date","title":"HOW WE ARE USING QOS TO DATE...","text":"<p>This is a summary of how QOS is configured at JHPCE.</p> <p>Our users all have a QOS value of \"normal\", which is inherited from their parent account, named \"jhpce\"</p> <p>(The account jhpce, of the organization jhpce, in the cluster jhpce3 is the parent of all of the users.)</p> <p>The \"normal\" QOS  (currently) has no limits defined for it. (It is the default QOS defined in SLURM. We didn't create it.)</p> <p>A fundamental element of our current practice is that the user\u2019s default QOS entries in the database are \"normal\".</p> <p>We\u2019ve defined additional ones and, for some users, changed the Allowed QoS field in their user entries to list ones that they can optionally use in addition to \"normal\". </p> <p>Those additional ones are being applied</p> <ol> <li>via per-partition QOS= definitions in /etc/slurm/partitions.conf     (e.g. QOS \"interactive-default\", \"shared-default\"), and </li> <li>via users specifying additional ones via per-job     directives (b/c we granted them access to them and     told them that they needed to use those directives).     (Users do not have to specify optional QOS on every     job thenceforward. Users can pick and choose what QOS to use for each job.</li> </ol> <ol> <li> <p>Capitalization doesn't matter when specifying QOS in commands.\u00a0\u21a9</p> </li> </ol>","tags":["done","slurm"]},{"location":"slurm/slurm-commands-ref/","title":"SLURM COMMANDS","text":"<p>Here are links to online copies of the manual pages for commands. If we've written a page with advice about using the command, use the (LOCAL TIPS) link.</p>","tags":["slurm"]},{"location":"slurm/slurm-commands-ref/#locally-written-tools","title":"Locally Written Tools","text":"<ul> <li>slurmpic: An essential program for getting cluster status info. Use -h option to see essential usage details. (no man page yet)</li> <li>smem: Displays memory used by your currently running jobs. If given a jobid number, it will display info about the memory usage of that job. (no man page yet)</li> <li>memory reporting script - puts per-user output daily into directories under /jhpce/shared/jhpce/jhpce-log/</li> </ul>","tags":["slurm"]},{"location":"slurm/slurm-commands-ref/#contributed-programs-weve-installed","title":"Contributed Programs We've Installed","text":"<ul> <li>seff: Display efficiency of CPU and RAM usage of a completed job. (no man page yet)</li> <li>slurm-mail: Tool used to add details to mail sent to you. Not something you can modify. Listed for completeness.</li> </ul>","tags":["slurm"]},{"location":"slurm/slurm-commands-ref/#provided-with-slurm","title":"Provided with Slurm","text":"<p>All of the manual pages are here, including those for the configuration files found in /etc/slurm/</p>","tags":["slurm"]},{"location":"slurm/slurm-commands-ref/#submitting-jobs","title":"Submitting Jobs","text":"<ul> <li>salloc: request an interactive job allocation (doesn't start any processes anywhere)</li> <li>sbatch: submit a batch script to Slurm to create an allocation and run processes</li> <li>srun: launch one or more tasks of an application using allocated resources</li> </ul>","tags":["slurm"]},{"location":"slurm/slurm-commands-ref/#information-about-cluster-and-jobs","title":"Information about cluster and jobs","text":"<p>Warning</p> <p>Do not frequently<sup>1</sup> run slurmpic, squeue, sacct or other Slurm client commands using loops in shell scripts or other programs. </p> <p>These commands all send remote procedure calls to slurmctld, the main SLURM control and scheduling daemon, They may also perform look-ups in the accounting database. That process and the database need to be highly responsive to the input/output caused by running jobs.</p> <p>Ensure that programs limit calls to slurmctld to the minimum necessary for the information you are trying to gather. Add arguments to limit to needed partitions or users or job data fields, etcetera.</p> <p>Some SLURM commands such as sacct and squeue can display a wide variety of information. It can be complex to specify what you want to see and to format it so it is readable. We've tried to document some common choices in the LOCAL TIPS documents. A tip: you  set certain environment variables to specify output arguments instead of providing the arguments on the command line. It can be useful to define these different ways in aliases or shell scripts to format output in ways you need, because simply changing the value of these variables can produce vastly different output for commands like sacct and squeue. Example variables are: SLURM_TIME_FORMAT, SACCT_FORMAT, SQUEUE_FORMAT, SQUEUE_FORMAT2, SQUEUE_SORT. </p> <ul> <li>sacct: (LOCAL TIPS): display accounting data for jobs in the Slurm database</li> <li>sattach: attach to a running job step</li> <li>scontrol: (LOCAL TIPS): display (or modify when permitted) the status of Slurm entities (jobs, nodes, partitions, reservations)</li> <li>sinfo: display node and partition information</li> <li>sprio: (LOCAL TIPS): display the factors that comprise a job's scheduling priority</li> <li>squeue: display the jobs in the scheduling queues, one job per line</li> <li>sshare: display the shares and usage for each charge account and user</li> <li>sstat: display process statistics of a running job/step</li> <li>sview: X11 graphical tool for displaying jobs, partitions, reservations</li> </ul>","tags":["slurm"]},{"location":"slurm/slurm-commands-ref/#controlling-jobs","title":"Controlling Jobs","text":"<ul> <li>scancel: cancel or pause a job or job step or signal a running job or job step to pause</li> <li>scontrol: (LOCAL TIPS): display (and modify when permitted) the status of Slurm entities (jobs, nodes, partitions, reservations)</li> </ul>","tags":["slurm"]},{"location":"slurm/slurm-commands-ref/#for-systems-administrators","title":"For Systems Administrators","text":"<ul> <li>sacctmgr:</li> <li>scontrol: (LOCAL TIPS): display and modify Slurm account information</li> <li>sdiag: display scheduling statistics and timing parameters</li> <li>slurmctld: central management daemon</li> <li>slurmd: client-side daemon</li> <li>sreport: generate canned reports from job accounting data and machine utilization statistics</li> </ul> <ol> <li> <p>Frequently meaning more than once every five minutes. Do you REALLY need to know something sooner than that? If you want to know when a job starts, fails, or finishes, use email notification settings. You can add them to pending and running jobs using scontrol. (See sbatch manual page for possible mail types.)\u00a0\u21a9</p> </li> </ol>","tags":["slurm"]},{"location":"slurm/slurm-faq/","title":"JHPCE SLURM FAQ","text":"<p>The search field on this web site produces good results.</p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#faqs-from-the-vendor","title":"FAQs from the vendor","text":"<p>https://slurm.schedmd.com/faq.html</p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#faqs-from-other-clusters","title":"FAQs from other clusters","text":"<p>Note that the information in these pages will include details which do not apply here in JHPCE. Caveat emptor.</p> <p>CECI</p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#when-will-my-job-start","title":"When will my job start?","text":"Click to open <p>See this document for a description of factors affecting when jobs start.  Of course the load on the cluster impacts job start times. Please consult the output of <code>slurmpic</code> for information about the state of the cluster and its available resources. Note that your job cannot start until a match is found for the resources you specified. There may be a lot of unused CPUs on a node, for example, but if someone has allocated all of the RAM on that node your job won't fit there.</p> <p>If the Reason given for a pending job is <code>QOSMaxMemoryPerUser</code> or <code>QOSMaxCpuPerUserLimit</code> then you can read about Quality of Service in our document here.</p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#what-partitions-exist","title":"What partitions exist?","text":"Click to open <p>The default partition is \"shared\". By default <code>slurmpic</code> describes the state of this partition. (Run <code>slurmpic -h</code> to see a list of options, including the flag to show other partitions.)</p> <p>See this document for a description of partitions and their purposes and limits.</p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#how-will-i-know-if-my-job-ended","title":"How will I know if my job ended?","text":"<p>See this document for information about monitoring pending, running and completed jobs.</p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#how-do-i-cancel-a-job","title":"How do I cancel a job?","text":"Click to open <p>Use <code>scancel &lt;jobid&gt;</code> where jobid is the number for your job. You can specify multiple jobs in a space-separated list.</p> <p>If your job is a member of a job array, it will have an underscore in it, e.g. 2095_15. You can cancel an array task (2095_15) or the whole job array (2095).</p> <p>If you want to cancel all of your pending jobs, use <code>scancel --me -t PENDING</code>. If you want to cancel all of your jobs, use <code>scancel -u your-username</code></p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#how-do-i-hold-or-modify-a-job","title":"How do I hold or modify a job?","text":"Click to open <p>Note that if you want to modify something about the job, instead of cancelling it and losing any accumulated age priority it has accrued, you can hold the job, modify it and release it with <code>scontrol</code> commands. Only some of the parameters of a job can be modified when it is pending, and even fewer if it has started running.</p> <p><code>scontrol hold &lt;jobid&gt;</code> where  can be a comma-separated list. <p>If your jobs have names, you can hold using the name. (This will hold all matching jobs.) <code>scontrol hold jobname=&lt;jobname&gt;</code> <code>scontrol update jobid=&lt;jobid&gt; ...</code> See this section of the manual page for a list of attributes which can be modified.</p> <p>We have a number of scontrol examples spelled out for you.</p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#how-do-i-control-the-order-my-jobs-start","title":"How do I control the order my jobs start?","text":"Click to open <p>You can rank your jobs with the \"nice\" and \"top\" subcommands to <code>scontrol</code>.  See the <code>scontrol</code> tips document mentioned above. You can also submit jobs with dependency directives and also create heterogenous jobs which spawn other jobs. </p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#unable-to-allocate-resources","title":"\"Unable to allocate resources\"","text":"Click to open <p>If the scheduler determines that your job is invalid in some fashion, it will generally reject it immediately instead of putting it into the queue with a pending status. There are a few causes of this. The wording of the error may or may not be clear.</p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#users-group-not-permitted-to-use-this-partition","title":"User's group not permitted to use this partition","text":"Click to open <p>Some of our PI partitions have UNIX groups defined to control who can submit jobs to them. If you are not a member of that group and try to submit a job, you'll see an error like this:</p> <p><code>srun: error: Unable to allocate resources: User's group not permitted to use this partition</code></p> <p>You can see which groups you belong to with the <code>groups</code> command.</p> <p>You can see which group you need to belong to by looking for the partition in question in the file /etc/slurm/partitions.conf</p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#job-violates-accountingqos-policy","title":"Job violates accounting/QOS policy","text":"Click to open <p>If you ask for more resources than will ever be able to be allocated to you, you might receive one of several error messages.</p> <p>This one appeared when a job asked for more RAM than was allowed by a QOS limit:</p> <p><code>Unable to allocate resources: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)</code></p> <p>But when more CPUs were requested (instead of too much RAM), the error was different:</p> <p><code>Unable to allocate resources: More processors requested than permitted</code></p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#how-many-jobs-can-i-run-at-a-time","title":"How many jobs can I run at a time?","text":"Click to open <p>As of 20240220 there are few limits. We are not currently limiting the number of simultaneous jobs submitted or running.</p> <p>Array jobs are limited to 15,000 tasks by variable <code>max_array_tasks</code> in /etc/slurm/slurm.conf</p> <p>Total jobs at a single time is 90,000, which is determined by the variable <code>MaxJobCount</code> in /etc/slurm/slurm.conf</p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#srun-error-_half_duplex","title":"srun: error: _half_duplex","text":"Click to open <p><code>srun: error: _half_duplex: read error -1 Connection reset by peer</code></p> <p>We consider this a SLURM bug. It appears when <code>srun</code> is used with the <code>--x11</code> argument. Sometimes immediately, but typically when an X11 program is launched.</p> <p>If you do not intend to run any X11 programs during your interactive session, then you can log out of that session and start a new one without the <code>--x11</code> flag.</p> <p>If you do intend to use X11 programs, when that error appears the only solution we have found is to abandon that whole login session to the compute node by typing \u201cexit\u201d to quit the shell. Back on the login node, verify that basic X11 functionality works by starting either the xterm or xclock programs. If that works, start a new srun command to get back onto a compute node. Once on a compute node, verify that basic X11 functionality works by starting either the xterm or xclock programs. If they did, then try your X11 program again.</p>","tags":["slurm"]},{"location":"slurm/slurm-faq/#srun-error-ignoring-x11-option","title":"srun: error: Ignoring --x11 option","text":"Click to open <p><code>srun: error: Ignoring --x11 option for a job step within an existing job. Set x11 options at job allocation time.</code></p> <p>This error is issued because the srun command was run after already logging into a compute node via an interactive job. In other words, it is an srun inside of an srun.  <code>Srun</code> can be issued inside of resource allocations created by the <code>salloc</code> or <code>sbatch commands</code>, but not inside of other srun\u2019s.</p>","tags":["slurm"]},{"location":"slurm/slurm/","title":"SLURM","text":"<p>JHPCE has used the SGE (Sun Grid Engine) for many years. We are changing to SLURM (Simple Linux Utility for Resource Management).  The SGE codebase is not actively maintained, and the newest version is about 10 years old at this point. SLURM on the other hand is more widely used, with regular patches and updates made available.</p> <p>SLURM and SGE are conceptually similar, with the notion of \u201cjobs\u201d, \u201cnodes\u201d, \u201cpartitions\u201d (known as \u201cqueues\u201d in SGE), and resource allocation for RAM and cores. However the commands and options between the two schedulers are different.  An orientation to using SLURM on the JHPCE cluster is available, and we will be providing training sessions for end users as we get closer to the cutover date. There are also documents and example code files in /jhpce/shared/jhpce/slurm on the test nodes.</p>"},{"location":"slurm/slurm/#links","title":"Links","text":"<p>GPUs on the JHPCE Cluster under SLURM</p>"},{"location":"slurm/tips-sacct/","title":"sacct useful command examples","text":"<p>Example</p> Show my failed jobs between noon and now<pre><code>sacct -s F -o \"user,jobid,state,nodelist,start,end,exitcode\" -S noon -E now\n</code></pre> <p>sacct is a command used to display information about jobs. It has a number of subtleties, such as the time window reported on and the formatting of output. We hope that this page will help you get the information you need.</p> <p>sacct can be used to investigate jobs' resource usage, nodes used, and exit codes. It can point to important information, such as jobs dying on a particular node but working on other nodes.</p> <p>sacct will show all submitted jobs but cannot, of course, provide data for a number of fields until the job has finished. Use the sstat command to get information about running programs. \"Instrumenting\" your jobs to gather information about them can include adding one or more sstat commands to batch jobs in multiple places.</p> <p>Tip</p> <p>Much of the information on this page can be used with <code>sstat</code>, but there are differences, particularly in available output fields.</p> <p>Examples below use angle brackets &lt; &gt;  to indicate where you are supposed to replace argumements with your values.</p>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#sacct-basics","title":"sacct basics","text":"<ol> <li>By default only your own jobs are displayed. Use the <code>--allusers</code> flag if necessary.</li> <li>Only jobs from a certain time window are displayed by default. The window varies depending the arguments you provide. See this section of the manual page. It is recommended to always provide start (<code>-S</code>) and end (<code>-E</code>) times.</li> <li>You can choose output fields and control their width. </li> <li>Even the simplest of batch jobs contain multiple \"steps\" as far as SLURM is concerned. One of them, named \"extern\" represents the ssh to the compute node on behalf of your job. Job records consist of a primary entry for the job as a whole  as  well as entries for job steps. The Job Launch page has a more detailed description of each type of job step. You may find the <code>-X</code> flag helpful to omit clutter.</li> <li>Regular jobs are in the form: JobID[.JobStep]</li> <li>Array jobs are in the form: ArrayJobID_ArrayTaskID</li> </ol> <p>Warning</p> <p>Sacct retrieves data from a SQL database. Be careful when creating your sacct commands to limit the queries to the information you need. Narrow the search as much as possible.  That database needs to be modified constantly as jobs start and complete, so we don't want it tied up answering sacct queries. If you want to look at a large amount of data in a variety of ways, consider saving the output to a text file and then working with that file.</p>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#command-options-of-note","title":"Command Options of Note","text":"<p>Check the man page. There are other useful options.</p> <ul> <li><code>-X</code>  show stats for the job allocation itself, ignoring steps (try it)</li> <li><code>-R</code> reasonlist  show jobs not scheduled for given reason</li> <li><code>-a</code>  allusers</li> <li><code>-N</code> nodelist  only show jobs which ran on this/these nodes</li> <li><code>-u</code> userlist  only show jobs which ran by this/these users</li> <li><code>--name=</code>namelist - only show jobs with this list of names</li> <li><code>-n</code>  noheader</li> <li><code>-p</code>  parsable  puts a | between fields and at end of line</li> <li><code>-P</code>  parsable2  does not put a | at end of line</li> <li><code>--delimeter</code>  - use that char instead of | for <code>-p</code> or <code>-P</code> <li><code>--units=[KMGTP]</code> - display in this unit</li> <li><code>-k</code> minimum time - looking for jobs with time limits in a range</li> <li><code>-K</code> maximum time - looking for jobs with time limits in a range</li> <li><code>-q</code> qoslist - list of qos used</li>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#start-and-end-times","title":"Start and End Times","text":"<p>It is best to use always specify a <code>-S</code> start time and a <code>-E</code> end time.</p> <p>Special time words: today, midnight, noon, now</p> <p>now[{+|-}count[seconds(default)|minutes|hours|days|weeks]]</p> Examples: <code>now-3day</code> <code>now-2hr</code> <p>Valid time formats are:</p> <pre><code>               HH:MM[:SS][AM|PM]\n               MMDD[YY][-HH:MM[:SS]]\n               MM.DD[.YY][-HH:MM[:SS]]\n               MM/DD[/YY][-HH:MM[:SS]]\n               YYYY-MM-DD[THH:MM[:SS]]\n</code></pre>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#job-state-values","title":"Job State Values","text":"<p>Using the <code>-s &lt;state&gt;</code> option, you can prune your search by looking for only jobs which match the state you need, such as F for failed. (All of these work: f, failed, F, FAILED)</p> <p>Warning</p> <p>Different steps of a job can have different end states. For example the \"extern\" step is often COMPLETED when the \"batch\" and overall steps are FAILED</p> <p>See this section of the manual page, which has also been saved to a text file you can copy for your own reference <code>/jhpce/shared/jhpce/slurm/docs/job-states.txt</code></p> <p>Primary job states of interest:</p> <ul> <li>CA CANCELLED</li> <li>CD COMPLETED</li> <li>F FAILED</li> <li>OOM OUT_OF_MEMORY</li> <li>PD PENDING</li> <li>R RUNNING</li> <li>TO TIMEOUT</li> </ul>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#available-fields","title":"Available fields","text":"<p>Field meanings are explained in this section of the manual page.</p> What output fields are available?<pre><code>sacct -e\n</code></pre> See all fields for a job<pre><code>sacct -o ALL -j &lt;jobid&gt;\n</code></pre>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#formatting-fields","title":"Formatting fields","text":"<p>You can put a %NUMBER after a field name to specify how many characters should be printed, e.g.</p> <ul> <li>format=name%30 will print 30 characters of field name right justified.  </li> <li>format=name%-30 will print 30 characters left justified.</li> </ul>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#using-environment-variables","title":"Using Environment Variables","text":"<p>You can define environment variables in your shell to reduce the complexity of issuing sacct commands. You can also set these in shell scripts. Command line options will always override these settings.</p> <p>SACCT_FORMAT</p> <p>SLURM_TIME_FORMAT</p>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#formatting-datestimes","title":"Formatting Dates/Times","text":"<p>You can use most variables defined by the STRFTIME(3) system call. This web page is a starting point, but what SLURM has chosen to implement may not match.</p> <ul> <li>%a - abbrieviated name of day of the week</li> <li>%m - month as decimal, 01 to 12</li> <li>%d - day of month as decimal</li> <li>%H - hour as decimal in 24-hour notation</li> <li>%M - minute as decimal, 00 to 59</li> <li>%T - time in 24-hour notation (%H:%M:%S)</li> </ul> <p>Day of week MM-DD HH:MM<pre><code>export SLURM_TIME_FORMAT=\"%a %m-%d %H:%M\" \n</code></pre> The start and end field widths show below are suitable for the time format shown above.</p> Resources requested, used<pre><code>export SACCT_FORMAT=\"user,jobid,jobname,nodelist%12,start%-20,end%-20,state%20,reqtres%40,TRESUsageInTot%200\"\n</code></pre>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#output-fields-of-interest","title":"Output Fields of Interest","text":"<p>These fields are probably the ones you'll want. See this section of the manual page for the list and their meaning. Capitalization does not matter; it is used for readability.</p> <ul> <li>TRES means Trackable RESources, such as RAM and CPUs.</li> <li>A number of fields (not listed) are available to tell you on which node a maximum occurred. Similarly there are fields to tell you minimum, average and maximum values for some items.</li> </ul>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#basics","title":"Basics","text":"<ul> <li>User</li> <li>JobId</li> <li>JobName</li> <li>Partition</li> <li>State</li> <li>ExitCode</li> </ul>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#times","title":"Times","text":"<ul> <li>Submit</li> <li>Start</li> <li>Elapsed - in format [DD-[HH:]]MM:SS</li> <li>End</li> </ul>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#nodes","title":"Nodes","text":"<ul> <li>AllocCPUS</li> <li>AllocNodes</li> <li>NNodes - number of nodes requested/used</li> <li>NodeList - </li> </ul>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#resources-requested","title":"Resources Requested","text":"<ul> <li>ReqTRES # this is what you will be billed for</li> <li>ReqNodes</li> <li>ReqCPUS</li> </ul>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#resources-consumed","title":"Resources Consumed","text":"<ul> <li>TRESUsageInTot</li> <li>CPUTime - (elapsed)*(AllocCPU) in HH:MM:SS format</li> <li>MaxRSS - Max resident set of all tasks in job</li> <li>MaxVMSize - Max virtual memory of all tasks in job</li> <li>MaxDiskRead - Number bytes read by all tasks in job</li> <li>MaxDiskWrite - Number bytes written by all tasks in job</li> </ul>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#exit-error-codes","title":"Exit Error Codes","text":"<p>In addition to the job's \"state\", SLURM also records error codes. Unfortunately their Job Exit Codes page doesn't provide a meaning for the numerical values.</p> <p>Error <code>0:53</code> often means that something wasn't readable or writable. For example, job output or error files couldn't be written in the directory in which the job ran (or where you told SLURM to put them with a directive).</p> <pre><code>a guide for exit codes:\n\n0 \u2192 success\nnon-zero \u2192 failure\nExit code 1 indicates a general failure\nExit code 2 indicates incorrect use of shell builtins\nExit codes 3-124 indicate some error in job (check software exit codes)\nExit code 125 indicates out of memory\nExit code 126 indicates command cannot execute\nExit code 127 indicates command not found\nExit code 128 indicates invalid argument to exit\nExit codes 129-192 indicate jobs terminated by Linux signals\nFor these, subtract 128 from the number and match to signal code\nEnter kill -l to list signal codes\nEnter man signal for more information\n</code></pre>","tags":["done","slurm"]},{"location":"slurm/tips-sacct/#diagnostic-arguments","title":"Diagnostic Arguments","text":"<p>These can be useful to double-check what someone actually did.</p> See the full command issued to submit the job<pre><code>sacct -o SubmitLine -j &lt;jobid&gt;\n</code></pre> See batch file used<pre><code>sacct -B -j &lt;jobid&gt;\n</code></pre> Directory used by the job to execute commands<pre><code>sacct -o WorkDir -j &lt;jobid&gt;\n</code></pre> See jobs given a time limit btwn 1min &amp; 1 day<pre><code>sacct -k 00:01 -K 1-0\n</code></pre>","tags":["done","slurm"]},{"location":"slurm/tips-sacctmgr/","title":"sacctmgr useful command examples","text":"<p>Sacctmgr is mostly used by systems administrators. Only they are allowed to make changes.</p> <pre><code># See our currently defined QOS in a readable format\nsacctmgr show qos format=Name%20,Priority,Flags%30,MaxWall,MaxTRESPU%20,MaxJobsPU,MaxSubmitPU,MaxTRESPA%25\n\n# See all users database values\nsacctmgr show user withassoc  | less\n\n# See a particular user's database values\nsacctmgr show user withassoc where name=smburke\n\n# WHO HAS EXTRA QOS shortens the output width\n#  (but needs improvement to align column entries)\nsacctmgr show user withassoc|grep -v \"normal \"|awk '{printf \"%s\\t\\t%s\\t%s\\t\\t%s%\\n\", $1,$3,$4,$7}'\n\n# Add a QOS to a user's existing allowed QOS:\nsacctmgr mod user mmill116 set qos+=high-priority\n# or, you can redefine their whole list\nsacctmgr mod user where name=tunison set qos=normal,shared-200-2\n\n# Remove a QOS from a user's existing allowed QOS:\nsacctmgr mod user where name=tunison set qos-=shared-200-2 # to remove\n\n# How users accounts are created in the sacctmgr database\nsacctmgr -i create user name=$userid cluster=jhpce3 account=jhpce \n\n# How C-SUB users accounts are created in the sacctmgr database on jhpcecms01\nsacctmgr -i create user name=$userid account=generic cluster=cms \n\n# Define a QOS\nsacctmgr add qos job-25run50sub\n# You MUST define these flags for the QOS to work as expected\nsacctmgr modify qos job-25run50sub set flags=DenyOnLimit,OverPartQOS\nsacctmgr modify qos job-25run50sub set MaxJobsPerUser=25 MaxSubmitJobsPerUser=50\n\nsacctmgr modify qos shared-default set MaxTRESPerUser=mem=524288 MaxTRESPerUser=cpu=100\n</code></pre>","tags":["slurm"]},{"location":"slurm/tips-scontrol/","title":"scontrol useful command examples","text":"<p>Scontrol is a command useful to both users and systems administrators.  It is used to display and modify SLURM configuration. It has a number of sub-commands, which take different arguments. See the index section of the manual page for a pointer to the area of interest (what kind of thing you want to see or modify).</p> <p>All  commands and options are case-insensitive, although node names, partition names, and reservation names are case-sensitive. All  commands  and options can be abbreviated to the extent that the specification is unique. </p> <p>Examples below use angle brackets &lt; &gt;  to indicate where you are supposed to replace argumements with your values.</p>","tags":["done","slurm"]},{"location":"slurm/tips-scontrol/#scontrol-for-users","title":"Scontrol for Users","text":"","tags":["done","slurm"]},{"location":"slurm/tips-scontrol/#show-things","title":"Show things","text":"<pre><code>scontrol show --details job &lt;jobid&gt;\n</code></pre> <pre><code>scontrol show node &lt;nodename&gt;\n</code></pre> <pre><code>scontrol show partition &lt;partitionname&gt;\n</code></pre>","tags":["done","slurm"]},{"location":"slurm/tips-scontrol/#update-jobs","title":"Update Jobs","text":"<p>You can update many aspects of pending jobs, fewer for running jobs. What follows is only a sample!!! Click here for the complete list.</p>","tags":["done","slurm"]},{"location":"slurm/tips-scontrol/#pending-jobs","title":"Pending Jobs","text":"Place one of your jobs ahead of other of your jobs<pre><code>scontrol top &lt;jobid&gt;\n</code></pre> Place one of your jobs ahead or behind other of your jobs<pre><code>scontrol update jobid=&lt;jobid&gt; nice=&lt;adjustment&gt; # larger #s decrease the priority\n</code></pre> <p>Set or modify max # of tasks in an array that execute at same time<pre><code>scontrol update jobid=&lt;jobid&gt; ArrayTaskThrottle=&lt;count&gt;\n</code></pre> Users can change the time limit on their pending jobs. After a job starts to run, only a system administrator can adjust the time.</p> Set max job duration<pre><code>scontrol update jobid=&lt;jobid&gt; TimeMin=&lt;time-specification&gt;\n</code></pre> Hold one of your jobs (to prefer other of your jobs)<pre><code>scontrol hold &lt;job-list&gt;  # Can be comma-separated list of jobids\n</code></pre> Release a held job<pre><code>scontrol release &lt;job-list&gt;  # Can be comma-separated list of jobids\n</code></pre> Lower the priority of one of your jobs (to prefer other of your jobs)<pre><code>scontrol update jobid=&lt;jobid&gt; nice=10\n</code></pre> This is per-node, not per-job. In megabytes<pre><code>scontrol update jobid=&lt;jobid&gt; MinMemoryNode=1024\n</code></pre>","tags":["done","slurm"]},{"location":"slurm/tips-scontrol/#running-jobs","title":"Running Jobs","text":"<p>These can also be used on pending jobs. They're just examples of something you might want to set afterwards.</p> <p>Be notified at 80% of job duration<pre><code>scontrol update jobid=&lt;jobid&gt; mailtype=time_limit_80\n</code></pre> But only if you tell it where to send email<pre><code>scontrol update jobid=&lt;jobid&gt; mailuser=&lt;your-address@jh.edu&gt;\n</code></pre></p>","tags":["done","slurm"]},{"location":"slurm/tips-scontrol/#scontrol-for-systems-administrators","title":"Scontrol for Systems Administrators","text":"Modify debug level<pre><code>scontrol setdebug info # or verbose\n</code></pre> Display running configuration<pre><code>scontrol show config\n</code></pre> Modify a partition<pre><code>scontrol update partitionname=interactive allowqos=normal,interactive-default\n</code></pre> Put a DOWN/DRAIN node back into service<pre><code>scontrol update nodename=compute-112 state=resume reason=\"Fixed sssd problem\"\n</code></pre> Show any reservations<pre><code>scontrol show reservation\n</code></pre> Create a reservation<pre><code>scontrol create reservation starttime=now duration=UNLIMITED user=root,tunison,mmill116,jyang flags=maint,ignore_jobs,NO_HOLD_JOBS_AFTER reservation=resv-name nodes=compute-number\n</code></pre> Delete a reservation<pre><code>scontrol delete reservation=&lt;resv-name&gt;\n</code></pre> Another way to delete a reservation<pre><code>scontrol update reservation=&lt;resv-name&gt; endtime=now\n</code></pre> Add a user to an existing reservation<pre><code>scontrol update reservation=&lt;resv-name&gt; user+=&lt;username&gt;\n</code></pre>","tags":["done","slurm"]},{"location":"slurm/user-guide-collection/","title":"SLURM USER GUIDES","text":"<p>Yale: their page</p> <p>Umich: their page</p> <p>New Mexico State Univ: their page</p> <p>BIH: their page</p> <p>C.E.C.I: their page (they have many good pages)</p> <p>Texas Advanced Computing Center: their Frontera cluster's home page</p> <p>Arctic Univ of Norway: their page</p>","tags":["slurm","in-progress"]},{"location":"slurm/whenstart/","title":"Factors Affecting Job Scheduling","text":"","tags":["done","slurm"]},{"location":"slurm/whenstart/#overview","title":"Overview","text":"<p>One of SLURM's primary functions is to schedule jobs so they run on various nodes. Running jobs only in the order that they are submitted on nodes in hostname order is one approach the scheduler could follow, but it turns out to be inefficient. That also doesn't allow organizations to implement policies to favor some jobs over others. So schedulers like SLURM have incorporated many features over the decades which help make maximum use of the cluster's resources and implement other goals.</p> <p>What are some of the things that go into these decisions?</p> <p>How does it choose which of a set of pending jobs to start in what order on which node and which CPU cores on the node?</p> <p>There are a number of vendor documents which document scheduling. See the \"Workload Prioritization\" and \"Slurm Scheduling\" sections at this site.</p>","tags":["done","slurm"]},{"location":"slurm/whenstart/#tldr","title":"TL;DR","text":"<p>Your jobs will start faster if you request the fewest resources required for their success, including duration. Smaller jobs \"fit\" into more slots between other jobs than larger jobs, so consider whether you can divide up your work. You should also direct your job to the most appropriate partition. For example, we have an interactive partition for small jobs.</p> <p>If the scheduler has been able to determine an estimated start date for your job, it will be shown in the output of</p> Start time estimate<pre><code>squeue --me --start\n</code></pre>","tags":["done","slurm"]},{"location":"slurm/whenstart/#backfill","title":"Backfill","text":"<p>In addition to the main scheduling cycle, where jobs are run in the order of priority and availability of resources, all jobs are also considered for \"backfill\". Backfill is a mechanism which will let jobs with lower priority score start before high priority jobs if they can fit in around them. For example, if a higher priority job needs 30 cores and it will have to wait 20 hours for those resources to be available, if a lower priority job only needs a couple cores for an hour, Slurm will run that shorter job in the meantime. This GREATLY enhances utilization of the cluster.</p> <p>For this reason, it is important to request accurate walltime limits for your jobs. If your job only requires 2 hours to run, but you request 24 hours, the likelihood that your job will be backfilled is greatly lowered. </p>","tags":["done","slurm"]},{"location":"slurm/whenstart/#priority","title":"Priority","text":"<p>Cluster-specific</p> <p>As of 20240320, multifactor priority is not enabled on the C-SUB.</p> <p>Multiple factors are used to assign a single priority value to each job. This is described in the Multifacor Job Priority document.</p> <p>(This priority is only used to decide which jobs to dispatch first. It is not used to set a UNIX process <code>nice</code> value on the processes created by jobs out on the compute nodes.)</p> <p>Once a job starts running, its priority no longer has much meaning.</p> <p>The job's priority is an integer that ranges between 0 and 4,294,967,295. The larger the number, the higher the job will be positioned in the queue, and the sooner the job will be scheduled and started. A job's priority, and hence its order in the queue, can vary over time.</p> <p>The final priority is determined by multiplying pairs of (weights and factors) and adding the results. Factors range from 0.0 to 1.0. Weights range from 0 to 65,533.</p> <p>Currently we are using three components: Age, Fairshare and Partition</p> <p>Tip</p> <p>You can see pending job's priority values and the contributors to the final value with the <code>sprio</code> command. This sorts jobs by total prio, partition, user. Pending jobs sorted by priority<pre><code>sprio -S -y,p,u | less\n</code></pre></p> <p>Tip</p> <p>A better formatted of that command which prints only the factors we are currently using<sup>1</sup> is:</p> Pending jobs sorted by priority, well-formatted<pre><code>sprio -o \"%.15i %9r %.8u %.10Y %.10A %.10F %.10P\" -S -y,p,u\n</code></pre> <p>Tip</p> <p>You can change the priority of your jobs among your jobs with <code>scontrol</code> commands like <code>top</code> and <code>nice</code>. See this document for details. </p>","tags":["done","slurm"]},{"location":"slurm/whenstart/#fairshare","title":"Fairshare","text":"<p>To help provide equitable access to the public partitions of the cluster, the FAIRSHARE priority component is based on your recent usage of those partitions. If you have used fewer CPU minutes than someone else in the last week, then your jobs will receive a higher fairshare value.</p> <p>The fairshare priority is the result of multiplying a weight stored in a variable, PriorityWeightFairshare, and a factor which is derived from the accounting database.</p> <p>Tip</p> <p>You inspect fairshare values for ALL users with this command:</p> Fairshare values<pre><code>sshare -a | sort -k7nr | less\n</code></pre> <p>You should focus on the values in the right-hand-most column. Heaviest users of the cluster in recent days have values closer to 0.0. People who haven't run any jobs lately will have values closer to 1.0. Jobs submitted by the latter will be given higher fairshare priority values.</p>","tags":["done","slurm"]},{"location":"slurm/whenstart/#age","title":"Age","text":"<p>In addition to fairshare, any pending job will accrue AGE priority over time. Currently (20240217) this maxes out to 100 over the course of a week.</p> <p>Job arrays which started running tasks many days ago will wind up with high age priority values for all of their future tasks. You can see that fairshare somewhat counteracts that age advantage.</p> <p>If you decide that you want to change something about a pending job, consider whether you can do so using <code>scontrol</code> commands as described here instead of killing the job with <code>scancel</code> and resubmitting it.</p>","tags":["done","slurm"]},{"location":"slurm/whenstart/#partition-priority","title":"Partition Priority","text":"<p>We have set this experimentally on the <code>interactive</code> partition to try to aid in quick access to (small) interactive sessions.</p> <ol> <li> <p>This command's output will be incomplete if we begin using other priority factors.\u00a0\u21a9</p> </li> </ol>","tags":["done","slurm"]},{"location":"storage/backups-restores/","title":"Backups and Restores","text":"","tags":["in-progress"]},{"location":"storage/backups-restores/#caveat","title":"Caveat","text":"<p>We try to protect your data, but ultimately you need to keep copies of your most vital files elsewhere.</p>","tags":["in-progress"]},{"location":"storage/backups-restores/#home-directories","title":"Home directories","text":"<p>Frequency, restore window. Form to request restores. Or just a description of what is needed (what is missing? when did you last see it? where do you want it restored to?)</p>","tags":["in-progress"]},{"location":"storage/backups-restores/#self-service-restores","title":"Self Service Restores","text":"<p>We make snapshots of the /users file system for fourteen days. You can restore files you have deleted recently by changing directory to the appropriate location and then copying the file or files back to your home directory (or anywhere else you desire).</p> <p>At any one time there are fourteen subdirectories in the path <code>/users/.zfs/snapshot</code></p> <p>Here is an example of looking through the collection of snapshots to find copies of a file you want to restore. Let's say that you deleted a file inside your home directory named susan that was stored in the absolute path <code>/users/your-userid/bob/frank/susan</code> You can see from the <code>ls -ld</code> output when the file existed and also the size of the possibly various versions of that file across the collection of snapshots (perhaps you changed it several times in the last two weeks).</p> <pre><code>cd /users/.zfs/snapshot\nls -ld */your-userid/bob/frank/susan\ncp -p 2024-02-16-23:00/your-userid/bob/frank/susan $HOME/restored-susan\n</code></pre> <p>If restoring substantial amounts of data, please do that work on a compute node instead of a login node. Thank you.</p>","tags":["in-progress"]},{"location":"storage/backups-restores/#project-space","title":"Project space","text":"<p>We offer optional backup service.</p> <p>What's included. Frequency, restore window, cost.</p> <p>Limit on what we'll consider (ONLY whole file systems?)</p> <p>Form to request restores. Or just a description of what is needed.</p>","tags":["in-progress"]},{"location":"storage/buying-in/","title":"How to get more space","text":""},{"location":"storage/buying-in/#home-directories","title":"Home Directories","text":"<p>Policies on how much we can give you, for how long.</p>"},{"location":"storage/buying-in/#project-space","title":"Project space","text":""},{"location":"storage/buying-in/#whats-available-to-get-now","title":"What's available to get now?","text":"<p>Costs, whom to contact.</p> <ul> <li>Un-allocated space - spinning disks</li> <li>Un-allocated space - SSD</li> </ul>"},{"location":"storage/buying-in/#future-servers","title":"Future servers","text":"<p>When will the next chance come to buy a large amount of space? How do you put in a request so we can plan?</p>"},{"location":"storage/fastscratch/","title":"Fastscratch","text":"<p>A 22TB file system created from fast Solid State Disk is available for your use. This provides a fast place to store input or output files for your compute jobs. There is no cost for using your personal scratch space.</p> <p>Note</p> <p>This scratch space is meant to be a short-term storage location; it is not a long-term storage solution.</p> <p>You can access your scratch space by using the <code>$MYSCRATCH</code> environment variable from an interactive cluster node session, or within a submitted job.</p> <p>The actual absolute path to your personal scratch space is <code>/fastscratch/myscratch/$USER</code>.</p>","tags":["done"]},{"location":"storage/fastscratch/#key-details","title":"Key details","text":"<p>Because this limited resource is shared by all users, there are some very important restrictions for using it.</p> <ul> <li>There is a 1TB quota set on the personal scratch space. (See this document for more information about disk quotas.)</li> <li>All files older than 30 days will be removed without exception.  </li> <li>Even though there is a 30 day automatic deletion of data, we ask that you please remove data from your personal scratch space once you have finished using it.</li> <li>The personal scratch space is not backed up. Therefore if you delete a file it cannot be recovered.</li> <li>The fastscratch file system has NO redundancy, so scratch space drive failures result in data loss. Thus, move important files needed to be kept from scratch space ASAP.</li> <li>Abuse of this space may result in files being deleted on an as needed basis.</li> </ul> <p>Danger</p> <p>If you <code>untar</code> or <code>unzip</code> a file, and the extracted files have a timestamp older than 30 days from the original bundle, they will be removed when the daily purge begins. To work around this, you can use the <code>touch</code> command to update the timestamp on the extracted files.</p>","tags":["done"]},{"location":"storage/quotas/","title":"Disk Quotas","text":"<p>Disk quotas are used to control disk space for certain file systems. We use \"hard\" quotas. You are not allowed to use more than your quota.  </p> <p>Danger</p> <p>Reaching your disk quota can become an obstacle of simply logging in, as even a small file needed to record some detail about your login session, such as $HOME/.Xauthority, cannot be created. Keep your usage below your quota cap.</p> <p>We use ZFS file systems for large volumes. Unfortunately, ZFS does not provide an end-user quota command with which to inspect your usage and remaining space.</p> <p>Therefore we have configured our login nodes to display your home directory disk consumption and quota during the login process.</p> <p>The figure shown during login are updated periodically. Every 30 minutes to an hour.</p> <p>Tip</p> <p>We have written a <code>getquota</code> command, which will look up your or someone else's quota.</p>","tags":["done"]},{"location":"storage/quotas/#home-directory","title":"Home Directory","text":"<p>In the JHPCE cluster, this quota is set to 100GB.</p> <p>In the C-SUB cluster, this quota is set to 500GB.</p>","tags":["done"]},{"location":"storage/quotas/#file-deletion-and-delayed-change-in-quota","title":"File Deletion and Delayed Change in Quota","text":"<p>When you delete files you may not see an immediate change in your disk consumption as far as the disk quota system is concerned.</p> <p>You can see how much space you are using in your home directory with the commands</p> <pre><code>cd\ndu -sh .\n</code></pre> <p>We use ZFS snapshots for home directories to make automated backups once an day<sup>1</sup>. These are kept for a period of time<sup>2</sup> so users and systems administrators can perform restores. See this document for instructions on performing your own restores!!!</p> <p>Snapshots work by making a record of your files at an instant in time.  They take zero space at first. As your files change, disk space is consumed to hold the changed material. Snapshot consumption is counted as part of your disk quota.</p> <p>Therefore it can take a number of days<sup>2</sup> for files you have changed in the past but now deleted to stop being counted against your quota.</p> <p>As you can imagine, the rate of change and size of files involved determines the amount of space held in snapshots.</p> <p>If you find yourself in the position where you have run into your disk quota limit, have deleted significant amounts of files but are still impacted by your snapshot'ed files, please email us at bitsupport with the details. We will give you a temporary increase in disk quota to accomodate the snapshot \"overhang\"</p>","tags":["done"]},{"location":"storage/quotas/#fastscratch","title":"Fastscratch","text":"<p>The /fastscratch file system has a 1TB quota per user.</p> <p>We have defined in the standard environment a variable <code>$MYSCRATCH</code> for users to use to access their space. (The actual absolute path to your personal scratch space is <code>/fastscratch/myscratch/$USER</code>)</p> <p>There is no reporting system currently available to display fastscratch disk usage and your quota. You can use these commands to view your current usage:</p> <pre><code>cd $MYSCRATCH\ndu -sh .\n</code></pre>","tags":["done"]},{"location":"storage/quotas/#fastscratch-automated-cleaning","title":"Fastscratch automated cleaning","text":"<p>Files which have not been modified in the last 30 days are automatically deleted by a daily process.</p> <p>If you extract files from an archive and maintain their original creation date, they may be deleted sooner than you expect. </p> <ol> <li> <p>At eleven pm (as of 20240215).\u00a0\u21a9</p> </li> <li> <p>Fourteen days (as of 20240215).\u00a0\u21a9\u21a9</p> </li> </ol>","tags":["done"]},{"location":"storage/stg-overview/","title":"STORAGE OVERVIEW","text":"<p>Warning</p> <p>Document under heavy-duty construction</p> <p>Previous stg page has some text that should move into this one.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"storage/stg-overview/#types-of-storage","title":"Types of storage","text":"<p>There are three basic categories of data storage you can write to.</p> Type Example Path Quota? Use Home directory /users/yourusername Yes Store your environment Project space /dcs07/grpname/data Yes Research data Scratch space /tmp/ No Application temporary files <p>Characteristics, best uses of each.</p> <p>Mention local versus network.</p> <p>(/tmp is a local example. Are we going to keep /scratch in existence? See Github 774.)</p> <p>Speed differences between SSD (dcs06, fastscratch) and spinning.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"storage/stg-overview/#specific-file-systems-you-need-to-know-about","title":"Specific File Systems You Need To Know About","text":"<p>Make a table for each of the three types of storage. Instead of one large table. Be consistent in dealing with the three types of stg.</p> <p>In each table, include</p> <ul> <li>Name or form (/dcs0N/group/data)</li> <li>the environment variable you can use to refer to it, e.g. $HOME $FASTSCRATCH (JRT doesn't know of a SLURM variable for where your job starts. There's SLURM_SUBMIT_DIR but it doesn't reflect any usage of --chdir)</li> </ul>","tags":["topic-overview","needs-major-revision"]},{"location":"storage/stg-overview/#dont-fill-up-tmp","title":"Don't fill up /tmp","text":"<p>What about compute node's /tmp? Users need to know about it, because they may not know that software often writes there, and they need to understand that it is a shared limited resource. if they are explicitly writing to /tmp they need to know to limit their usage and clean up after themselves</p>","tags":["topic-overview","needs-major-revision"]},{"location":"storage/stg-overview/#home-directories","title":"Home directories","text":"<p>How to learn how much you're using. How often updated? Disk quotas - only hard, no soft (so no warning) Issue with snapshots preventing you from being able to immediately reduce usage. Ask for increase in disk quota while overhang is being deleted? See this document to request increases in /users quota?</p>","tags":["topic-overview","needs-major-revision"]},{"location":"storage/stg-overview/#buying-additional-storage-space","title":"Buying additional storage space","text":"<p>Periodic offerings. How paid for (and therefore length of committment)</p>","tags":["topic-overview","needs-major-revision"]},{"location":"storage/stg-overview/#backing-up-storage","title":"Backing up storage","text":"<p>You need to ensure that you have copies of your most vital files located somewhere else. See this document for more information.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"storage/stg-overview/#getting-information-about-storage","title":"Getting information about storage","text":"<ul> <li>du -sh</li> <li>df -h</li> <li>df -h .</li> </ul> <p>Consider potential impact of running certain commands that will cause lots of I/O. Not crossing file system boundaries is an option found on a number of UNIX commands that is good to use.</p>","tags":["topic-overview","needs-major-revision"]},{"location":"storage/stg-overview/#just-yanked-out-of-knowledgebase-doc-put-somewhere","title":"JUST YANKED OUT OF KNOWLEDGEBASE DOC - PUT SOMEWHERE","text":"","tags":["topic-overview","needs-major-revision"]},{"location":"storage/stg-overview/#disk-storage-space-on-the-jhpce-cluster","title":"Disk Storage Space on the JHPCE Cluster","text":"<ul> <li>There are several types of storage on the JHPCE cluster. </li> <li>Some space is for permanent storage of files, and other spaces can be used for short term storage of data.</li> <li>For long term storage of files, most users make use of their 100GB of space in their home directory. </li> <li>For those groups needing more, we have large storage arrays and sell allocations on these large arrays. Storage docs.</li> <li>We build a new storage array about every 18 months; so if you are interested in purchasing an allocation please email bitsupport@lists.jhu.edu. </li> <li>In addition to these long-term storage offerings, there are scratch space areas for short-term data storage. <ul> <li>Scratch space tends to be faster. Using scratch space avoids taking up space in your home or project storage space.</li> </ul> </li> <li>The best area used for scratch is the <code>fastscratch</code> array on the cluster. The fastscratch array provides 22TB of space that is built on faster SSD drives, vs traditional hard drives used for project space and home directories. All users have a 1TB quota for scratch space, and data older than 30 days is purged.</li> <li>Traditionally in Unix/Linux, <code>/tmp</code> or <code>/var/tmp</code> directories are used for storing temporary files. On the JHPCE cluster, this is strongly discouraged as these directories are small. </li> <li>In R, the <code>tmpdir()</code> setting will dictate where temporary files are stored. If you are generating 10s of GB of temporary files, change <code>tmpdir()</code> to <code>fastscratch</code>.</li> <li>In SAS, the default <code>WORK</code> directory will be located under your <code>fastscratch</code> directory.</li> <li>In Stata, the default <code>tempfile</code> location is under <code>/tmp</code>. This can be changed by setting the <code>STATATMP</code> environment variable.</li> </ul>","tags":["topic-overview","needs-major-revision"]},{"location":"storage/stg-overview/#encrypted-filesystem","title":"Encrypted filesystem","text":"<p>Hopefully</p> <p>We can just delete this info because we're getting rid of Lustre ASAP</p> <ul> <li>The JHPCE Cluster currently supports the following mechanisms for using encrypted filesystems.</li> <li>Encrypted filesystem are used to provide \u201cEncryption At Rest\u201d, meaning that the data on disk will be safely stored in an encrypted format, and only available in an unencrypted state when the data is accessed by an approved user.</li> <li>Userspace encrypted filesystems using <code>encfs</code> <code>ZFS/Lustre</code> encrypted filesystems.</li> <li>The <code>DCL02</code> storage array is built on encrypted disk devices.</li> </ul>","tags":["topic-overview","needs-major-revision"]},{"location":"storage/storage/","title":"Old Stg Page","text":"<p>Test 2</p>"},{"location":"storage/storage/#current-storage-offerings","title":"Current Storage Offerings","text":"<p>Test1</p> <p>There are 2 main categories of storage space available for purchase on the JHPCE cluster, detailed below:</p> <ol> <li> <p>Pay-as-you-go space: This includes home directory space, legacy storage space, and leased spaces. Users are charged only for the actual space used and the time data is stored there. For example, using 10 TB of <code>/dcl01/leased</code> space for a year costs $500/year.</p> </li> <li> <p>Project spaces: These are large storage arrays built approximately every 18 months, funded by various labs purchasing allocations on the storage array. For example, the buy-in cost for <code>/dcl02</code> was $43/TB, with a $300/year storage management fee for a 10TB allocation.</p> </li> </ol> <p>Pay-as-you-go spaces are generally more expensive than project spaces due to their smaller size, upfront costs being included in the annual fee, and higher maintenance requirements.</p> <p>Additionally all users have access to 1TB of \"fastscratch\" storage for storing files less than 30 days.  More information on using fastscratch can be found at [/jhpce_mkdocs/knowledge_base/#fastscratch] - Personal Scratch space: A network-based filesystem with a backend NVME based storage array, intended for short-term storage of large files.</p> <p>Off-site backup space is also available, with <code>/users</code> directory currently backed up, and other directories backed up upon request.</p> <p>For inquiries about purchasing storage, please email bitsupport@lists.jhu.edu.</p>"},{"location":"storage/storage/#current-offerings","title":"Current Offerings","text":"Type Location Env Var Capacity Quota Lifetime FY21Q3 Rate Charge Basis Notes Home ZFS /users/ $HOME 34TB 100GB Long $345/TByr Used TB - Temp scratch /scratch/temp/ $TMPDIR 500GB-4TB None Transient Free - [1][2] Personal scratch /fastscratch/myscratch/ $MYSCRATCH 22TB 1TB 30 days Free - [1][3] Leased Lustre /dcl02/leased - 200TB As agreed Intermediate $50/TByr Used TB - Project ZFS /dcs04, /dcs05, /dcs07 - 5,000TB As purchased Long $20/TByr + buyin Purchased TB [4] Backup ZFS varies - 2,675TB - Permanent $11/TByr Purchased TB [5] <p>Notes: - [All] Rates fluctuate slightly from quarter to quarter based on actual JHPCE expenses and capacities. - [1] Scratch space is only visible on compute and transfer nodes. Scratch is not visible on the login node. <code>&lt;JQT&gt;</code> = 'job.queue.task'. - [2] Scratch space varies from node to node based on local disk space. - [3] Currently there is a 1TB quota on files in /fastscratch/myscratch, with a 30-day file retention limit. - [4] The buy-in cost for DCS04 is $42/TB. Limited capacity still available for sale. - [5] Backups are done of the /users filesystem. Other filesystems may be backed up upon arrangement with PI.</p>"},{"location":"storage/storage/#previouslegacy-offerings","title":"Previous/Legacy Offerings","text":"<p>The storage spaces listed below are currently in use but are no longer available for purchase.</p> Type Location Env Var Capacity Quota Lifetime FY2019Q2 Rate Charge Basis Notes Leased Lustre /dcl01/leased - 200TB As agreed Intermediate $50/TByr Used TB - Leased ZFS /legacy - 100TB From legacy Short &lt; $1350/TByr Used TB [1] Leased ZFS /starter/starter-02 - 10TB 10TB Short $1,041/TByr Used TB [1] Project Lustre /dcl01 - 3,400TB As purchased Long $26-$ <p>There are 2 main categories of storage space available for purchase on the JHPCE cluster, detailed below:</p> <ol> <li> <p>Pay-as-you-go space: This includes home directory space, legacy storage space, and leased spaces. Users are charged only for the actual space used and the time data is stored there. For example, using 10 TB of <code>/dcl01/leased</code> space for a year costs $500/year.</p> </li> <li> <p>Project spaces: These are large storage arrays built approximately every 18 months, funded by various labs purchasing allocations on the storage array. For example, the buy-in cost for <code>/dcl02</code> was $43/TB, with a $300/year storage management fee for a 10TB allocation.</p> </li> </ol> <p>Pay-as-you-go spaces are generally more expensive than project spaces due to their smaller size, upfront costs being included in the annual fee, and higher maintenance requirements.</p> <p>Additionally all users have access to 1TB of \"fastscratch\" storage for storing files less than 30 days.  More information on using fastscratch can be found at [/jhpce_mkdocs/knowledge_base/#fastscratch] - Personal Scratch space: A network-based filesystem with a backend NVME based storage array, intended for short-term storage of large files.</p>"},{"location":"sw/adding-pkgs/","title":"Adding Your Own Python and R Libraries","text":"","tags":["needs-to-be-written"]},{"location":"sw/adding-pkgs/#how-to-add-your-own-packages-to-r-and-python","title":"How to add your own packages to R and python","text":"<p>Authoring Note</p> <p>Should this document be split into ones for R and Python?</p> <p>I think our user community would welcome instructions on how to add pkgs to R and python, at the minimum.</p> <p>There are right and wrong ways to do this.</p> <p>There are implications of loading modules in which order before doing things.</p> <p>Do you create a conda environment first, or a python virtual environment?</p> <p>WHAT DO YOU DO WHEN YOU WANT TO RUN A DIFFERENT VERSION OF A LIBRARY THAT IS FOUND IN CONDA_R?</p> <p>What information do other HPC sites deem important to tell their users? Are there examples among the pages for listed TOWARDS THE BOTTOM in this github issue?</p> <p>A GOOD EXAMPLE Example from C.E.C.I</p>","tags":["needs-to-be-written"]},{"location":"sw/adding-pkgs/#r","title":"R","text":"<p>FIRST YOU MUST LOAD R MODULE <code>module load R</code></p> <p>If you try to load a library and it is not found, then you can install one in your home directory.</p> <pre><code>&gt; install.packages(\"sf\")\n&gt; install.packages('terra', repos='https://rspatial.r-universe.dev')\n&gt; library('sf')\n&gt; library('terra')\n</code></pre> <p>You should recompile your libraries when the version of R changes.</p> <p>How do you recompile instead of install?</p> <p>When installing R packages from source with compiled programs, you can add custom compiler flags in ~/.R/Makevars. Adding optimization flags may provide a boost in performance for some packages.  <pre><code>STDFLAGS = -O2 -pipe -Wall \n</code></pre></p> <p>We have a wide variety of CPU architecture across the cluster, so you probably don't want to add to STDFLAGS <code>-march=</code> and <code>-mtune=</code> arguments.</p>","tags":["needs-to-be-written"]},{"location":"sw/adding-pkgs/#python","title":"Python","text":"<p>C.E.C.I has a page with what I think might be useful info:</p> <p>It is important when you install a package that you load the correct Python module, and use the Pip option --no-binary :all: to recompile from source rather than install pre-compiled binaries whenever possible. See more information in the PIP documentation </p>","tags":["needs-to-be-written"]},{"location":"sw/building-from-src-old/","title":"Building from src old","text":"<p>Authoring Note</p> <p>Our younger users haven't necessarily ever built anything from source. Or on machines owned by someone else where you cannot use sudo dnf install blah. We can encourage them that it is possible, give them a few pointers to doing it successfully.</p> <p>For example, telling them that they will have to modify the destination location from the typical /usr/local/bin and that you can usually do that easily in the config stage with <code>--config=</code></p> <p>Please do it on a compute node in an interactive shell.</p> <p>If we don't write something, then we can provide pointers to the work of others. If so, that would probably be inside a larger document.</p> <p>Software installation with Conda</p> <p>Example building from source page</p>"},{"location":"sw/building-from-src-old/#please-visit-the-links-below-poke-around-to-nearby-topics-on-those-site-pages-if-you-were-a-new-jhpce-user-and-new-to-unix-and-hpc-what-would-you-like-to-see-using-these-examples","title":"**Please visit the links below, poke around to nearby topics on those site pages. If you were a new JHPCE user and new to UNIX and HPC, what would you like to see, using these examples?","text":"<p>**</p> <p>Maybe the info JRT has collected below about toolchains, maybe these particular URL compared to others on those sites, should be inserted into a github issue and considered later. JRT wonders if we should begin to adopt the practice of being more specific about creating and using toolchains.</p> <p>Note that these clusters provide modules with toolchain information. AFAIK we've never named our modules with toolchain information (with which compiler they were built). Does ARCH? A lot of this seems to be Intel vs gcc. But wouldn't it help us keep our modules updated if we embedded the compiler generation they were built with into their name?</p> <p>These places give date names to collections of tools. Yale's toolchain page has an illustration of \"foss\" versus \"foss-cuda\"</p> <p>Example from C.E.C.I</p> <p>Another example for frontera cluster Very nice info to help you optimize your code. Advice about locality, I/O performance, machine learning etc nearby in sidebar.</p> <p>Another example from Yale warns users about considering node CPU capabilities. (So does Frontera where you get practical info about gcc -march and -mtune)</p> <p>The C.E.C.I folks are surprisingly opposed to people using Anaconda. I guess this is specifically about the full Anaconda versus Miniconda?????</p>"},{"location":"sw/building-from-src/","title":"Compile from Source","text":""},{"location":"sw/building-from-src/#compiling-and-installing-software-with-no-root-privilege","title":"Compiling and installing software with no root privilege","text":"<p>You are allowed to download and install small software packages in your own home directory. In this page, we go through an example of installing a piece of free software that converts between different units of measurements, to show you the general steps needed to install a software from source.</p> <p>Warning</p> <p>Please do the software installation from a compute node</p>"},{"location":"sw/building-from-src/#step-1-download-source-code","title":"Step 1: Download source code","text":"<pre><code>[test@compute-110 ~]$ mkdir download\n[test@compute-110 ~]$ cd download/\n[test@compute-110 download]$ wget http://ftp.gnu.org/gnu/units/units-2.23.tar.gz\n--2024-03-18 11:57:38--  http://ftp.gnu.org/gnu/units/units-2.23.tar.gz\nResolving ftp.gnu.org (ftp.gnu.org)... 209.51.188.20, 2001:470:142:3::b\nConnecting to ftp.gnu.org (ftp.gnu.org)|209.51.188.20|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1423494 (1.4M) [application/x-gzip]\nSaving to: \u2018units-2.23.tar.gz\u2019\n\nunits-2.23.tar.gz                                 100%[==========================================================================================================&gt;]   1.36M  --.-KB/s    in 0.1s    \n\n2024-03-18 11:57:39 (12.7 MB/s) - \u2018units-2.23.tar.gz\u2019 saved [1423494/1423494]\n</code></pre>"},{"location":"sw/building-from-src/#step-2-extract-the-source-code","title":"Step 2: Extract the source code","text":"<pre><code>[test@compute-110 download]$ ls -l\n-rw-r--r-- 1 test test 1423494 Feb 18 22:45 units-2.23.tar.gz\n\n[test@compute-110 download]$ tar -zxvf units-2.23.tar.gz \nunits-2.23/\nunits-2.23/definitions.units\nunits-2.23/units.txt\n...\n</code></pre>"},{"location":"sw/building-from-src/#step-3-configure-the-software","title":"Step 3: Configure the software","text":"<pre><code>[test@compute-110 download]$ cd units-2.23/\n[test@compute-110 units-2.23]$ ./configure --prefix=$HOME/mysoftware/units-2.23\n</code></pre> <p>Note</p> <p>The first thing to do is carefully read the <code>README</code> and <code>INSTALL</code> text files (use the <code>less</code> command). These contain important information on how to compile and the run the software. Since you do not have root privilege to install the software on system area, you will need to specify the installation directory using <code>--prefix=/path/to/your/softwre</code>.  </p>"},{"location":"sw/building-from-src/#step-4-build-and-install","title":"Step 4: Build and install","text":"<pre><code>[test@compute-110 units-2.23]$ make\n[test@compute-110 units-2.23]$ make install\n</code></pre> <p>Note</p> <p>This will install the files into the <code>~/mysoftware/units-2.23</code> directory that you specified with <code>./configure</code>.</p>"},{"location":"sw/building-from-src/#step-5-add-the-software-to-path","title":"Step 5: Add the software to path","text":"<pre><code>[test@compute-110 ~]$ export PATH=$PATH:$HOME/mysoftware/units-2.23/bin\n</code></pre> <p>Note</p> <p>You can add the above line in your <code>.bashrc</code> file so the software would be available when you login</p>"},{"location":"sw/building-from-src/#step-6-run-the-software","title":"Step 6: Run the software","text":"<pre><code>[test@compute-110 ~]$ units\n...\nYou have: tempF(75)\nYou want: tempC\n    23.888889\nYou have: exit\n[test@compute-110 ~]$\n</code></pre>"},{"location":"sw/conda/","title":"Conda Environment","text":""},{"location":"sw/conda/#introduction","title":"Introduction","text":"<p>Conda gives you the ability to create environments with packages and their dependencies that will be separate from other environments. This page goes over the basic usage of it.</p>"},{"location":"sw/conda/#create-an-environment","title":"Create an environment","text":"<ul> <li> <p>load conda module <pre><code>module load conda\n</code></pre> or <pre><code>module load anaconda\n</code></pre></p> </li> <li> <p>create a new environment <pre><code>conda create -n &lt;evn-name&gt;\n</code></pre></p> </li> </ul> <p>Note</p> <ul> <li>Conda is a package manager, similar to pip.  </li> <li>Anaconda is a \"batteries included\" distribution of Python. It uses Conda as its package manager.</li> </ul>"},{"location":"sw/conda/#list-environments","title":"list environments","text":"<ul> <li>lista all your conda environment <pre><code>conda info --envs\n</code></pre></li> </ul> <p>Tip</p> <p>The active environment is the one with an asterisk (*)</p>"},{"location":"sw/conda/#install-a-conda-package-in-the-new-created-environment","title":"Install a conda package in the new created environment","text":"<pre><code>conda activate env-name\nconda install package-name\n</code></pre> <p>Notes:</p> <p>To install a specific version: <pre><code>conda install package-name=2.3.4\n</code></pre> To specify only a major version <pre><code>conda install package-name=2\n</code></pre></p>"},{"location":"sw/conda/#specifying-channels-to-use","title":"specifying channels to use","text":"<ul> <li>Channels are locations where packages are stored. By default, conda searchs for packages in its default channels. You can specify a channel when installing the package (e.g. conda-forge channel) <pre><code>conda install conda-forge::numpy\n</code></pre></li> </ul>"},{"location":"sw/containers/","title":"Containers","text":"","tags":["needs-to-be-written","mark"]},{"location":"sw/containers/#using-our-container-solutions","title":"Using Our Container Solutions","text":"<p>We have two solutions that you can use.</p> <p>Maybe this is a good time to at least get credit for the work Mark has done building the singularity containers we now offer.</p> <p>What do you need to know about using them? Quitting them? Waiting how long for them to finish starting?</p> <p>What verbiage about this can be shared with Web Portal docs?</p>","tags":["needs-to-be-written","mark"]},{"location":"sw/containers/#building-your-own-containers","title":"Building Your Own Containers","text":"<p>Maybe we can document this later in terms of how users can build them. In the mean time, provide some links??</p> <p>They don't have root access, so what is that trick that allows you to make a container image?</p>","tags":["needs-to-be-written","mark"]},{"location":"sw/containers/#how-do-you-run-a-batch-slurm-job-using-a-container","title":"How do you run a batch SLURM job using a container?","text":"<p>Where is the best file system to host a container file if you're going to run it in batch mode on multiple nodes? /fastscratch? Does it make a difference?</p>","tags":["needs-to-be-written","mark"]},{"location":"sw/containers/#examples-from-elsewhere","title":"Examples from Elsewhere","text":"<p>The Frontera site's section on containers mentions something that users building their own containers on JHPCE need to know to add to their containers -- e.g. which file systems to include.</p> <p>NERSC has a well-written set of pages about using podman-hpc, which might serve as an example of just building and using containers even without podman-hpc</p> <p>Zurich pages on Singularity and Recipes and Hints</p> <p>USC pages on Singularity</p>","tags":["needs-to-be-written","mark"]},{"location":"sw/gui-tools/","title":"Helpful GUI Programs","text":"<p>This chart is C-SUB specific.</p> <p>JRT thinks JHPCE users would benefit from seeing a chart that is correct for that cluster. (A Github issue exists about considering installing some of these C-SUB-only tools onto main cluster.)</p>","tags":["needs-major-revision"]},{"location":"sw/jupyter/","title":"Jupyter","text":"<p>Everything you need to know to get started using Jupyter and related friends.</p>","tags":["needs-to-be-written"]},{"location":"sw/jupyter/#using-the-web-portal","title":"Using the Web Portal","text":"<p>Authoring Note</p> <p>Put here information about aspects of using this tool. Perhaps a warning that it can take some time to launch.</p> <p>Please see this document about this service.</p>","tags":["needs-to-be-written"]},{"location":"sw/locally-written/","title":"Locally Written Tools","text":"<p>We here try to capture information about programs you may want to use. Most of them lack on-line manual pages. We try to add support for usage statements and the <code>-h</code> (help) argument. Because all of them are shell scripts or python, you can look at the source code.</p>","tags":["in-progress"]},{"location":"sw/locally-written/#where-are-they","title":"Where are they?","text":"<p>Many of these programs live in <code>/jhpce/shared/jhpce/core/JHPCE_tools/3.0/bin/</code> If that directory is not in your PATH, then you are not seeing the normal and supported JHPCE environment. (If it occurs after your additions to the PATH, then you may see only parts of the supported environment.)</p> <p>Your environment, including your PATH variable, is created when logging in. A number of configuration files are processed. Your <code>.bashrc</code> file is a core one. By default it will consult one in <code>/etc/bashrc</code>  Files in <code>/etc/profile.d/</code> are also processed. It is via these latter files that we do things like provide support for modules, display messages of the day on login nodes, etc.</p> <p>You can use the command <code>which cmd</code> to be told where \"cmd\" comes from.</p>","tags":["in-progress"]},{"location":"sw/locally-written/#general","title":"General","text":"<ul> <li>auth_util: Interface for working with OTP MFA configuration. View and generate verification tokens for Google Authenticator. See orientation documents for details on using it to configure your smartphone, etc.</li> </ul>","tags":["in-progress"]},{"location":"sw/locally-written/#disk-usage","title":"Disk Usage","text":"<ul> <li>getquota: Displays your quota stats (not yet working on C-SUB)</li> <li>cmsquota-dcs05: For C-SUB users</li> <li>cmsquota-dcs06: For C-SUB users</li> </ul>","tags":["in-progress"]},{"location":"sw/locally-written/#container-computing","title":"Container Computing","text":"<ul> <li>jupyterlab.sh: Start an Jupyter server available via an SSH tunnel.</li> <li>jupyterlab-gpu.sh: Start an Jupyter server available via an SSH tunnel with CUDA libraries in LD_LIBRARY_PATH.</li> <li>jhpce-rstudio-server: Start an RStudio server available via an SSH tunnel.</li> <li>csub-rstudio-server: Cluster-specific version.</li> </ul>","tags":["in-progress"]},{"location":"sw/locally-written/#slurm-related","title":"SLURM-related","text":"","tags":["in-progress"]},{"location":"sw/locally-written/#information-about-cluster-and-jobs","title":"Information about cluster and jobs","text":"<p>Warning</p> <p>Do not frequently<sup>1</sup> run slurmpic, squeue, sacct or other Slurm client commands using loops in shell scripts or other programs. </p> <p>These commands all send remote procedure calls to slurmctld, the main SLURM control and scheduling daemon, They may also perform look-ups in the accounting database. That process and the database need to be highly responsive to the input/output caused by running jobs.</p> <p>Ensure that programs limit calls to slurmctld to the minimum necessary for the information you are trying to gather. Add arguments to limit to needed partitions or users or job data fields, etcetera.</p> <ul> <li>slurmpic: Essential program for getting cluster status info. Use -h option to see essential usage details. (no man page yet)</li> <li>smem: Displays memory used by your currently running jobs. If given a jobid number, it will display info about the memory usage of that job. (no man page yet)</li> <li>memory reporting script - puts per-user output daily into directories under <code>/jhpce/shared/jhpce/jhpce-log/</code></li> <li>jobson: Displays running jobs when given a three digit node number.</li> </ul>","tags":["in-progress"]},{"location":"sw/locally-written/#submitting-jobs","title":"Submitting Jobs","text":"<p>None yet.</p>","tags":["in-progress"]},{"location":"sw/locally-written/#contributed-slurm-programs-weve-installed","title":"Contributed SLURM Programs We've Installed","text":"<ul> <li>seff: Display efficiency of CPU and RAM usage of a completed job. (no man page yet)</li> <li>slurm-mail: Tool used to add details to mail sent to you. Not something you can modify. Listed for completeness.</li> </ul> <ol> <li> <p>Frequently meaning more than once every five minutes. Do you REALLY need to know something sooner than that? If you want to know when a job finishes, use email notification settings. You can add them to pending and running jobs using scontrol.\u00a0\u21a9</p> </li> </ol>","tags":["in-progress"]},{"location":"sw/matlab/","title":"Matlab","text":""},{"location":"sw/matlab/#using-matlab-interactively","title":"Using Matlab interactively","text":"<pre><code>[test@login31 ~]$ srun --mem 10G --x11 --pty bash\nsrun: job 3109996 queued and waiting for resources\nsrun: job 3109996 has been allocated resources\n[test@compute-152 ~]$ module load matlab\n[test@compute-152 ~]$ module list\n\nCurrently Loaded Modules:\n  1) JHPCE_ROCKY9_DEFAULT_ENV   2) JHPCE_tools/3.0   3) matlab/R2023a\n\n[test@compute-152 ~]$ matlab\n</code></pre>"},{"location":"sw/matlab/#running-matlab-program-in-batch-mode","title":"Running Matlab program in batch mode","text":"<ol> <li> <p>Write your matlab source in a file with .m extension (e.g. matlab_example.m) <pre><code>x = [1 2 3 4];\nfprintf('Example number = %i\\n', x)\n</code></pre></p> </li> <li> <p>Write a submit job script (e.g. matlab_example.sh) <pre><code>#!/bin/bash\n\n#SBATCH --mem=2G\n#SBATCH --time=5:00\n\n#SBATCH -o slurm.%N.%J.%u.out   # STDOUT\n#SBATCH -e slurm.%N.%J.%u.err   # STDERR\n\nmodule load matlab\nmatlab -nojvm -nodisplay -r \"matlab_example;quit;\"\n</code></pre></p> </li> <li> <p>Submit your matlab job <pre><code>[test@login31 ~]$ sbatch matlab_example.sh \nSubmitted batch job 3110505\n</code></pre></p> </li> <li> <p>Monitor the job status <pre><code>[test@login31 ~]$ squeue --me\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n           3110505    shared matlab_e    test  R       0:03      1 compute-100\n</code></pre></p> </li> <li> <p>When the job is finished, the output files are created in your Current Working Directory <pre><code>-rw-r--r-- 1 test test   0 Mar 12 17:09 slurm.compute-100.3110505.test.err\n-rw-r--r-- 1 test test 410 Mar 12 17:10 slurm.compute-100.3110505.test.out\n</code></pre></p> </li> <li> <p>Look at the results from output file, file with stderr is empty(job without errors): <pre><code>[test@login31 ~]$ cat slurm.compute-100.3110505.test.out\n                                May 25, 2023\n\nFor online documentation, see https://www.mathworks.com/support\nFor product information, visit www.mathworks.com.\n\nExample number = 1\nExample number = 2\nExample number = 3\nExample number = 4\n</code></pre></p> </li> </ol>"},{"location":"sw/modules-old/","title":"Environment modules","text":"<p>Authoring Note</p> <p>The last section needs to be updated for 2024. LIBD is not mentioned, documentation is not linked correctly anymore, etc. Convert to a Markdown table?</p>","tags":["needs-review","jiong"]},{"location":"sw/modules-old/#introduction","title":"Introduction","text":"<p>The JHPCE cluster uses the Lmod module system to allow users to configure their shell environments. Some applications will not run until you load the corresponding modulefile. </p> <p>A handful of widely used modulefiles are loaded by default when you log into the cluster. To see what modules are loaded you can enter the following command at the shell prompt:</p> <p><pre><code>module list\n</code></pre> The naming convention for modules is \"software_name/version\" (e.g. bowtie/2.5.1). If a module is loaded, it will be followed by <code>(L)</code> The default version, if designatedk will be followed by a <code>(D)</code></p> <p>Modules cure the the age-old headaches associated with configuring paths, environment variables and different software versions. For example, gcc or open64 compilers need different libraries. Some users need python 3.9 while other users need python 3.10. Some users want a standard stable R, while some want the latest and greatest development version of R that was compiled the night before.</p>","tags":["needs-review","jiong"]},{"location":"sw/modules-old/#basic-module-commands-for-users","title":"Basic module commands for users","text":"<p>A module file is a script that sets up the paths and environment variables that are needed for a particular application or development environment. Most users will just use our modulefiles. But if you want to finely control your shell environment, you can start developing your own custom module files. </p> <p>There are a few basic commands that users should know:</p> <pre><code>module list                 # list your currently loaded modules\nmodule load   &lt;MODULEFILE&gt;  # configures your environment according to modulefile \nmodule unload &lt;MODULEFILE&gt;  # rolls back the configuration performed by the associated load\nmodule avail                # shows what modules are available for loading\nmodule help                 # \nmodule spider               # lists all modules, including ones not in your MODULEPATH\nmodule spider &lt;NAME&gt;        # search for a module whose name includes &lt;NAME&gt;\nmodule save &lt;NAME&gt;.         # save currently-loaded modules to \"default\" or optionally to &lt;NAME&gt;\nmodule restore &lt;NAME&gt;.      # load the saved collection\n</code></pre>","tags":["needs-review","jiong"]},{"location":"sw/modules-old/#defaults","title":"Defaults","text":"<p>By default the following modules are loaded on all compute hosts and the login hosts when you log in</p> <pre><code>JHPCE_ROCKY9_DEFAULT_ENV\nJHPCE_tools/3.0\n</code></pre>","tags":["needs-review","jiong"]},{"location":"sw/modules-old/#configuring-your-bashrc","title":"Configuring your .bashrc","text":"<p>It is critical that your <code>.bashrc</code> file sources the system-wide bashrc file. Otherwise basic programs will not work! After you source the system-wide bashrc file you can add code which will modify your environment. For example:</p> <pre><code># Always source the global bashrc\nif [ -f /etc/bashrc ]; then\n. /etc/bashrc\nfi\n\n# If I prefer gcc/4.8.1 as my default compiler\nmodule load gcc/4.8.1\n</code></pre>","tags":["needs-review","jiong"]},{"location":"sw/modules-old/#community-maintained-applications","title":"Community maintained applications","text":"<p>We use a community-based model of application maintenance to support our diverse user base. Briefly, this means that we support essentially few applications as a service center. Instead we encourage and facilitate power users to maintain their tools in a manner that makes their tools available to all users. These users maintain their applications as well as the corresponding modulefiles. Below is a list of applications and application suites that are maintained by community maintainers. Please refer to their documentation for details. Also please be considerate. Maintaining software for you is not their day job. There is absolutely no point in getting bent out of shape if they can\u2019t (or won\u2019t) service your request.</p> <pre><code>Description Maintainer  Documentation\nR   Kasper Hansen   Documentation\nPerl    Jiong Yang  Documentation\nPython  Alyssa Frazee   Documentation\nShortRead Tools Kasper Hansen   Documentation\n</code></pre>","tags":["needs-review","jiong"]},{"location":"sw/modules/","title":"Modules","text":""},{"location":"sw/modules/#environment-modules","title":"Environment Modules","text":""},{"location":"sw/modules/#introduction","title":"Introduction","text":"<p>Environment Modules provide a convenient way to dynamically change the users\u2019 environment through modulefiles. When a user loads a module for a specific version of a software package, appropriate changes are made to the user's environment, such as adding new locations in the PATH environment variables. When package is no longer needed, users can unload the module from their environment.  </p> <p>The JHPCE cluster uses the Lmod module system to allow users to configure their shell environments.</p>"},{"location":"sw/modules/#use-modules-on-jhpce-cluster","title":"Use modules on JHPCE cluster","text":"<ul> <li>list loaded modules in your environment</li> </ul> <pre><code>[test@compute-107 ~]$ module list\n\nCurrently Loaded Modules:\n  1) JHPCE_ROCKY9_DEFAULT_ENV   2) JHPCE_tools/3.0\n</code></pre> <pre><code>[test@compute-107 ~]$ module list\n\nCurrently Loaded Modules:\n  1) JHPCE_ROCKY9_DEFAULT_ENV   2) JHPCE_tools/3.0\n</code></pre> <ul> <li>list available modules <pre><code>[test@compute-107 ~]$ module avail\n</code></pre></li> </ul> <p>Notes:</p> <ul> <li>in order to use a software that is not in shell's standard search path, you need first load its module  </li> <li>LIBD contributes many modules. If you need help with any of these, please email bithelp</li> </ul> <ul> <li>load a module (e.g. R module) <pre><code>[test@compute-107 ~]$ module load R\nLoading R/4.3\n(4.3)[test@compute-107 ~]$ module list\n\nCurrently Loaded Modules:\n  1) JHPCE_ROCKY9_DEFAULT_ENV   2) JHPCE_tools/3.0   3) conda/3-23.3.1   4) R/4.3\n</code></pre></li> </ul> <p>Note: Some software packages depend on other software. Loading module for the package may load modules for the other software as well. In this case, loading R also loads conda module. If you have your own conda environment, please make sure there is no conflicts.</p> <ul> <li> <p>unload a module (e.g. when R is no longer needed, you can unload it from your environment) <pre><code>(4.3)[test@compute-107 ~]$ module unload R\nUnloading R/4.3\n[test@compute-107 ~]$ module list\n\nCurrently Loaded Modules:\n  1) JHPCE_ROCKY9_DEFAULT_ENV   2) JHPCE_tools/3.0   3) conda/3-23.3.1\n</code></pre></p> </li> <li> <p>get help on using module <pre><code>[test@compute-107 ~]$ module help\nUsage: module [options] sub-command [args ...]\n...\n</code></pre></p> </li> </ul>"},{"location":"sw/python-pkg/","title":"Python Packages","text":""},{"location":"sw/python-pkg/#installing-python-packages","title":"Installing Python Packages","text":"<ul> <li>Choose the Python version you want to use <pre><code>[test@compute-107 ~]$ module load python\n[test@compute-107 ~]$ python3 --version\nPython 3.9.14\n</code></pre></li> </ul> <p>Note</p> <p>You can use <code>module avail python</code> to see available python versions on the cluster, and load the one you want to use.</p> <ul> <li> <p>Ensure you can run pip from the command line <pre><code>[compute-107 /users/test]$ python3 -m pip --version\npip 23.1.2 from /jhpce/shared/jhpce/core/python/3.9.14/lib/python3.9/site-packages/pip (python 3.9)\n</code></pre></p> </li> <li> <p>Installing a package into your own home directory (e.g. requests package) <pre><code>[test@compute-107 ~]$ python3 -m pip install --user requests\n</code></pre></p> </li> </ul> <p>Notes:</p> <p>To install a specific version: <pre><code>[test@compute-107 ~]$ python3 -m pip install --user requests=2.31.0\n</code></pre></p>"},{"location":"sw/python/","title":"Python","text":""},{"location":"sw/python/#using-python-interactively-on-command-line","title":"Using Python Interactively on command line","text":"<pre><code>[test@login31 ~]$ srun --pty bash\nsrun: job 3168742 queued and waiting for resources\nsrun: job 3168742 has been allocated resources\n[test@compute-100 ~]$ module load python\n[test@compute-100 ~]$ module list\n\nCurrently Loaded Modules:\n  1) JHPCE_ROCKY9_DEFAULT_ENV   2) JHPCE_tools/3.0   3) python/3.9.14\n\n[test@compute-100 ~]$ python3\nPython 3.9.14 (main, May 16 2023, 14:32:18) \n[GCC 11.3.1 20220421 (Red Hat 11.3.1-2)] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; \n</code></pre>"},{"location":"sw/python/#running-python-program-in-batch-mode","title":"Running Python program in batch mode","text":"<ol> <li> <p>Write your python source in a file with .py extension (e.g. python_example.py) <pre><code>values = [88, 47, 96, 85, 72]\nfor i in values:\n    print('Example number = ', i)\n</code></pre></p> </li> <li> <p>Write a submit job script (e.g. python_example.sh) <pre><code>#!/bin/bash\n\n#SBATCH --mem=2G\n#SBATCH --time=2:00\n\n#SBATCH -o slurm.%N.%J.%u.out   # STDOUT\n#SBATCH -e slurm.%N.%J.%u.err   # STDERR\n\nmodule load python\npython3 python_example.py\n</code></pre></p> </li> <li> <p>Submit your python job <pre><code>[test@login31 ~]$ sbatch python_example.sh \nSubmitted batch job 3169570\n</code></pre></p> </li> <li> <p>Monitor the job status <pre><code>[test@login31 ~]$ squeue --me\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n           3169570    shared python_e    test R       0:01      1 compute-153\n</code></pre></p> </li> <li> <p>When the job is finished, the output files are created in your Current Working Directory <pre><code>-rw-r--r-- 1 test test   0 Mar 13 12:45 slurm.compute-153.3169570.test.err\n-rw-r--r-- 1 test test 105 Mar 13 12:45 slurm.compute-153.3169570.test.out\n</code></pre></p> </li> <li> <p>Look at the results from output file, file with stderr is empty(job without errors): <pre><code>[test@login31 ~]$ cat slurm.compute-153.3169570.test.out\nExample number =  88\nExample number =  47\nExample number =  96\nExample number =  85\nExample number =  72\n</code></pre></p> </li> </ol>"},{"location":"sw/r-n-friends/","title":"R Basics","text":"<ul> <li>R</li> <li>RStudio</li> <li>RStudio Server</li> </ul> <p>Authoring Note</p> <p>Jeffrey started copying over RStudio and RStudio Server images and text from the old web site. Then switched to another task. So those sections, especially, need careful review in this document. They may look complete but is not.</p> <p>Authoring Note</p> <p>Multiple other documents refer to this one. If it is decided to break this document up into multiple documents, those reference links will need to be updated.</p> <p>We have a version of R available as a module.</p> <p>This version of R is also known as conda_R. It was built with conda and contains many extra packages commonly used on the cluster.</p> <p>You can install your own packages to your home directory, as described in this document about building your own R and python pkgs. You can also install your own version of R in your home directory, preferably using conda.</p>","tags":["in-progress","refers-to-old-website"]},{"location":"sw/r-n-friends/#examples-of-running-r","title":"Examples of Running R","text":"<p>During orientation, participants are shown a number of example files stored in a directory copied into new account home directories. There is a copy of the latest set of those in the directory /jhpce/shared/jhpce/class-scripts/</p> <p>We have one set for users of the main cluster and a second for users of the C-SUB. </p> <p>You can copy the latest files into your home directory with this command, replacing \"clustername\" with either \"jhpce\" or \"c-sub\" <code>rsync -av /jhpce/shared/jhpce/slurm/class-scripts/clustername/ $HOME/class-scripts</code> For that rsync command to work correctly, there needs to be a trailing slash on the path to the originals of the class-scripts.</p>","tags":["in-progress","refers-to-old-website"]},{"location":"sw/r-n-friends/#running-r-interactively","title":"Running R Interactively","text":"<p>In $HOME/class-scripts/R-demo there are two files, a SLURM batch job file and an R program file. </p> <ul> <li><code>cd $HOME/class-scripts/R-demo</code></li> <li>Inspect the batch job file: <code>cat plot1.sh</code></li> <li><code>srun --pty --x11 bash</code></li> <li><code>module load conda_R</code></li> <li>Run plot1.r: <code>R CMD BATCH plot1.r</code></li> <li>Running the program creates a file \"plot1-R-results.pdf\"</li> <li>You can view it with a program or a web browser:</li> <li><code>xpdf plot1-R-results.pdf &amp;</code></li> <li><code>chromium-browser file:///$HOME/class-scripts/R-demo/plot1-R-results.pdf &amp;</code></li> </ul>","tags":["in-progress","refers-to-old-website"]},{"location":"sw/r-n-friends/#running-r-in-a-batch-job","title":"Running R In A Batch Job","text":"<ul> <li>Inspect the batch job file: <code>cat plot1.sh</code></li> <li>Submit the job to run: <code>sbatch plot1.sh</code></li> <li>See your</li> </ul>","tags":["in-progress","refers-to-old-website"]},{"location":"sw/r-n-friends/#examples-of-running-rstudio","title":"Examples of Running RStudio","text":"","tags":["in-progress","refers-to-old-website"]},{"location":"sw/r-n-friends/#running-from-the-command-line","title":"Running from the Command Line","text":"<ul> <li><code>srun --pty --x11 --mem=10G bash</code></li> <li><code>module load conda_R</code></li> <li><code>module load rstudio</code></li> <li><code>rstudio &amp;</code></li> </ul>","tags":["in-progress","refers-to-old-website"]},{"location":"sw/r-n-friends/#running-via-the-web-portal","title":"Running via the Web Portal","text":"<p>Please see our page about using it.</p>","tags":["in-progress","refers-to-old-website"]},{"location":"sw/r-n-friends/#running-rstudio-server","title":"Running RStudio Server","text":"","tags":["in-progress","refers-to-old-website"]},{"location":"sw/r-n-friends/#running-from-the-command-line_1","title":"Running from the Command Line","text":"<p>Depending on which cluster you are using, run one of the following two scripts after starting an interactive session and landing on a compute node. (The discussion below assumes that you are on the jhpce cluster.) </p> <ul> <li>jhpce-rstudio-server</li> <li>csub-rstudio-server</li> </ul> <p>Rstudio Server is a web based environment for developing R programs.  On the JHPCE cluster we have put together a script called \u201cjhpce-rstudio-server\u201d which will allow you to run your own personal copy of Rstudio Server and access it from a browser on your laptop or desktop.  When the \u201cjhpce-rstudio-server\u201d program is run, it starts an instance of the Rstudio Server web server within a Singularity image on a unique port number, and then provides instructions for setting up an ssh tunnel to allow you to access Rstudio Server from your local system.</p> <p>You will need to perform one step to enable access to this Rstudio Server from your local laptop/desktop;  specifically, you will need to add a tunnel to your existing ssh session to the JHPCE cluster.</p> <p>Tip</p> <p>In UNIX, you send an interrupt signal to a running foreground program using the key combination <code>CONTROL c</code> This is historically written as <code>^C</code>  Note that you DO NOT actually use the SHIFT key to capitalize the C. The way it is written is misleading. You do NOT type <code>CONTROL SHIFT c</code>. However this is the way it has been written for decades, and we will do so.</p> <p>Warning</p> <p>However, you DO need to capitalize the letter <code>c</code> when trying to send an interrupt signal to the ssh program on Mac or Linux computers. The key combination for an ssh interrupt is <code>~ SHIFT c</code></p>","tags":["in-progress","refers-to-old-website"]},{"location":"sw/r-n-friends/#for-mac-or-linux-computers","title":"For Mac or Linux computers:","text":"<p>To add this tunnel, first type ~C (while holding down SHIFT, press \u201c~\u201d then \u201cC\u201d).  The ~C is used to send an interrupt to your ssh session.  The ~C will likely not show up, but you should see an \u201cssh&gt;\u201d prompt as a result.  At this \u201cssh&gt;\u201d prompt you activate the tunnel by typing  -L XXXXX:compute-YYY:XXXXX  .  This will allow your laptop/desktop to access the compute node compute-YYY on port XXXXX (in the above example, the port used was 12345 and the compute node used was compute-012).</p>","tags":["in-progress","refers-to-old-website"]},{"location":"sw/r-n-friends/#for-windows-computers-or-from-the-safe-desktop","title":"For Windows computers, or from the SAFE Desktop:","text":"<p>If you connected to the JHPCE cluster with MobaXterm from a Windows-based system or SAFE desktop, you should ignore the first step (entering ~C and adding the local tunnel). </p> <p>Instead, you will need to  add a tunnel from MobaXterm.</p> <p>Before setting up the tunnel you may find it helpful to set up an SSH key using the steps at https://jhpce.jhu.edu/knowledge-base/mobaxterm-configuration#ssh-keys While not a requirement, this will eliminate the need to login using your password and Google Verification Code.  Note that if you are setting up the tunnel for the C-SUB, you will not be able to use SSH keys due to the enhanced security of the C-SUB.</p> <p>To start, click on the \u201cTunneling\u201d icon at the top of MobaXterm, and you should see the window below:</p> <p></p> <p>Click on \u201cNew SSH Tunnel\u201d, and you should see:</p>","tags":["in-progress","refers-to-old-website"]},{"location":"sw/r-n-friends/#shutting-down-the-rstudio-server","title":"Shutting down the Rstudio Server","text":"<p>When you have finished using Rstudio Server, you should close the browser tab or window that you are using to run Rstudio Server, and then return to the ssh session where you ran the \u201cjhpce-rstudio-server\u201d command.  To stop the Rstudio Server, type \u201c^C\u201d.  You will then be given a few additional steps to run to deactivate the port forward. As with the establishment of the tunnel, these steps are for MacOS and Linux based desktops/laptops.  You will again be prompted to type \u201c~C\u201d, and then enter \u201c-KL XXXXX\u201d at the \u201cssh&gt;\u201d prompt to stop the forwarding (NOTE: you\u2019ll need to hit  once before typing \u201c~C\u201d).  The session should look similar to: <p>Once you enter your login and password, you should see Rstudio running in your browser.</p> <p>For Windows desktops/laptops, you should also use \u201c^C\u201d to terminate the Rstudio Server, but to stop the tunnel you will need to return to the MobaSSHTunnel screen, and use the \u201cStop\u201d icon  in the Start/Stop column.  You can keep this tunnel configuration in MobaSSHTunnel, and reuse it the next time you run Rstudio Server, however you will need to edit the tunnel configuration and change the \u201cRemote Server\u201d to match the compute node you are running on.</p>","tags":["in-progress","refers-to-old-website"]},{"location":"sw/r-n-friends/#faqscomments","title":"FAQs/Comments","text":"<p>Q) Why did you do this?  R works just fine for me on the cluster!</p> <p>A) On the JHPCE cluster we have historically had several ways to run R programs.  Often  people will use the text-based version of R to run programs, and that works well for a lot of people.  Some people prefer to work in a graphical environment, so we also have the X11-based \u201cRstudio\u201d available on the cluster, which is great, except that on a slower network connection, this can get quite laggy.  The web based Rstudio Server provides the same graphical version available in Rstudio, but over a much lighter network protocol than the X11-based Rstudio, so it is much faster and more responsive to use.</p> <p>Q) Why not just set up a dedicated web server to run Rstudio Server like I had back at ZZZZ?</p> <p>A) Rstudio Server does not play well with clusters.  For us to run a dedicated Rstudio Server server, we would need to purchase a fairly large system with lots of RAM and CPU power.  This was considered, but in the end was deemed cost prohibitive, and it didn\u2019t allow the use of the JHPCE cluster resources to run R programs.  This solution allows the nice web-based Rstudio Server to be used, while making use of the existing CPU and RAM resources available on the cluster.</p> <p>Q) My program can\u2019t run because it needs XXX package!</p> <p>A) The R that is run within the Rstudio Server is completely separate  from the default version of R that is used on the JHPCE cluster, therefor you may need to install packages using the install.packages() function, or through the Rstudio Server GUI .</p> <p>Q) I forgot to cleanly disconnect from the Rstudio Server/My session got disconnected.</p> <p>A) This should be fine.  Your interactive srun session will eventually time out and will kill the Rstudio Server that was running.  You may get warning messages about ports being in use \u2013 if so, please wait a few minutes and try again.</p> <p>Q) When I try to add the port forward, I get an error message about \u201cPort is in use\u201d.  How do I fix this?</p> <p>A) You can only run one instance of Rstudio Server. You likely have another SSH session running that has the port forward lingering.  If you had been using Rstudio Server in another SSH session, you will need to either need to log out of that ssh session, or run the \u201c~C\u201d \u201c-KL XXXXX\u201d command to tear down the port forward.</p> <p>If you have any questions  about using Rstudio Server, please feel free to email us at bitsupport.</p>","tags":["in-progress","refers-to-old-website"]},{"location":"sw/r-pkg/","title":"R Packages","text":""},{"location":"sw/r-pkg/#installing-r-packages","title":"Installing R packages","text":"<ul> <li>load R module from a compute node <pre><code>[test@compute-107 ~]$ module load R\nLoading R/4.3\n(4.3)[test@compute-107 ~]$\n</code></pre></li> </ul> <p>Note</p> <p>R points to conda_R. Therefore, loading either R or conda_R would use the same version of R.</p> <ul> <li>use <code>install.package(pkgname)</code> to install a package <pre><code>(4.3)[test@compute-107 ~]$ R\n\nR version 4.3.1 Patched (2023-07-19 r84711) -- \"Beagle Scouts\"\nCopyright (C) 2023 The R Foundation for Statistical Computing\nPlatform: x86_64-conda-linux-gnu (64-bit)\n...\n[Previously saved workspace restored]\n\n&gt; install.package(\"your-package-name\")\n</code></pre></li> </ul>"},{"location":"sw/r-slurmjobs/","title":"Working with SLURM via R and slurmjobs","text":"<p>slurmjobs provides helper functions for interacting with SLURM-managed high-performance-computing environments from R. It includes functions for creating submittable jobs (including array jobs), monitoring partitions, and extracting info about running or complete jobs.</p> <p>R is an open-source statistical environment which can be easily modified to enhance its functionality via packages. </p> <p>slurmjobs is a R package available via the Bioconductor repository for packages. R can be installed on any operating system from CRAN after which you can install slurmjobs </p> <p>For more information about slurmjobs, see</p> <p>http://research.libd.org/slurmjobs/articles/slurmjobs.html</p>"},{"location":"sw/r/","title":"R","text":""},{"location":"sw/r/#running-r-interactively-from-command-line","title":"Running R Interactively from command line","text":"<pre><code>[test@login31 ~]$ srun --pty bash\nsrun: job 3176550 queued and waiting for resources\nsrun: job 3176550 has been allocated resources\n[test@compute-152 ~]$ module load conda_R\nLoading conda_R/4.3.x\n(4.3.x)[test@compute-152 ~]$ module list\n\nCurrently Loaded Modules:\n  1) JHPCE_ROCKY9_DEFAULT_ENV   2) JHPCE_tools/3.0   3) conda/3-23.3.1   4) conda_R/4.3.x\n\n(4.3.x)[test@compute-152 ~]$ R\n\nR version 4.3.2 Patched (2024-02-08 r85876) -- \"Eye Holes\"\nCopyright (C) 2024 The R Foundation for Statistical Computing\nPlatform: x86_64-conda-linux-gnu (64-bit)\n...\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n...\n&gt; \n</code></pre>"},{"location":"sw/r/#running-r-in-batch-mode","title":"Running R in batch mode","text":"<ol> <li> <p>Write your R source in a file with .r extension (e.g. plot1.r) <pre><code># Set output file name\npdf(\"plot1-R-results.pdf\")\n\n# Define 2 vectors\ncars &lt;- c(1, 3, 6, 4, 9)\ntrucks &lt;- c(2, 5, 4, 5, 12)\n\n# Graph cars using a y axis that ranges from 0 to 12\nplot(cars, type=\"o\", col=\"blue\", ylim=c(0,12))\n\n# Graph trucks with red dashed line and square points\nlines(trucks, type=\"o\", pch=22, lty=2, col=\"red\")\n\n# Create a title with a red, bold/italic font\ntitle(main=\"Autos\", col.main=\"red\", font.main=4)\n</code></pre></p> </li> <li> <p>Write a submit job script (e.g. plot1.sh) <pre><code>#!/bin/bash\n\n#SBATCH --mem=2G\n#SBATCH --time=2:00\n\nmodule load conda_R\nR CMD BATCH plot1.r\n</code></pre></p> </li> <li> <p>Submit your R job <pre><code>[test@login31 ~]$ sbatch plot1.sh \nSubmitted batch job 3177833\n</code></pre></p> </li> <li> <p>Monitor the job status <pre><code>[test@login31 ~]$ squeue --me\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n           3177833    shared plot1.sh    test  R       0:03      1 compute-095\n</code></pre></p> </li> <li> <p>When the job is finished, the output files are created in your Current Working Directory <pre><code>-rw-r--r--    1 test test        22 Mar 13 16:29  slurm-3177833.out\n-rw-r--r--    1 test test      4988 Mar 13 16:29  plot1-R-results.pdf\n</code></pre></p> </li> <li> <p>Look at the result file, plot1-R-results.pdf; you can use xpdf to view it if you have set X11 forward when login.    Otherwise, you need download the file to local machine to view it. <pre><code>[test@login31 ~]$ xpdf plot1-R-results.pdf\n</code></pre></p> </li> </ol>"},{"location":"sw/r/#running-rstudio","title":"Running RStudio","text":"<pre><code>[test@login31 ~]$ srun --mem 10G --x11 --pty bash\nsrun: job 3244190 queued and waiting for resources\nsrun: job 3244190 has been allocated resources\n[test@compute-097 ~]$ module load R\nLoading R/4.3\n(4.3)[test@compute-097 ~]$ module load rstudio\n(4.3)[test@compute-097 ~]$ rstudio\n</code></pre> <p>Note</p> <p>X Windows Setup - For Windows, MobaXterm has an X server built into it - For Mac, you need to have the XQuartz program installed (which requires a reboot), and you need to add the \"-X\" option to ssh: <pre><code>ssh -X yourusername@jhpce03.jhsph.edu\n</code></pre></p>"},{"location":"sw/r/#running-rstudio-via-web","title":"Running RStudio via web","text":"<p>You can run RStudio via JHPCE Application Portal by login with your JHED ID and password.</p> <p>Note</p> <p>This web site is only available on campus, so if you are outside of the school network, you will need login to the JHU VPN first.</p>"},{"location":"sw/sas-old/","title":"SAS","text":"","tags":["in-progress","jiong"]},{"location":"sw/sas-old/#we-have-a-sas-partition","title":"We Have A SAS Partition","text":"<p>Containing two nodes.</p>","tags":["in-progress","jiong"]},{"location":"sw/sas-old/#other-ways-to-access-sas","title":"Other ways to access SAS","text":"<p>SAS is available in a virtual Windows environment called SAFE. Here is a link to information about SAFE.</p>","tags":["in-progress","jiong"]},{"location":"sw/sas-old/#marketscan-database","title":"MarketScan Database","text":"","tags":["in-progress","jiong"]},{"location":"sw/sas-old/#how-to-get-permission-to-access-it","title":"How To Get Permission To Access It","text":"","tags":["in-progress","jiong"]},{"location":"sw/sas-old/#where-is-it","title":"Where Is It","text":"","tags":["in-progress","jiong"]},{"location":"sw/sas-old/#when-running-sas-an-error-dialog-pops-up-about-remote-browser","title":"When running SAS, an error dialog pops up about Remote Browser","text":"<p>When running SAS, you may need to specify options to indicate which browser to use when displaying either help or graphical output. We recommend using the Chromium browser. You can use the following options to the SAS command to do so:</p> <p><code>sas -helpbrowser SAS -xrm \"SAS.webBrowser:'/usr/bin/chromium-browser'\" -xrm \"SAS.helpBrowser:'/usr/bin/chromium-browser'\"</code></p> <p>Here is some code you can add to your .bashrc file which contain some convenient bash aliases for starting SAS with browser support configured. Once that becomes part of your environment (by sourcing the file or by logging out and back in again), after loading the SAS module you can start SAS using either <code>csas</code> or <code>fsas</code> so that it can open the desired web browser if needed.</p> <p>Warning</p> <p>These definitions include optional syntax (<code>&gt; /dev/null 2&gt;&amp;1</code>) which hide error messages. If you are having problems displaying SAS material in web browsers, you may need to run SAS without that output redirection. The \"srun half duplex\" error is an example of such a case.</p> <pre><code># SAS routines for __interactive__ sessions where plotting is involved\n# (because SAS generates HTML for the plots when run in interactive mode)\n# \n# (YOU HAVE TO RUN \"module load SAS\" before calling either of these routines)\n#\n# If you want to use Firefox as your web browser for SAS:\n#\nfsas() { sas -helpbrowser SAS -xrm \"SAS.webBrowser:'/usr/bin/firefox'\" -xrm \"SAS.helpBrowser:'/usr/bin/firefox'\" \"$@\" &gt; /dev/null 2&gt;&amp;1; }\n#\n# If you want to use Chromium-browser as your web browser for SAS:\n#\ncsas() { sas -helpbrowser SAS -xrm \"SAS.webBrowser:'/usr/bin/chromium-browser'\" -xrm \"SAS.helpBrowser:'/usr/bin/chromium-browser'\" \"$@\" &gt; /dev/null 2&gt;&amp;1; }\n</code></pre>","tags":["in-progress","jiong"]},{"location":"sw/sas/","title":"SAS","text":""},{"location":"sw/sas/#using-sas-interactively","title":"Using SAS interactively","text":"<pre><code>[test@login31 ~]$ srun --partition sas --mem 10G --x11 --pty bash\nsrun: job 3178287 queued and waiting for resources\nsrun: job 3178287 has been allocated resources\n\n[test@compute-101 ~]$ module load sas\n[test@compute-101 ~]$ module list\n\nCurrently Loaded Modules:\n  1) JHPCE_ROCKY9_DEFAULT_ENV   2) JHPCE_tools/3.0   3) sas/9.4\n\n[test@compute-101 ~]$ sas -helpbrowser SAS -xrm \"SAS.webBrowser:'/usr/bin/chromium-browser'\" -xrm \"SAS.helpBrowser:'/usr/bin/chromium-browser'\"\n\n## if you want to use Firefox as your web browser for SAS, run the following command instead\n[test@compute-101 ~]$ sas -helpbrowser SAS -xrm \"SAS.webBrowser:'/usr/bin/firefox'\" -xrm \"SAS.helpBrowser:'/usr/bin/firefox'\"\n</code></pre> <p>Note</p> <ul> <li>You may need to accept popups in the chromium/firefox browser that gets started in order to see the windows that SAS is trying to display  </li> <li>In the terminal session that you started \u201csas\u201d, you may see messages similar to ones below.  These can be ignored because the browser wants to run on a local system with a graphics card, and the X11 session doesn\u2019t allow that <pre><code>[2970887:2970887:1024/152818.092311:ERROR:chrome_browser_cloud_management_controller.cc(163)] Cloud management controller initialization aborted as CBCM is not enabled.\n[2970887:2971086:1024/152818.161869:ERROR:login_database.cc(922)] Password store database is too new, kCurrentVersionNumber=35, GetCompatibleVersionNumber=39\n[2970887:2971087:1024/152818.164247:ERROR:login_database.cc(922)] Password store database is too new, kCurrentVersionNumber=35, GetCompatibleVersionNumber=39\n[2970887:2971086:1024/152818.167534:ERROR:login_database_async_helper.cc(59)] Could not create/open login database.\n[2970887:2971087:1024/152818.170351:ERROR:login_database_async_helper.cc(59)] Could not create/open login database.\n[2970887:2970887:1024/152818.626429:ERROR:object_proxy.cc(590)] Failed to call method: org.freedesktop.portal.Settings.Read: object_path= /org/freedesktop/portal/desktop: org.freedesktop.portal.Error.NotFound: Requested setting not found\nlibGL error: No matching fbConfigs or visuals found\nlibGL error: failed to load driver: swrast\n</code></pre></li> </ul>"},{"location":"sw/sas/#running-sas-job-in-batch-mode","title":"Running SAS job in batch mode","text":"<ol> <li> <p>Write your sas source in a file with .sas extension (e.g. class-info.sas) <pre><code>DATA CLASS;\n     INPUT NAME $ 1-8 SEX $ 10 AGE 12-13 HEIGHT 15-16 WEIGHT 18-22;\nCARDS;\nJOHN     M 12 59 99.5\nJAMES    M 12 57 83.0\nALFRED   M 14 69 112.5\nALICE    F 13 56 84.0\n\nPROC MEANS;\n     VAR AGE HEIGHT WEIGHT;\nPROC PLOT;\n     PLOT WEIGHT*HEIGHT;\nENDSAS;\n;\n</code></pre></p> </li> <li> <p>Write a submit job script (e.g. sas-demo1.sh) <pre><code>#!/bin/bash\n\n#SBATCH --partition=sas\n#SBATCH --mem=2G\n#SBATCH --time=2:00\n\nmodule load sas\nsas class-info.sas\n</code></pre></p> </li> <li> <p>Submit your matlab job <pre><code>[test@login31 ~]$ sbatch sas-demo1.sh\nSubmitted batch job 3178475\n</code></pre></p> </li> <li> <p>Monitor the job status <pre><code>[test@login31 ~]$ squeue --me\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n            3178475       sas sas-demo    test R       0:01      1 compute-101\n</code></pre></p> </li> <li> <p>When the job is finished, the output files are created in your Current Working Directory <pre><code>-rw-r--r-- 1 test test    0 Mar 13 16:49 slurm-3178475.out\n-rw-r--r-- 1 test test 2108 Mar 13 16:49 class-info.lst\n</code></pre></p> </li> <li> <p>Look at the results from output file <pre><code>[test@login31 ~]$ cat class-info.lst\n\n                                                        The MEANS Procedure\n\n                           Variable    N            Mean         Std Dev         Minimum         Maximum\n                           -----------------------------------------------------------------------------\n                           AGE         4      12.7500000       0.9574271      12.0000000      14.0000000\n                           HEIGHT      4      60.2500000       5.9651767      56.0000000      69.0000000\n                           WEIGHT      4      94.7500000      14.0386372      83.0000000     112.5000000\n                           -----------------------------------------------------------------------------\n</code></pre></p> </li> </ol>"},{"location":"sw/singularity/","title":"stub page for the \"Software\" topic","text":"<p>This is a stub page for the \"Software\" topic.</p> <p>Create a new file with the right contents for the topic header in the nav bar. Then point that header to the new document instead of \"sw/sw-stub.md\"</p>","tags":["needs-to-be-written","jiong"]},{"location":"sw/stata/","title":"Stata","text":""},{"location":"sw/stata/#using-stata-interactively","title":"Using Stata interactively","text":"<pre><code>[test@login31 ~]$ srun --mem 10G --x11 --pty bash\nsrun: job 3179341 queued and waiting for resources\nsrun: job 3179341 has been allocated resources\n[test@compute-092 ~]$ module load stata\n[test@compute-092 ~]$ module list\n\nCurrently Loaded Modules:\n  1) JHPCE_ROCKY9_DEFAULT_ENV   2) JHPCE_tools/3.0   3) stata/17\n\n[test@compute-092 ~]$ xstata\n</code></pre>"},{"location":"sw/stata/#running-stata-program-in-batch-mode","title":"Running Stata program in batch mode","text":"<ol> <li> <p>Write your Stata source in a file with .do extension (e.g. stata-demo1.do) <pre><code>program define hello\ndi \"Hello There World 123\"\nend\nhello\n</code></pre></p> </li> <li> <p>Write a submit job script (e.g. stata-demo1.sh) <pre><code>#!/bin/bash\n\n#SBATCH --mem=2G\n#SBATCH --time=2:00\n\nmodule load stata\nstata -b stata-demo1.do\n</code></pre></p> </li> <li> <p>Submit your matlab job <pre><code>[test@login31 ~]$ sbatch stata-demo1.sh\nSubmitted batch job 3179530\n</code></pre></p> </li> <li> <p>Monitor the job status <pre><code>[test@login31 ~]$ squeue --me\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n            3179530    shared stata-de    test  R       0:01      1 compute-092\n</code></pre></p> </li> <li> <p>When the job is finished, the output files are created in your Current Working Directory <pre><code>-rw-r--r-- 1 test test   0 Mar 13 17:29 slurm-3179530.out\n-rw-r--r-- 1 test test 890 Mar 13 17:29 stata-demo1.log\n</code></pre></p> </li> <li> <p>Look at the result <pre><code>[test@login31 ~]$ cat stata-demo1.log\n...\n. do \"stata-demo1.do\" \n\n. program define hello\n  1. di \"Hello There World 123\"\n  2. end\n\n. hello\nHello There World 123\n\n. \nend of do-file\n</code></pre></p> </li> </ol>"},{"location":"sw/sw-overview-old/","title":"SOFTWARE TOPIC - page to develop outline","text":"","tags":["topic-overview","needs-to-be-written"]},{"location":"sw/sw-overview-old/#what-weve-installed-how-to-use-it","title":"What we've installed &amp; how to use it","text":"","tags":["topic-overview","needs-to-be-written"]},{"location":"sw/sw-overview-old/#overview","title":"Overview","text":"","tags":["topic-overview","needs-to-be-written"]},{"location":"sw/sw-overview-old/#modules","title":"Modules","text":"<p>Who creates our modules? Where is the document about using modules?</p>","tags":["topic-overview","needs-to-be-written"]},{"location":"sw/sw-overview-old/#in-the-operating-system","title":"In the operating system","text":"<p>Is there anything useful to say about what's available to people outside of what they see listed by <code>module avail</code>?</p>","tags":["topic-overview","needs-to-be-written"]},{"location":"sw/sw-overview-old/#suggested-programs-for-gui-use","title":"Suggested programs for GUI use","text":"<p>Jeffrey includes in C-SUB orientation a table of GUI programs people might find useful, particularly those new to UNIX and the CLI.</p> <p>There's an open github issue about whether to install some of those C-SUB tools on the JHPCE cluster.</p>","tags":["topic-overview","needs-to-be-written"]},{"location":"sw/sw-overview-old/#software-by-category","title":"Software by category","text":"<p>We don't have to aim for a complete and frequently updated list. But we might give folks pointers to some important tool sets. Maybe our bithelp members can help write this document/section.</p> <p>Example from C.E.C.I</p> <p>Available software, example of</p> <p>Biomolecular simulation pkgs, example of</p>","tags":["topic-overview","needs-to-be-written"]},{"location":"sw/sw-overview-old/#how-to-add-your-own-packages-to-r-and-python","title":"How to add your own packages to R and python","text":"<p>Mark seems to think that we don't need to provide much in the way of instructions to users on building software. But JRT feels that this subtopic, at least, deserves a document.</p> <p>Here is a starter document about adding your needed packages to existing python and R modules.</p>","tags":["topic-overview","needs-to-be-written"]},{"location":"sw/sw-overview-old/#building-your-own-software","title":"Building your own software","text":"<p>If we don't write much beyond the adding-pkgs-to-the-two-popular-interpreted-languages, perhaps this section or document merely provides links to the work of others.</p> <p>JRT thinks that people who have spent decades building software from source may be underestimating what younger people know.  </p> <p>We want to facilitate our users getting going, gaining proficiency. Part of what we want to differentiate us from other options is that we are more helpful than cold and impersonal organizations.</p> <p>Here is a starter document about building your own software.</p> <p>Software installation with Conda</p>","tags":["topic-overview","needs-to-be-written"]},{"location":"sw/sw-overview-old/#gpu-information","title":"GPU Information","text":"<p>Point to documents in that section. JRT created an overview document as a starting point.</p>","tags":["topic-overview","needs-to-be-written"]},{"location":"sw/sw-overview/","title":"Overview","text":""},{"location":"sw/sw-overview/#introduction","title":"Introduction","text":"<p>The Joint High Performance Computing Exchange (JHPCE) offers a variety of software for use on the cluster. They are installed and running on Rocky Linux 9.2. We use Lmod module system to manage the installed software. You can run <code>module aval</code> at the cluster prompt for the available software.</p>"},{"location":"sw/sw-overview/#current-available-software","title":"Current available software","text":"<pre><code>[test@compute-110 ~]$ module avail\n\n--------------------------------------------------------------------------------- /jhpce/shared/jhpce/modulefiles ---------------------------------------------------------------------------------\n   JHPCE_ROCKY9_DEFAULT_ENV (L)    bcl2fastq/2.17.1              freesurfer/7.4.1           gmp/6.2.1                 mathematica/13.3        python/3.11.8             stata/17\n   JHPCE_tools/3.0          (L)    bowtie/2.5.1                  fsl/6.0.6.5                go/20.6                   matlab/R2023a    (D)    rstudio/2023.06.1         tex/20240117\n   R_test/4.3.2                    conda/3-23.3.1-testing        gcc/9.5.0                  helix/23.10.0             matlab/R2023b           rust/1.76.0               wine/7.11\n   afni/23.3.09                    conda/3-23.3.1         (D)    gcc/13.1.0          (D)    java/19            (D)    mpc/1.3.1               sas/9.0\n   alphafold/4.3.1                 dcmtk/3.6.7                   gdal/3.6.0                 julia/1.9.2               mpfr/4.2.0              sas/9.4            (D)\n   anaconda/2023.03                encfs/1.9.5                   ghostscript/10.02.1        kakoune/2023-08-05        python/3.9.14    (D)    shapeit/5.1.1\n   aws/2.12.7                      ffmpeg/6.0                    glpk/5.0                   latex/20240117            python/3.10.13          singularity/3.11.4\n\n------------------------------------------------------------------------------- /jhpce/shared/community/modulefiles -------------------------------------------------------------------------------\n   R/4.3    bedtools/2.31.0    conda_R/devel    conda_R/test    conda_R/4.3.x (D)    conda_R/4.3\n\n--------------------------------------------------------------------------------- /jhpce/shared/libd/modulefiles ----------------------------------------------------------------------------------\n   PRSice/2.2.13           cell2location/0.1.3          fusion_twas/github            java/17                   plink/1.90b              samtools/1.18       (D)    trimgalore/0.6.6\n   Salmon/1.2.1            cell2location/0.8a0   (D)    gatk/4.2.0.0                  java/18                   plink/2.00a4.6    (D)    samui/1.0.0-next.24        trimmomatic/0.39\n   Salmon/1.10.1    (D)    cellpose/2.2.2               gffread/github                kallisto/0.46.1           qctool/2.0.7             samui/1.0.0-next.45 (D)    vampire/3.4.4\n   arioc/1.51              cellprofiler/4.2.6           gffread/0.12.7         (D)    ldsc/1.0.1                qtl_gtex/dae3369         spaceranger/2.1.0          vcftools/0.1.16\n   bamtofastq/1.4.1        cellranger/7.0.0             git-lfs/3.4.0                 magma/1.10                r_nac/1.0                spagcn/1.2.0               wiggletools/1.2.1\n   bcftools/1.10.2         cellranger/7.2.0      (D)    git-status-size/github        methyldackel/0.5.2        regtools/0.5.33g         star/2.7.8a                wigtobigwig/2.9\n   bcftools/1.18    (D)    cellranger_arc/2.0.2         graphst/da29b75               methylpy/1.4.3            resept/1.0.0             subread/2.0.0\n   bfg/1.13.0              cibersortx/04_04_2020        hipstr/0.7                    nextflow/20.01.0          rmate/1.5.10             synapse/2.7.2\n   bismark/0.23.0          dissect/dc45940c             hisat2/2.2.1                  nextflow/22.10.7          rseqc/3.0.1              synapse/3.1.1       (D)\n   bs/1.3.0                fastqc/0.11.8                htslib/1.10.2                 nextflow/23.10.0   (D)    samblaster/0.1.26        tangram/1.0.4\n   bustools/0.39.3         fastqc/0.12.1         (D)    htslib/1.18            (D)    paste/1.3.0               samtools/1.10            tensorqtl/1.0.8\n</code></pre>"},{"location":"sw/sw-overview/#resources-for-some-software","title":"Resources for some software","text":"<ul> <li>Matlab</li> <li>Python</li> <li>R</li> <li>SAS</li> <li>Stata</li> </ul>"},{"location":"sw/sw-stub/","title":"stub page for the \"Software\" topic","text":"<p>This is a stub page for the \"Software\" topic.</p> <p>Create a new file with the right contents for the topic header in the nav bar. Then point that header to the new document instead of \"sw/sw-stub.md\"</p>","tags":["needs-to-be-written","jiong"]},{"location":"sw/vscode/","title":"Virtual Studio Code","text":"","tags":["needs-to-be-written"]},{"location":"ourtools/tags/","title":"Tagged Files","text":"<p>Tags and the files they are mentioned in are listed here, automatically generated by Material for MkDocs.</p> <p>While the web site is under development, they guide site authors to documents which need help and notify users how to approach the information found on tagged pages.</p> <p>After the web site content stabilizes, the tags that remain will primarily consist of keywords.</p>"},{"location":"ourtools/tags/#adi","title":"adi","text":"<ul> <li>GUI Applications</li> </ul>"},{"location":"ourtools/tags/#csub","title":"csub","text":"<ul> <li>What Is The C-SUB?</li> <li>New User</li> </ul>"},{"location":"ourtools/tags/#done","title":"done","text":"<ul> <li>Access Overview</li> <li>Submitting Good Queries</li> <li>Self Service MFA, Password Requests</li> <li>Quality of Service (QOS)</li> <li>sacct tips</li> <li>scontrol tips</li> <li>When Will My Job Start?</li> <li>Fastscratch</li> <li>Quotas</li> </ul>"},{"location":"ourtools/tags/#gpu","title":"gpu","text":"<ul> <li>GPU</li> </ul>"},{"location":"ourtools/tags/#in-progress","title":"in-progress","text":"<ul> <li>SSH</li> <li>X11</li> <li>ACL</li> <li>Files Overview</li> <li>Sharing Files</li> <li>External Guides</li> <li>FAQ</li> <li>Tips &amp; Conventions</li> <li>GUI Applications</li> <li>Crafting SLURM Jobs</li> <li>Monitoring Your Jobs</li> <li>Example User Guides</li> <li>Backups &amp; Restores</li> <li>JHPCE-created</li> <li>R Basics</li> <li>SAS</li> </ul>"},{"location":"ourtools/tags/#jeffrey","title":"jeffrey","text":"<ul> <li>SSH</li> <li>X11</li> <li>ACL</li> <li>Files Overview</li> <li>Sharing Files</li> <li>External Guides</li> <li>Job Environment</li> <li>Getting Started</li> <li>Interactive Jobs</li> </ul>"},{"location":"ourtools/tags/#jiong","title":"jiong","text":"<ul> <li>Environment modules</li> <li>SAS</li> <li>Singularity</li> <li>stub page for the \"Software\" topic</li> </ul>"},{"location":"ourtools/tags/#mark","title":"mark","text":"<ul> <li>GPU</li> <li>Cost Calculator</li> <li>Containers</li> </ul>"},{"location":"ourtools/tags/#needs-major-revision","title":"needs-major-revision","text":"<ul> <li>File Transfer - Overview</li> <li>General Tips/Requests</li> <li>Storage Overview</li> <li>Helpful GUI Programs</li> </ul>"},{"location":"ourtools/tags/#needs-review","title":"needs-review","text":"<ul> <li>OneDrive via rclone</li> <li>FAQ</li> <li>Environment modules</li> </ul>"},{"location":"ourtools/tags/#needs-to-be-written","title":"needs-to-be-written","text":"<ul> <li>Data Security</li> <li>GPU</li> <li>Cost Calculator</li> <li>Job Environment</li> <li>Getting Started</li> <li>Adding Your Own Python and R Libraries</li> <li>Containers</li> <li>Jupyter</li> <li>Singularity</li> <li>SOFTWARE TOPIC - page to develop outline</li> <li>stub page for the \"Software\" topic</li> <li>VS Code</li> </ul>"},{"location":"ourtools/tags/#refers-to-old-website","title":"refers-to-old-website","text":"<ul> <li>Joint HPC Exchange</li> <li>SSH</li> <li>X11</li> <li>GPU</li> <li>General Tips/Requests</li> <li>New PI Form</li> <li>New user form</li> <li>R Basics</li> </ul>"},{"location":"ourtools/tags/#slurm","title":"slurm","text":"<ul> <li>Crafting SLURM Jobs</li> <li>Job Environment</li> <li>Getting Started</li> <li>Interactive Jobs</li> <li>Monitoring Your Jobs</li> <li>Node Features</li> <li>Partitions</li> <li>Quality of Service (QOS)</li> <li>Cmd tips &amp; reference</li> <li>SLURM FAQ</li> <li>sacct tips</li> <li>sacctmgr tips</li> <li>scontrol tips</li> <li>Example User Guides</li> <li>When Will My Job Start?</li> </ul>"},{"location":"ourtools/tags/#ssh","title":"ssh","text":"<ul> <li>SSH</li> </ul>"},{"location":"ourtools/tags/#topic-overview","title":"topic-overview","text":"<ul> <li>Access Overview</li> <li>File Transfer - Overview</li> <li>What Is The C-SUB?</li> <li>Files Overview</li> <li>GPU</li> <li>Storage Overview</li> <li>SOFTWARE TOPIC - page to develop outline</li> </ul>"}]}